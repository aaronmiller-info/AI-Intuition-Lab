<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Intuition Lab</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Work+Sans:wght@400;500;600;700;800;900&family=IBM+Plex+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <style>
    :root {
      /* ═══════════════════════════════════════════════════════════════
         BAUHAUS LIGHT MODE DESIGN SYSTEM
         A comprehensive, consistent color palette inspired by Bauhaus
         ═══════════════════════════════════════════════════════════════ */
      
      /* ─── Background Colors ─── */
      --bg-deep: #FAF7F2;
      --bg-panel: #F5F0E8;
      --bg-card: #FFFFFF;
      --bg-elevated: #EDE8DE;
      --bg-well: #F0EBE3;
      
      /* ─── Primary Colors (Bauhaus Palette) ─── */
      --color-red: #D32F2F;
      --color-blue: #1565C0;
      --color-yellow: #F9A825;
      --color-green: #2E7D32;
      --color-purple: #7B1FA2;
      --color-gray: #9E9E9E;
      --color-gray-dark: #6B7280;
      --color-gray-light: #E0E0E0;
      
      /* RGB values for rgba() usage */
      --color-red-rgb: 211, 47, 47;
      --color-blue-rgb: 21, 101, 192;
      --color-yellow-rgb: 249, 168, 37;
      --color-green-rgb: 46, 125, 50;
      --color-purple-rgb: 123, 31, 162;
      --color-gray-rgb: 158, 158, 158;
      --color-black-rgb: 26, 26, 26;
      --color-white-rgb: 255, 255, 255;
      
      /* ─── Semantic Accent Colors ─── */
      --accent-primary: var(--color-red);
      --accent-secondary: var(--color-blue);
      --accent-warm: var(--color-yellow);
      --accent-cool: var(--color-blue);
      --accent-pink: var(--color-red);
      
      /* ─── Text Colors ─── */
      --text-primary: #1A1A1A;
      --text-secondary: #4A4A4A;
      --text-muted: #7A7A7A;
      
      /* ─── Feedback Colors ─── */
      --positive: var(--color-green);
      --negative: #C62828;
      --negative-rgb: 198, 40, 40;
      
      /* ─── Border Colors ─── */
      --border-subtle: rgba(var(--color-black-rgb), 0.12);
      --border-accent: rgba(var(--color-red-rgb), 0.4);
      --border-primary: rgba(var(--color-red-rgb), 0.3);
      --border-secondary: rgba(var(--color-blue-rgb), 0.3);
      --border-warm: rgba(var(--color-yellow-rgb), 0.3);
      
      /* ─── Glow/Shadow Colors ─── */
      --glow-accent: rgba(var(--color-red-rgb), 0.15);
      --glow-primary: rgba(var(--color-red-rgb), 0.2);
      --glow-secondary: rgba(var(--color-blue-rgb), 0.2);
      --glow-warm: rgba(var(--color-yellow-rgb), 0.3);
      
      /* ─── Opacity Variants (Background fills) ─── */
      --primary-5: rgba(var(--color-red-rgb), 0.05);
      --primary-8: rgba(var(--color-red-rgb), 0.08);
      --primary-10: rgba(var(--color-red-rgb), 0.1);
      --primary-15: rgba(var(--color-red-rgb), 0.15);
      --primary-20: rgba(var(--color-red-rgb), 0.2);
      --primary-30: rgba(var(--color-red-rgb), 0.3);
      
      --secondary-10: rgba(var(--color-blue-rgb), 0.1);
      --secondary-15: rgba(var(--color-blue-rgb), 0.15);
      --secondary-20: rgba(var(--color-blue-rgb), 0.2);
      --secondary-30: rgba(var(--color-blue-rgb), 0.3);
      
      --warm-10: rgba(var(--color-yellow-rgb), 0.1);
      --warm-15: rgba(var(--color-yellow-rgb), 0.15);
      --warm-20: rgba(var(--color-yellow-rgb), 0.2);
      --warm-30: rgba(var(--color-yellow-rgb), 0.3);
      
      --positive-10: rgba(var(--color-green-rgb), 0.1);
      --positive-15: rgba(var(--color-green-rgb), 0.15);
      --positive-30: rgba(var(--color-green-rgb), 0.3);
      
      --negative-8: rgba(var(--negative-rgb), 0.08);
      --negative-10: rgba(var(--negative-rgb), 0.1);
      --negative-15: rgba(var(--negative-rgb), 0.15);
      --negative-20: rgba(var(--negative-rgb), 0.2);
      --negative-30: rgba(var(--negative-rgb), 0.3);
      
      --purple-15: rgba(var(--color-purple-rgb), 0.15);
      --purple-30: rgba(var(--color-purple-rgb), 0.3);
      
      --gray-15: rgba(var(--color-gray-rgb), 0.15);
      --gray-30: rgba(var(--color-gray-rgb), 0.3);
      
      --black-4: rgba(var(--color-black-rgb), 0.04);
      --black-5: rgba(var(--color-black-rgb), 0.05);
      --black-6: rgba(var(--color-black-rgb), 0.06);
      --black-20: rgba(var(--color-black-rgb), 0.2);
      
      /* ─── Layout ─── */
      --radius: 0px;
      --radius-sm: 0px;
      --swiss-border: 2px solid var(--text-primary);
      --swiss-thick: 4px solid var(--text-primary);
      --min-viewport-width: 1024px;
      --max-content-width: 1100px;
      
      /* ─── Typography ─── */
      --font-sans: 'Work Sans', system-ui, sans-serif;
      --font-mono: 'IBM Plex Mono', monospace;
    }

    /* Utilities */
    .mt-1 { margin-top: 1rem; }
    .mt-15 { margin-top: 1.5rem; }
    .mt-2 { margin-top: 2rem; }
    .mb-05 { margin-bottom: 0.5rem; }
    .mb-1 { margin-bottom: 1rem; }
    .mb-15 { margin-bottom: 1.5rem; }
    .mb-2 { margin-bottom: 2rem; }
    .mb-0 { margin-bottom: 0; }
    .p-075 { padding: 0.75rem; }
    .p-1 { padding: 1rem; }
    .p-125 { padding: 1.25rem; }
    .p-15 { padding: 1.5rem; }
    .flex { display: flex; }
    .flex-col { flex-direction: column; }
    .items-center { align-items: center; }
    .justify-center { justify-content: center; }
    .gap-05 { gap: 0.5rem; }
    .gap-075 { gap: 0.75rem; }
    .gap-1 { gap: 1rem; }
    .w-full { width: 100%; }
    .h-full { height: 100%; }
    .flex-1 { flex: 1; }
    .mono { font-family: var(--font-mono); }
    .text-sm { font-size: 0.85rem; }
    .text-xs { font-size: 0.75rem; }
    .text-muted { color: var(--text-muted); }
    .text-secondary { color: var(--text-secondary); }
    .text-accent { color: var(--accent-primary); }
    .text-warm { color: var(--accent-warm); }
    .text-cool { color: var(--accent-cool); }
    .text-pink { color: var(--accent-pink); }
    .text-positive { color: var(--positive); }
    .text-negative { color: var(--negative); }
    .bold { font-weight: 700; }
    .uppercase { text-transform: uppercase; letter-spacing: 0.1em; }
    .h-900 { height: 900px; }
    .max-w-600 { max-width: 600px; }
    .mt-125 { margin-top: 1.25rem; }
    .mb-125 { margin-bottom: 1.25rem; }
    .overflow-y-auto { overflow-y: auto; }
    .hidden { display: none; }
    .card-sm { border: 1px solid var(--border-subtle); padding: 0.75rem; background: var(--bg-card); }
    .grid { display: grid; }
    .grid-2-col { grid-template-columns: 1fr 1fr; }
    .text-center { text-align: center; }
    .bg-dark { background: var(--black-5); }
    .border-none { border: none; }
    .bg-transparent { background: transparent; }
    .border-collapse { border-collapse: collapse; }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    html {
      font-size: 18px;
    }

    body {
      font-family: var(--font-sans);
      background: var(--bg-deep);
      color: var(--text-primary);
      min-height: 100vh;
      line-height: 1.4;
      min-width: var(--min-viewport-width);
    }

    h1, h2, h3, h4, h5, h6 {
      word-spacing: 0.15em;
    }

    h3 {
      text-transform: uppercase;
      letter-spacing: -0.01em;
    }

    /* Layout: Sidebar + Content */
    .app-layout {
      display: flex;
      min-height: 100vh;
    }

    /* Sidebar */
    .sidebar {
      width: 240px;
      flex-shrink: 0;
      background: var(--bg-deep);
      border-right: var(--swiss-border);
      position: sticky;
      top: 0;
      height: 100vh;
      overflow-y: auto;
      padding: 1rem 0;
      display: flex;
      flex-direction: column;
    }

    .sidebar-header {
      padding: 0 1rem 1.5rem;
      border-bottom: var(--swiss-border);
      margin-bottom: 1.5rem;
    }

    .sidebar-header h1 {
      font-size: 1.3rem;
      font-weight: 900;
      letter-spacing: -0.02em;
      word-spacing: 0.25em;
      text-transform: uppercase;
      line-height: 0.9;
      margin-bottom: 0.4rem;
      color: var(--text-primary);
    }

    .sidebar-header p {
      font-size: 0.65rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      word-spacing: 0.1em;
      font-weight: 700;
    }

    .sidebar-footer {
      margin-top: auto;
      padding: 1rem;
      border-top: var(--swiss-border);
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .sidebar-footer a {
      color: var(--text-secondary);
      text-decoration: none;
      font-weight: 600;
    }

    .sidebar-footer a:hover {
      color: var(--accent-primary);
    }

    .sidebar-footer .copyright {
      margin-top: 0.5rem;
      font-size: 0.65rem;
    }

    /* Navigation Tabs */
    .tab-nav {
      display: flex;
      flex-direction: column;
      gap: 0;
      padding: 0;
    }

    .tab-group {
      margin-bottom: 1rem;
    }

    .tab-group-label {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.6rem;
      font-weight: 900;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.1em;
      word-spacing: 0.1em;
      padding: 0.4rem 1rem;
      border-bottom: 1px solid var(--border-subtle);
    }

    .tab-group-label .group-num {
      color: var(--accent-primary);
    }

    .tab-group-buttons {
      display: flex;
      flex-direction: column;
    }

    .tab-btn {
      display: flex;
      align-items: center;
      gap: 0.6rem;
      padding: 0.6rem 1rem;
      background: transparent;
      border: none;
      border-bottom: 1px solid var(--border-subtle);
      color: var(--text-secondary);
      font-family: inherit;
      font-size: 0.75rem;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      word-spacing: 0.1em;
      cursor: pointer;
      transition: all 0.2s;
      text-align: left;
      width: 100%;
    }

    .tab-btn:hover {
      background: var(--bg-panel);
      color: var(--text-primary);
    }

    .tab-btn.active {
      background: var(--text-primary);
      color: var(--bg-deep);
    }

    .tab-btn .icon {
      font-size: 0.9rem;
      width: 1.1rem;
      text-align: center;
    }

    /* Main Content */
    .main-content {
      flex: 1;
      padding: 2rem 3rem;
      width: 100%;
      min-width: 0;
      overflow-y: auto;
      background: var(--bg-deep);
    }

    .main-content > * {
      max-width: var(--max-content-width);
    }

    /* Section Header */
    .section-header {
      margin-bottom: 2rem;
      border-bottom: var(--swiss-thick);
      padding-bottom: 1rem;
    }

    .section-header h2 {
      font-size: 3.5rem;
      font-weight: 900;
      letter-spacing: -0.02em;
      word-spacing: 0.2em;
      text-transform: uppercase;
      line-height: 0.85;
      margin-bottom: 1rem;
    }

    .section-header p {
      font-size: 1.1rem;
      font-weight: 700;
      color: var(--text-secondary);
      max-width: 700px;
      border-left: 6px solid var(--accent-primary);
      padding-left: 1rem;
    }

    /* Cards & Concepts */
    .concept-card {
      border: var(--swiss-border);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
      background: var(--bg-card);
    }

    .concept-card h4 {
      text-transform: uppercase;
      font-weight: 900;
      font-size: 1rem;
      letter-spacing: -0.01em;
      word-spacing: 0.15em;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--accent-primary);
    }

    /* Interactive Well / Workbench */
    .interactive-well {
      background: var(--bg-panel);
      border: var(--swiss-thick);
      padding: 1.5rem;
      margin: 2rem 0;
      position: relative;
    }

    .interactive-well::before {
      content: 'WORKBENCH';
      position: absolute;
      top: -12px;
      left: 1rem;
      background: var(--accent-primary);
      color: var(--bg-deep);
      font-size: 0.65rem;
      font-weight: 900;
      padding: 2px 8px;
      letter-spacing: 0.1em;
      word-spacing: 0.1em;
    }

    /* Forms & Inputs */
    textarea, select, input {
      width: 100%;
      background: var(--bg-deep);
      border: var(--swiss-border);
      color: var(--text-primary);
      padding: 0.75rem;
      font-family: var(--font-mono);
      font-size: 0.9rem;
      outline: none;
    }

    .action-btn {
      background: var(--text-primary);
      color: var(--bg-deep);
      border: none;
      padding: 0.75rem 1.5rem;
      font-family: inherit;
      font-weight: 900;
      text-transform: uppercase;
      letter-spacing: 0.1em;
      cursor: pointer;
      width: 100%;
      transition: transform 0.1s;
    }

    .action-btn:active {
      transform: scale(0.98);
    }

    /* Grid Layouts */
    .grid-2 {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
    }

    .grid-3 {
      display: grid;
      grid-template-columns: 1fr 1fr 1fr;
      gap: 1.25rem;
    }

    /* ═══════════════════════════════════════════════════════════════
       NARROW SCREEN WARNING OVERLAY
       Shows when viewport is narrower than minimum supported width
       ═══════════════════════════════════════════════════════════════ */
    .narrow-screen-warning {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: var(--bg-deep);
      z-index: 10000;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 2rem;
      text-align: center;
    }

    .narrow-screen-warning .warning-icon {
      font-size: 4rem;
      margin-bottom: 1.5rem;
    }

    .narrow-screen-warning h2 {
      font-family: var(--font-sans);
      font-size: 1.75rem;
      font-weight: 800;
      color: var(--text-primary);
      margin-bottom: 1rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .narrow-screen-warning p {
      font-family: var(--font-sans);
      font-size: 1rem;
      color: var(--text-secondary);
      max-width: 400px;
      line-height: 1.6;
      margin-bottom: 1.5rem;
    }

    .narrow-screen-warning .min-width-note {
      font-family: var(--font-mono);
      font-size: 0.9rem;
      color: var(--text-muted);
      padding: 0.75rem 1.25rem;
      background: var(--bg-panel);
      border: var(--swiss-border);
    }

    @media (max-width: 1023px) {
      .narrow-screen-warning {
        display: flex;
      }
      .app-layout {
        display: none;
      }
    }

    /* Tab Animation */
    .tab-section {
      display: none;
      animation: swissFadeIn 0.5s cubic-bezier(0.19, 1, 0.22, 1);
    }

    .tab-section.active {
      display: block;
    }

    @keyframes swissFadeIn {
      from { opacity: 0; transform: translateY(30px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* Custom scrollbar */
    ::-webkit-scrollbar { width: 8px; }
    ::-webkit-scrollbar-track { background: var(--bg-deep); }
    ::-webkit-scrollbar-thumb { background: var(--text-muted); }
    ::-webkit-scrollbar-thumb:hover { background: var(--text-secondary); }

    /* Force Swiss Sharp Corners Everywhere */
    * { border-radius: 0px !important; }


    /* Sub-panel for controls inside a workbench */
    .control-panel-well {
      background: var(--bg-deep);
      padding: 1.5rem;
      margin: 0;
      border: var(--swiss-border);
    }

    .nn-intro-flow {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.75rem;
      flex-wrap: nowrap;
      margin-bottom: 1rem;
    }

    .nn-intro-box {
      flex: 1;
      background: var(--bg-card);
      padding: 0.75rem;
      text-align: center;
      min-width: 0;
      border: var(--swiss-border);
      display: flex;
      flex-direction: column;
      justify-content: center;
      min-height: 100px;
    }

    .nn-intro-box.input-box {
      border: 1px solid var(--accent-cool);
    }

    .nn-intro-box.network-box {
      border: 1px solid var(--accent-secondary);
      background: var(--secondary-10);
    }

    .nn-intro-box.output-box {
      border: 1px solid var(--accent-primary);
    }

    .intro-box-label {
      font-size: 0.6rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      word-spacing: 0.1em;
      margin-bottom: 0.2rem;
    }

    .intro-box-content {
      font-size: 0.8rem;
      color: var(--text-primary);
      line-height: 1.2;
    }

    .intro-box-content strong {
      display: block;
      margin-bottom: 0.1rem;
      font-size: 0.85rem;
    }

    .intro-example {
      font-family: var(--font-mono);
      font-size: 0.65rem;
      color: var(--text-muted);
      display: block;
      margin-top: 0.2rem;
    }

    .nn-intro-arrow {
      font-size: 1rem;
      color: var(--text-muted);
      flex-shrink: 0;
    }

    .nn-intro-note {
      font-size: 0.8rem;
      color: var(--text-secondary);
      text-align: center;
      margin: 0.5rem 0 0;
      line-height: 1.4;
    }

    /* Neural Network Visualization Canvas */
    .nn-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    .nn-canvas-wrapper {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .controls-note {
      font-size: 0.75rem;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
    }

    .nn-output-display {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.4rem;
    }

    .nn-output-display .output-row {
      display: flex;
      align-items: center;
      gap: 0.35rem;
      padding: 0.25rem 0;
    }

    .nn-output-display .output-label {
      font-family: var(--font-mono);
      font-size: 0.7rem;
      min-width: 45px;
    }

    .output-bar-container {
      flex: 1;
      height: 5px;
      background: var(--bg-elevated);
      border-radius: 3px;
      overflow: hidden;
    }

    .output-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 3px;
      transition: width 0.2s ease;
      width: 0%;
    }

    .nn-output-display .output-value {
      font-family: var(--font-mono);
      font-size: 0.7rem;
      min-width: 30px;
      text-align: right;
    }

    .nn-try-this {
      margin-top: 0.6rem;
      padding: 0.4rem 0.5rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.75rem;
      color: var(--text-secondary);
      border-left: 3px solid var(--accent-primary);
      line-height: 1.4;
    }

    .nn-try-this strong {
      color: var(--accent-primary);
    }

    .legend-circle {
      width: 14px;
      height: 14px;
      border-radius: 50% !important;
      background: var(--accent-primary);
      box-shadow: 0 0 6px var(--accent-primary);
    }

    .legend-circle.active {
      background: var(--accent-primary);
    }

    #nn-canvas {
      width: 100%;
      height: 340px;
      display: block;
    }

    .nn-legend {
      display: flex;
      justify-content: center;
      gap: 1.5rem;
      margin-top: 0.75rem;
      padding-top: 0.75rem;
      border-top: 1px solid var(--border-subtle);
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      font-size: 0.85rem;
      color: var(--text-secondary);
    }

    .legend-line {
      width: 25px;
      height: 3px;
      border-radius: 2px;
    }

    .legend-line.positive { background: var(--positive); }
    .legend-line.negative { background: var(--negative); }
    .legend-line.thick { height: 6px; }
    .legend-line.thin { height: 2px; }

    /* Controls Panel */
    .controls-panel {
      background: var(--bg-panel);
      border-radius: var(--radius);
      padding: 0.75rem;
      border: 1px solid var(--border-subtle);
    }

    .controls-panel h3 {
      font-size: 0.95rem;
      font-weight: 600;
      margin-bottom: 0.6rem;
      display: flex;
      align-items: center;
      gap: 0.4rem;
    }

    .control-group {
      margin-bottom: 0.75rem;
    }

    .control-group:last-child {
      margin-bottom: 0;
    }

    .control-group-title {
      font-size: 0.7rem;
      font-weight: 600;
      color: var(--accent-primary);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      word-spacing: 0.1em;
      margin-bottom: 0.4rem;
    }

    .slider-row {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      margin-bottom: 0.4rem;
    }

    .slider-row label {
      flex: 0 0 75px;
      font-size: 0.8rem;
      color: var(--text-secondary);
      font-weight: 500;
    }

    .slider-row input[type="range"] {
      flex: 1;
      height: 5px;
      -webkit-appearance: none;
      appearance: none;
      background: var(--bg-elevated);
      border-radius: 4px;
      outline: none;
      min-width: 70px;
    }

    .slider-row input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 14px;
      height: 14px;
      background: var(--accent-primary);
      border-radius: 50%;
      cursor: pointer;
      box-shadow: 0 0 6px var(--glow-accent);
    }

    .slider-value {
      flex: 0 0 40px;
      text-align: right;
      font-family: var(--font-mono);
      font-size: 0.8rem;
      font-weight: 600;
      color: var(--text-primary);
      background: var(--bg-elevated);
      padding: 0.25rem 0.5rem;
      border-radius: var(--radius-sm);
    }

    /* Output Display */
    .output-display {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      margin-top: 1rem;
      border: 2px solid var(--border-accent);
    }

    .output-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0.5rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .output-row:last-child {
      border-bottom: none;
      padding-bottom: 0;
    }

    .output-row:first-child {
      padding-top: 0;
    }

    .output-label {
      font-size: 0.9rem;
      color: var(--text-secondary);
    }

    .output-value {
      font-family: var(--font-mono);
      font-size: 1.15rem;
      font-weight: 600;
    }

    .output-value.highlight {
      color: var(--accent-primary);
      font-size: 1.4rem;
    }

    /* Tokenizer Section */
    .tokenizer-container {
      width: 100%;
      margin: 0;
    }

    .input-area {
      margin-bottom: 1.5rem;
    }

    .input-area textarea {
      width: 100%;
      min-height: 120px;
      padding: 1.25rem;
      font-family: inherit;
      font-size: 1.2rem;
      background: var(--bg-card);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius);
      color: var(--text-primary);
      resize: vertical;
      transition: border-color 0.2s ease;
    }

    .input-area textarea:focus {
      outline: none;
      border-color: var(--accent-primary);
    }

    .input-area textarea::placeholder {
      color: var(--text-muted);
    }

    .action-btn {
      display: inline-flex;
      align-items: center;
      gap: 0.6rem;
      padding: 0.8rem 1.6rem;
      background: var(--accent-primary);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 700;
      cursor: pointer;
      transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
      border-bottom: 3px solid var(--black-20);
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .action-btn:hover {
      transform: translateY(-2px);
      filter: brightness(1.1);
      box-shadow: 0 4px 12px var(--glow-primary);
    }

    .action-btn:active {
      transform: translateY(1px);
      border-bottom-width: 1px;
    }

    /* Slider refinement */
    .slider-row input[type="range"] {
      flex: 1;
      height: 4px;
      -webkit-appearance: none;
      appearance: none;
      background: var(--bg-deep);
      border-radius: 2px;
      outline: none;
      min-width: 80px;
    }

    .slider-row input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 18px;
      height: 18px;
      background: var(--accent-primary);
      border: 2px solid var(--bg-panel);
      border-radius: 50%;
      cursor: pointer;
      transition: transform 0.1s ease;
    }

    .slider-row input[type="range"]:hover::-webkit-slider-thumb {
      transform: scale(1.1);
    }

    /* Canvas refinement */
    canvas {
      background-image: 
        linear-gradient(var(--black-4) 1px, transparent 1px),
        linear-gradient(90deg, var(--black-4) 1px, transparent 1px);
      background-size: 20px 20px;
      border: 1px solid var(--border-subtle) !important;
    }

    .tokens-display {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      margin-top: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .tokens-display h4 {
      font-size: 0.95rem;
      color: var(--text-secondary);
      margin-bottom: 0.75rem;
      font-weight: 500;
    }

    .tokens-grid {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
    }

    .token-chip {
      display: inline-flex;
      align-items: center;
      gap: 0.4rem;
      padding: 0.3rem 0.6rem;
      background: var(--bg-deep);
      border: 1px solid var(--border-subtle);
      border-left: 3px solid var(--accent-secondary);
      border-radius: var(--radius-sm);
      font-size: 0.9rem;
      transition: all 0.2s ease;
    }

    .token-chip:hover {
      border-color: var(--accent-secondary);
      background: var(--bg-elevated);
    }

    .token-chip .index {
      font-family: var(--font-mono);
      font-size: 0.75rem;
      color: var(--accent-primary);
      font-weight: 600;
    }

    .token-chip .text {
      color: var(--text-primary);
      font-weight: 500;
    }

    .ids-display {
      margin-top: 1rem;
      padding: 1rem;
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      font-family: var(--font-mono);
      font-size: 0.9rem;
      color: var(--text-secondary);
      line-height: 1.6;
      overflow-x: auto;
    }

    /* Embeddings Section */
    .embeddings-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    #embedding-canvas {
      width: 100%;
      height: 450px;
      background: var(--bg-card);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
      cursor: crosshair;
    }

    .word-selector {
      margin-bottom: 1.5rem;
    }

    .word-selector label {
      display: block;
      font-size: 1rem;
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    .word-selector select {
      width: 100%;
      padding: 1rem;
      font-family: inherit;
      font-size: 1.1rem;
      background: var(--bg-card);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      cursor: pointer;
    }

    .word-selector select:focus {
      outline: none;
      border-color: var(--accent-primary);
    }

    .similarity-table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 1rem;
    }

    .similarity-table th,
    .similarity-table td {
      padding: 0.9rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border-subtle);
    }

    .similarity-table th {
      font-size: 0.9rem;
      font-weight: 600;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .similarity-table td {
      font-size: 1.05rem;
    }

    .similarity-table td:first-child {
      font-weight: 600;
      color: var(--text-primary);
    }

    .similarity-table td:last-child {
      font-family: var(--font-mono);
      text-align: right;
    }

    .sim-bar {
      display: inline-block;
      height: 8px;
      border-radius: 4px;
      margin-right: 0.75rem;
      vertical-align: middle;
    }

    /* Attention Section */
    .attention-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    #attention-canvas {
      width: 100%;
      height: 400px;
      background: var(--bg-card);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .attention-weights {
      margin-top: 1.5rem;
    }

    .attention-row {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      margin-bottom: 0.75rem;
    }

    .attention-row .word {
      flex: 0 0 100px;
      font-weight: 600;
      font-size: 1.1rem;
    }

    .attention-row .bar-container {
      flex: 1;
      height: 24px;
      background: var(--bg-elevated);
      border-radius: 12px;
      overflow: hidden;
    }

    .attention-row .bar {
      height: 100%;
      border-radius: 12px;
      transition: width 0.4s ease;
    }

    .attention-row .value {
      flex: 0 0 60px;
      text-align: right;
      font-family: var(--font-mono);
      font-size: 1rem;
      font-weight: 600;
    }

    /* Pre-Training Section */
    .pretrain-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .pretrain-mindblown {
      display: flex;
      gap: 1.25rem;
      align-items: flex-start;
      margin-bottom: 1.5rem;
    }

    .mindblown-icon {
      font-size: 2.5rem;
      flex-shrink: 0;
    }

    .mindblown-content h4 {
      margin: 0 0 0.5rem 0;
      color: var(--accent-primary);
      font-size: 1.1rem;
    }

    .mindblown-content p {
      margin: 0 0 0.75rem 0;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    .mindblown-content p:last-child {
      margin-bottom: 0;
    }

    .pretrain-timeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 1rem;
      flex-wrap: wrap;
    }

    .timeline-stage {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem 1rem;
      text-align: center;
      min-width: 120px;
    }

    .timeline-stage.highlight {
      border-color: var(--accent-primary);
      background: var(--primary-10);
    }

    .timeline-stage .stage-icon {
      font-size: 1.5rem;
      margin-bottom: 0.25rem;
    }

    .timeline-stage .stage-label {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.1rem;
    }

    .timeline-stage .stage-desc {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .timeline-arrow {
      font-size: 1.25rem;
      color: var(--text-muted);
    }

    /* Training Data Section */
    .training-data-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .training-data-section h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .training-data-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .training-examples {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .training-example {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem 1rem;
      border-left: 3px solid var(--accent-cool);
    }

    .example-source {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .example-text {
      font-family: var(--font-mono);
      font-size: 0.85rem;
    }

    .masked-word {
      background: var(--accent-primary);
      color: var(--bg-deep);
      padding: 0.1rem 0.4rem;
      border-radius: 4px;
      font-weight: 600;
    }

    .data-scale-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--text-secondary);
    }

    /* Training Loop Section */
    .training-loop-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .training-loop-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .training-loop-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .training-loop-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .loop-step-container {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-bottom: 1rem;
    }

    .loop-example-card,
    .loop-predictions-card,
    .loop-loss-card,
    .loop-adjust-card {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .loop-step-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.5rem;
    }

    .loop-prompt {
      font-family: var(--font-mono);
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .prompt-blank {
      background: var(--accent-warm);
      color: var(--bg-deep);
      padding: 0.1rem 0.5rem;
      border-radius: 4px;
    }

    .loop-answer {
      display: flex;
      flex-direction: column;
      gap: 0.1rem;
    }

    .answer-label {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .answer-token {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-weight: 600;
    }

    .prediction-bars {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
    }

    .pred-row {
      display: flex;
      align-items: center;
      gap: 1rem;
      font-size: 0.75rem;
    }

    .pred-token {
      font-family: var(--font-mono);
      width: 75px;
      flex-shrink: 0;
    }

    .pred-token.correct-highlight {
      color: var(--accent-primary);
    }

    .pred-bar-container {
      flex: 1;
      height: 8px;
      background: var(--bg-card);
      border-radius: 4px;
      overflow: hidden;
    }

    .pred-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 4px;
      transition: width 0.3s ease;
    }

    .pred-prob {
      font-family: var(--font-mono);
      width: 35px;
      text-align: right;
    }

    .pred-feedback {
      font-size: 0.65rem;
      color: var(--accent-warm);
      width: 110px;
      flex-shrink: 0;
    }

    .loss-display {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .loss-formula {
      font-family: var(--font-mono);
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .loss-value {
      font-family: var(--font-mono);
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--accent-warm);
    }

    .loss-interpretation {
      font-size: 0.7rem;
      color: var(--text-muted);
      width: 100%;
    }

    .adjust-explanation {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .adjust-explanation p {
      margin: 0 0 0.25rem 0;
    }

    .adjust-visual {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
      margin-top: 0.5rem;
    }

    .weight-change {
      font-family: var(--font-mono);
      font-size: 0.65rem;
      color: var(--accent-primary);
    }

    .loop-controls {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
    }

    .train-loop-btn {
      padding: 0.5rem 1rem;
      background: var(--accent-primary);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .train-loop-btn:hover {
      transform: translateY(-1px);
    }

    .train-loop-btn.auto {
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      color: var(--text-primary);
    }

    .train-loop-btn.auto.active {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .train-loop-btn.reset {
      background: transparent;
      border: 1px solid var(--text-muted);
      color: var(--text-secondary);
    }

    .loop-stats {
      margin-left: auto;
      font-size: 0.8rem;
      color: var(--text-secondary);
      display: flex;
      gap: 1rem;
    }

    .loop-stats strong {
      color: var(--accent-primary);
      font-family: var(--font-mono);
    }

    /* Mini Training Demo (in deep dive) */
    .mini-training-demo {
      display: grid;
      grid-template-columns: 1.5fr 1fr;
      gap: 1rem;
      margin: 1rem 0;
    }

    @media (max-width: 700px) {
      .mini-training-demo {
        grid-template-columns: 1fr;
      }
    }

    .mini-canvas-container {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
      overflow: hidden;
    }

    #training-canvas {
      width: 100%;
      height: 200px;
      display: block;
    }

    .mini-training-controls {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .mini-metrics {
      display: flex;
      gap: 0.5rem;
    }

    .mini-metric {
      flex: 1;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      text-align: center;
    }

    .mini-metric .label {
      font-size: 0.65rem;
      color: var(--text-muted);
      display: block;
    }

    .mini-metric .value {
      font-family: var(--font-mono);
      font-size: 0.9rem;
      font-weight: 600;
      color: var(--accent-primary);
    }

    .mini-metric.loss .value {
      color: var(--accent-warm);
    }

    .mini-buttons {
      display: flex;
      gap: 0.5rem;
    }

    .mini-btn {
      flex: 1;
      padding: 0.4rem 0.5rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.75rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .mini-btn:hover {
      border-color: var(--accent-primary);
    }

    .mini-btn.active {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .mini-epoch {
      font-size: 0.75rem;
      color: var(--text-secondary);
      text-align: center;
    }

    .mini-demo-note {
      font-size: 0.8rem;
      color: var(--text-muted);
      text-align: center;
      margin-top: 0.5rem;
    }

    /* Deep Dive: What Emerges */
    .emerges-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 0.75rem;
      margin: 1rem 0;
    }

    @media (max-width: 600px) {
      .emerges-grid {
        grid-template-columns: 1fr;
      }
    }

    .emerges-item {
      display: flex;
      gap: 0.75rem;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .emerges-icon {
      font-size: 1.25rem;
      flex-shrink: 0;
    }

    .emerges-item strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.2rem;
    }

    .emerges-item p {
      font-size: 0.75rem;
      color: var(--text-secondary);
      margin: 0;
    }

    .emerges-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Backpropagation Section */
    .backprop-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .backprop-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .backprop-section > p {
      color: var(--text-secondary);
      margin-bottom: 1.25rem;
    }

    .backprop-visual {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .backprop-network {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 1rem;
    }

    .backprop-stage {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .stage-title {
      font-weight: 600;
      font-size: 0.85rem;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .stage-desc {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
    }

    .network-mini {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.25rem;
      padding: 0.5rem 0;
    }

    .layer-col {
      display: flex;
      flex-direction: column;
      gap: 1.25rem;
      align-items: center;
    }

    .connection-col {
      width: 40px;
      height: 80px;
    }

    .conn-svg {
      width: 100%;
      height: 100%;
    }

    .mini-node {
      width: 28px;
      height: 28px;
      border-radius: 50% !important;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.55rem;
      font-family: var(--font-mono);
      position: relative;
    }

    .mini-node.input-node {
      background: var(--secondary-15);
      border: 2px solid var(--color-blue);
    }

    .mini-node.hidden-node {
      background: var(--gray-30);
      border: 2px solid var(--color-gray-dark);
    }

    .mini-node.output-node {
      background: var(--primary-15);
      border: 2px solid var(--color-red);
    }

    .mini-node .node-label {
      color: var(--text-primary);
      font-weight: 500;
    }

    .mini-node.blamed {
      box-shadow: 0 0 8px var(--glow-warm);
    }

    .mini-node .blame-amount {
      position: absolute;
      top: -14px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 0.55rem;
      font-weight: 700;
      color: var(--color-yellow);
      white-space: nowrap;
    }

    .stage-result {
      font-size: 0.7rem;
      color: var(--text-secondary);
      text-align: center;
      margin-top: 0.5rem;
      padding-top: 0.5rem;
      border-top: 1px solid var(--border-subtle);
    }

    .loss-calc-visual {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
      padding: 0.5rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .loss-target,
    .loss-actual {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .loss-result {
      font-size: 0.8rem;
      color: var(--accent-warm);
      padding-top: 0.4rem;
      border-top: 1px dashed var(--border-subtle);
    }

    .weight-updates {
      display: flex;
      flex-direction: column;
      gap: 0.3rem;
    }

    .weight-update-row {
      display: flex;
      align-items: center;
      gap: 0.25rem;
      font-family: var(--font-mono);
      font-size: 0.65rem;
      padding: 0.2rem 0.4rem;
      background: var(--bg-card);
      border-radius: 4px;
    }

    .weight-update-row.ellipsis {
      justify-content: center;
      color: var(--text-muted);
      font-style: italic;
    }

    .weight-name {
      color: var(--text-secondary);
      flex: 1;
    }

    .weight-old {
      color: var(--text-muted);
    }

    .weight-arrow {
      color: var(--accent-primary);
    }

    .weight-new {
      color: var(--accent-primary);
    }

    .backprop-key-insight {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--text-secondary);
      border-left: 3px solid var(--accent-warm);
    }

    .backprop-key-insight strong {
      color: var(--accent-warm);
    }

    /* Math Intuition */
    .math-intuition {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin: 1rem 0;
    }

    .math-block {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .math-question {
      font-size: 0.85rem;
      color: var(--text-primary);
      font-weight: 500;
    }

    .math-answer {
      font-size: 0.8rem;
      color: var(--text-secondary);
      padding-left: 1rem;
      border-left: 2px solid var(--accent-primary);
    }

    /* Training Changes Visual */
    .training-changes {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .change-item {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
    }

    .change-before,
    .change-after {
      flex: 1;
      min-width: 150px;
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
    }

    .change-before {
      background: var(--negative-10);
      border: 1px solid var(--negative-30);
    }

    .change-after {
      background: var(--primary-10);
      border: 1px solid var(--border-primary);
    }

    .change-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      text-transform: uppercase;
      display: block;
    }

    .change-desc {
      font-size: 0.8rem;
    }

    .change-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Does/Doesn't Section */
    .does-doesnt {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin: 1rem 0;
    }

    @media (max-width: 600px) {
      .does-doesnt {
        grid-template-columns: 1fr;
      }
    }

    .does,
    .doesnt {
      padding: 0.75rem;
      border-radius: var(--radius-sm);
    }

    .does {
      background: var(--primary-10);
      border: 1px solid var(--border-primary);
    }

    .doesnt {
      background: var(--negative-10);
      border: 1px solid var(--negative-30);
    }

    .does-header,
    .doesnt-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .does-header {
      color: var(--accent-primary);
    }

    .doesnt-header {
      color: var(--negative);
    }

    .does ul,
    .doesnt ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.8rem;
    }

    .does li,
    .doesnt li {
      margin-bottom: 0.25rem;
    }

    /* Fine-Tuning Section */
    .ft-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-gap-visual {
      display: flex;
      align-items: stretch;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }

    .gap-side {
      flex: 1;
      min-width: 200px;
      max-width: 280px;
      padding: 1rem;
      border-radius: var(--radius);
      text-align: center;
    }

    .gap-side.pretrained {
      background: var(--gray-15);
      border: 1px solid var(--gray-30);
    }

    .gap-side.finetuned {
      background: var(--primary-10);
      border: 1px solid var(--border-primary);
    }

    .gap-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .gap-icon {
      font-size: 2rem;
      margin-bottom: 0.5rem;
    }

    .gap-desc {
      font-size: 0.8rem;
      color: var(--text-secondary);
      margin-bottom: 0.75rem;
    }

    .gap-list {
      list-style: none;
      padding: 0;
      margin: 0;
      text-align: left;
      font-size: 0.75rem;
    }

    .gap-list li {
      padding: 0.25rem 0;
      padding-left: 1.25rem;
      position: relative;
    }

    .gap-side.pretrained .gap-list li::before {
      content: '○';
      position: absolute;
      left: 0;
      color: var(--text-muted);
    }

    .gap-side.finetuned .gap-list li::before {
      content: '●';
      position: absolute;
      left: 0;
      color: var(--accent-primary);
    }

    .gap-arrow {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 0 0.5rem;
    }

    .gap-arrow span {
      font-size: 0.7rem;
      color: var(--accent-primary);
      font-weight: 600;
      margin-bottom: 0.25rem;
    }

    .arrow-line {
      width: 60px;
      height: 3px;
      background: var(--accent-primary);
      position: relative;
    }

    .arrow-line::after {
      content: '';
      position: absolute;
      right: -4px;
      top: -4px;
      border: 5px solid transparent;
      border-left-color: var(--accent-primary);
    }

    /* Before/After Example */
    .ft-example-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-example-section h3 {
      margin: 0 0 1rem 0;
      font-size: 1.1rem;
    }

    .ft-example-container {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .ft-prompt {
      background: var(--bg-card);
      padding: 0.75rem 1rem;
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-cool);
    }

    .prompt-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .prompt-text {
      font-family: var(--font-mono);
      font-size: 0.9rem;
    }

    .ft-responses {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1rem;
    }

    .ft-response {
      padding: 1rem;
      border-radius: var(--radius-sm);
    }

    .ft-response.before {
      background: var(--negative-8);
      border: 1px solid var(--negative-20);
    }

    .ft-response.after {
      background: var(--primary-8);
      border: 1px solid var(--primary-20);
    }

    .response-header {
      margin-bottom: 0.5rem;
    }

    .response-badge {
      display: inline-block;
      padding: 0.2rem 0.5rem;
      border-radius: 4px;
      font-size: 0.7rem;
      font-weight: 600;
    }

    .response-badge.bad {
      background: var(--negative-15);
      color: var(--negative);
    }

    .response-badge.good {
      background: var(--positive-15);
      color: var(--positive);
    }

    .response-text {
      font-size: 0.85rem;
      line-height: 1.5;
      margin-bottom: 0.5rem;
    }

    .response-note {
      font-size: 0.7rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* What Fine-Tuning Teaches */
    .ft-teaches-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-teaches-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .ft-teaches-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .teaches-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 0.75rem;
    }

    @media (max-width: 1000px) {
      .teaches-grid {
        grid-template-columns: repeat(2, 1fr);
      }
    }

    @media (max-width: 600px) {
      .teaches-grid {
        grid-template-columns: 1fr;
      }
    }

    .teaches-card {
      display: flex;
      gap: 0.75rem;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
    }

    .teaches-icon {
      font-size: 1.5rem;
      flex-shrink: 0;
    }

    .teaches-content h4 {
      margin: 0 0 0.25rem 0;
      font-size: 0.85rem;
    }

    .teaches-content p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* RLHF Section */
    .rlhf-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .rlhf-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .rlhf-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .rlhf-loop {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 1rem;
    }

    .rlhf-step {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .rlhf-step .step-number {
      width: 28px;
      height: 28px;
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.9rem;
      margin-bottom: 0.5rem;
    }

    .rlhf-step .step-content h4 {
      margin: 0 0 0.25rem 0;
      font-size: 0.9rem;
    }

    .rlhf-step .step-content > p {
      margin: 0 0 0.5rem 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .step-example {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      font-size: 0.7rem;
    }

    .example-prompt {
      font-family: var(--font-mono);
      color: var(--text-primary);
      margin-bottom: 0.4rem;
    }

    .example-responses {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .resp-a, .resp-b {
      padding: 0.25rem 0.4rem;
      border-radius: 4px;
    }

    .resp-a {
      background: var(--negative-10);
      color: var(--text-secondary);
    }

    .resp-b {
      background: var(--primary-10);
      color: var(--text-secondary);
    }

    .human-choice {
      display: flex;
      gap: 0.5rem;
      align-items: center;
    }

    .choice-label {
      color: var(--text-muted);
    }

    .choice-winner {
      color: var(--accent-primary);
      font-weight: 600;
    }

    .choice-reason {
      color: var(--text-muted);
      font-style: italic;
      margin-top: 0.25rem;
    }

    .reward-model {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .reward-insight {
      color: var(--accent-primary);
      font-style: italic;
    }

    .weight-update-note {
      color: var(--text-muted);
      font-style: italic;
    }

    .rlhf-repeat {
      text-align: center;
      margin-top: 1rem;
      padding: 0.5rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--accent-primary);
    }

    /* Rater Demo */
    .rater-demo-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .rater-demo-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .rater-demo-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .rater-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .rater-prompt {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      margin-bottom: 1rem;
    }

    .rater-prompt-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .rater-prompt-text {
      font-family: var(--font-mono);
      font-size: 0.9rem;
    }

    .rater-choices {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1rem;
      margin-bottom: 1rem;
    }

    .rater-choice {
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      cursor: pointer;
      transition: all 0.2s ease;
      text-align: left;
      font-family: inherit;
    }

    .rater-choice:hover {
      border-color: var(--accent-primary);
    }

    .rater-choice.selected {
      border-color: var(--accent-primary);
      background: var(--primary-10);
    }

    .rater-choice.not-selected {
      opacity: 0.5;
    }

    .choice-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
      color: var(--text-primary);
    }

    .choice-text {
      font-size: 0.8rem;
      color: var(--text-secondary);
      line-height: 1.5;
    }

    .rater-feedback {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin-bottom: 1rem;
      min-height: 60px;
      font-size: 0.85rem;
    }

    .rater-feedback.show {
      border-left: 3px solid var(--accent-primary);
    }

    .rater-stats {
      display: flex;
      align-items: center;
      justify-content: space-between;
      font-size: 0.85rem;
    }

    .rater-next-btn {
      padding: 0.5rem 1rem;
      background: var(--accent-primary);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .rater-next-btn:hover {
      transform: translateY(-1px);
    }

    .rater-next-btn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
      transform: none;
    }

    /* Deep Dive: Training Stages */
    .training-stages {
      display: flex;
      align-items: stretch;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: nowrap;
      margin: 1rem 0;
    }

    .stage-block {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
      flex: 1;
      max-width: 253px;
    }

    .stage-num {
      width: 24px;
      height: 24px;
      background: var(--accent-secondary);
      color: white;
      border-radius: 4px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.8rem;
      flex-shrink: 0;
    }

    .stage-info h5 {
      margin: 0 0 0.3rem 0;
      font-size: 0.85rem;
    }

    .stage-info p {
      margin: 0;
      font-size: 0.8rem;
      color: var(--text-secondary);
      line-height: 1.4;
    }

    .stage-data {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-top: auto;
      padding-top: 0.5rem;
    }

    .stage-arrow {
      color: var(--text-muted);
      font-size: 1.25rem;
      align-self: center;
      flex-shrink: 0;
    }

    /* Approaches Grid */
    .approaches-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .approach-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 1px solid var(--border-subtle);
    }

    .approach-name {
      font-family: var(--font-mono);
      font-weight: 700;
      color: var(--accent-primary);
      font-size: 0.9rem;
    }

    .approach-full {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.4rem;
    }

    .approach-desc {
      font-size: 0.75rem;
      color: var(--text-secondary);
      margin-bottom: 0.4rem;
    }

    .approach-used {
      font-size: 0.65rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* Reward Model Visual */
    .reward-model-visual {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin: 1rem 0;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .rm-input, .rm-model, .rm-output {
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
      text-align: center;
    }

    .rm-input {
      background: var(--secondary-15);
      border: 1px solid var(--border-secondary);
    }

    .rm-model {
      background: var(--purple-15);
      border: 1px solid var(--purple-30);
    }

    .rm-output {
      background: var(--primary-15);
      border: 1px solid var(--border-primary);
    }

    .rm-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.2rem;
    }

    .rm-content {
      font-size: 0.8rem;
      font-weight: 500;
    }

    .rm-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Challenges List */
    .challenges-list {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      margin: 1rem 0;
    }

    .challenge-item {
      padding: 0.5rem 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-warm);
    }

    .challenge-item strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.2rem;
    }

    .challenge-item p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Tradeoff Visual */
    .tradeoff-visual {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      margin: 1rem 0;
    }

    .tradeoff-item {
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }

    .tradeoff-label {
      width: 100px;
      font-size: 0.75rem;
      flex-shrink: 0;
    }

    .tradeoff-bar {
      flex: 1;
      height: 12px;
      background: var(--bg-card);
      border-radius: 6px;
      overflow: hidden;
    }

    .bar-fill {
      height: 100%;
      border-radius: 6px;
    }

    .bar-fill.pretrain {
      background: var(--text-muted);
    }

    .bar-fill.finetune {
      background: var(--accent-secondary);
    }

    .bar-fill.helpful {
      background: var(--accent-primary);
    }

    .bar-fill.safe {
      background: var(--accent-cool);
    }

    .tradeoff-note {
      font-size: 0.65rem;
      color: var(--text-muted);
      width: 150px;
    }

    /* Complete Pipeline */
    .complete-pipeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.25rem;
      flex-wrap: wrap;
      margin: 1rem 0;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .pipeline-stage {
      text-align: center;
      padding: 0.5rem;
      min-width: 70px;
    }

    .pipeline-stage.highlight {
      background: var(--primary-15);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-primary);
    }

    .pipe-icon {
      font-size: 1.25rem;
      margin-bottom: 0.25rem;
    }

    .pipe-name {
      font-size: 0.7rem;
      font-weight: 600;
      margin-bottom: 0.1rem;
    }

    .pipe-desc {
      font-size: 0.6rem;
      color: var(--text-muted);
    }

    .pipe-arrow {
      color: var(--text-muted);
      font-size: 0.9rem;
    }

    /* Legacy Training Section (keeping for reference) */
    .training-container {
      display: grid;
      grid-template-columns: 1.2fr 1fr;
      gap: 2rem;
    }

    @media (max-width: 1000px) {
      .training-container {
        grid-template-columns: 1fr;
      }
    }

    .training-controls {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .metric-card {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem 1.5rem;
      border: 1px solid var(--border-subtle);
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .metric-card .label {
      font-size: 1rem;
      color: var(--text-secondary);
    }

    .metric-card .value {
      font-family: var(--font-mono);
      font-size: 1.5rem;
      font-weight: 600;
      color: var(--accent-primary);
    }

    .metric-card.loss .value {
      color: var(--accent-warm);
    }

    .step-btn {
      padding: 1.25rem 2rem;
      background: linear-gradient(135deg, var(--accent-warm) 0%, var(--accent-pink) 100%);
      border: none;
      border-radius: var(--radius);
      color: white;
      font-family: inherit;
      font-size: 1.2rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
      margin-top: 0.5rem;
    }

    .step-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 10px 30px var(--warm-30);
    }

    .auto-train-btn {
      padding: 1rem 1.5rem;
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
    }

    .auto-train-btn:hover {
      border-color: var(--accent-primary);
    }

    .auto-train-btn.active {
      background: var(--accent-primary);
      border-color: var(--accent-primary);
      color: var(--bg-deep);
    }

    .reset-btn {
      padding: 1rem 1.5rem;
      background: transparent;
      border: 2px solid var(--negative);
      border-radius: var(--radius);
      color: var(--negative);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
    }

    .reset-btn:hover {
      background: var(--negative);
      color: white;
    }

    .epoch-counter {
      text-align: center;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      font-size: 1rem;
      color: var(--text-secondary);
    }

    .epoch-counter strong {
      color: var(--text-primary);
      font-family: var(--font-mono);
    }

    /* Explanation boxes */
    .explanation {
      background: var(--bg-card);
      border: 2px solid var(--accent-primary);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-top: 1.5rem;
    }

    .explanation h4 {
      font-size: 1.1rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
      color: var(--accent-primary);
    }

    .explanation p {
      font-size: 1.05rem;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    /* Formula display */
    .formula-box {
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      padding: 1.25rem 1.5rem;
      font-family: var(--font-mono);
      font-size: 1rem;
      color: var(--text-secondary);
      margin: 1rem 0;
      overflow-x: auto;
      line-height: 1.8;
    }

    .formula-box .highlight {
      color: var(--accent-primary);
    }

    .formula-box .warm {
      color: var(--accent-warm);
    }

    /* Deep Dive Sections */
    .deep-dive {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 2px solid var(--border-subtle);
    }

    .deep-dive-title {
      font-size: 1.5rem;
      font-weight: 700;
      margin-bottom: 2rem;
      color: var(--text-primary);
      text-align: center;
    }

    .concept-card {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
      margin-bottom: 1.5rem;
    }

    .concept-card h4 {
      font-size: 1.25rem;
      font-weight: 600;
      margin-bottom: 1rem;
      color: var(--accent-primary);
    }

    .concept-card p {
      font-size: 1.05rem;
      line-height: 1.7;
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .concept-card p:last-child {
      margin-bottom: 0;
    }

    .concept-list {
      list-style: none;
      padding: 0;
      margin: 1rem 0;
    }

    .concept-list li {
      padding: 0.75rem 0 0.75rem 2rem;
      position: relative;
      font-size: 1.05rem;
      color: var(--text-secondary);
      border-bottom: 1px solid var(--border-subtle);
    }

    .concept-list li:last-child {
      border-bottom: none;
    }

    .concept-list li::before {
      content: counter(concept-step);
      counter-increment: concept-step;
      position: absolute;
      left: 0;
      width: 1.5rem;
      height: 1.5rem;
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-radius: 50%;
      font-size: 0.85rem;
      font-weight: 600;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .concept-list {
      counter-reset: concept-step;
    }

    .analogy-box {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1.5rem 0;
    }

    .analogy-item {
      display: flex;
      gap: 1rem;
      padding: 1rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .analogy-item:last-child {
      border-bottom: none;
      padding-bottom: 0;
    }

    .analogy-item:first-child {
      padding-top: 0;
    }

    .analogy-icon {
      font-size: 1.5rem;
      flex-shrink: 0;
    }

    .analogy-item strong {
      color: var(--text-primary);
      display: block;
      margin-bottom: 0.25rem;
    }

    .analogy-item p {
      margin: 0;
      font-size: 0.95rem;
    }

    /* Black Box Visual */
    .black-box-container {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 800px) {
      .black-box-container {
        grid-template-columns: 1fr;
      }
    }

    .box-side {
      background: var(--bg-card);
      padding: 1.25rem;
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .box-side-label {
      font-size: 0.7rem;
      font-weight: 700;
      color: var(--accent-primary);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .code-snippet {
      font-family: var(--font-mono);
      font-size: 0.75rem;
      color: var(--accent-cool);
      line-height: 1.4;
      background: var(--bg-deep);
      padding: 1rem;
      border-radius: var(--radius-sm);
      min-height: 120px;
    }

    .weights-grid-mini {
      display: grid;
      grid-template-columns: repeat(8, 1fr);
      gap: 4px;
      background: var(--bg-deep);
      padding: 1rem;
      border-radius: var(--radius-sm);
      min-height: 120px;
    }

    .weight-dot {
      aspect-ratio: 1;
      border-radius: 2px;
      background: var(--text-muted);
      opacity: 0.3;
    }

    .weight-dot.active-pos { background: var(--accent-primary); opacity: 0.8; }
    .weight-dot.active-neg { background: var(--negative); opacity: 0.8; }

    /* Hierarchy Visual */
    .hierarchy-container {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: var(--bg-deep);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .hierarchy-level {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 0.75rem 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border-left: 4px solid var(--text-muted);
      transition: all 0.2s ease;
    }

    .hierarchy-level:hover {
      transform: translateX(5px);
      border-left-color: var(--accent-primary);
      background: var(--bg-card);
    }

    .level-icon {
      font-size: 1.25rem;
      min-width: 30px;
      text-align: center;
    }

    .level-content {
      flex: 1;
    }

    .level-title {
      font-weight: 600;
      font-size: 0.9rem;
      margin-bottom: 0.15rem;
      color: var(--text-primary);
    }

    .level-desc {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .hierarchy-arrow {
      text-align: center;
      color: var(--text-muted);
      font-size: 0.8rem;
      line-height: 1;
      margin: -0.25rem 0;
    }

    /* Scale Comparison */
    .scale-comparison {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .scale-comparison {
        grid-template-columns: repeat(2, 1fr);
      }
    }

    .scale-item {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
      border: 1px solid var(--border-subtle);
    }

    .scale-number {
      font-family: var(--font-mono);
      font-size: 1.75rem;
      font-weight: 700;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .scale-label {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Experiment Box */
    .experiment-box {
      background: var(--bg-card);
      border: 2px solid var(--accent-secondary);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1rem 0;
    }

    .experiment-box p {
      margin-bottom: 0.75rem;
    }

    .experiment-box p:last-child {
      margin-bottom: 0;
    }

    .experiment-box ul {
      margin: 0.5rem 0;
      padding-left: 1.5rem;
    }

    .experiment-box li {
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    /* Comparison Table */
    .comparison-table {
      border-radius: var(--radius);
      overflow: hidden;
      margin: 1.5rem 0;
    }

    .comparison-row {
      display: grid;
      grid-template-columns: 1fr 1.5fr 2fr;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-bottom: 1px solid var(--border-subtle);
    }

    .comparison-row.header {
      background: var(--bg-elevated);
      font-weight: 600;
      color: var(--text-muted);
      font-size: 0.85rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .comparison-row.highlight {
      background: var(--primary-10);
      border-color: var(--border-accent);
    }

    .comparison-row:last-child {
      border-bottom: none;
    }

    /* Token Evolution */
    .token-evolution {
      display: flex;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .evolution-step {
      text-align: center;
    }

    .step-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .step-tokens {
      display: flex;
      gap: 0.25rem;
    }

    .evo-token {
      padding: 0.4rem 0.6rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: 4px;
      font-family: var(--font-mono);
      font-size: 0.9rem;
    }

    .evo-token.merged {
      background: var(--primary-20);
      border-color: var(--accent-primary);
    }

    .evo-token.final {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .evolution-arrow {
      color: var(--text-muted);
      padding: 0 0.5rem;
    }

    /* Vocab Table */
    .vocab-table {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 0.75rem;
      margin: 0.75rem 0;
    }

    .vocab-row {
      display: grid;
      grid-template-columns: 70px 1fr 1fr;
      gap: 0.75rem;
      padding: 0.4rem 0;
      border-bottom: 1px solid var(--border-subtle);
      align-items: center;
    }

    .vocab-row:last-child {
      border-bottom: none;
    }

    .vocab-id {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-size: 0.85rem;
    }

    .vocab-token {
      font-family: var(--font-mono);
      font-size: 0.9rem;
    }

    .vocab-note {
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    /* Token Cost */
    .token-cost-example {
      display: grid;
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .cost-item {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0.75rem 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .cost-text {
      color: var(--text-secondary);
    }

    .cost-tokens {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Real Vector Display */
    .real-vector-display {
      margin: 1.5rem 0;
    }

    .real-vector-grid {
      display: grid;
      grid-template-columns: repeat(16, 1fr);
      gap: 3px;
      margin-bottom: 1rem;
    }

    .vector-cell {
      aspect-ratio: 1;
      border-radius: 3px;
      position: relative;
    }

    .vector-cell:hover::after {
      content: attr(data-value);
      position: absolute;
      bottom: 100%;
      left: 50%;
      transform: translateX(-50%);
      background: var(--bg-deep);
      color: var(--text-primary);
      padding: 0.25rem 0.5rem;
      border-radius: 4px;
      font-size: 0.75rem;
      white-space: nowrap;
      z-index: 10;
    }

    .vector-stats {
      display: flex;
      justify-content: center;
      gap: 2rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .stat {
      text-align: center;
    }

    .stat-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      display: block;
    }

    .stat-value {
      font-family: var(--font-mono);
      font-size: 1.1rem;
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Dimension Examples */
    .dimension-examples {
      display: grid;
      gap: 1rem;
      margin: 1.5rem 0;
    }

    .dim-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem 1.25rem;
    }

    .dim-header {
      display: flex;
      justify-content: space-between;
      margin-bottom: 0.75rem;
    }

    .dim-num {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-weight: 600;
    }

    .dim-might {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .dim-spectrum {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 0.5rem;
    }

    .spectrum-end {
      font-size: 0.8rem;
      color: var(--text-muted);
      white-space: nowrap;
    }

    .spectrum-bar {
      flex: 1;
      height: 8px;
      background: linear-gradient(to right, var(--accent-cool), var(--bg-elevated), var(--accent-warm));
      border-radius: 4px;
      position: relative;
    }

    .spectrum-marker {
      position: absolute;
      top: -4px;
      width: 16px;
      height: 16px;
      background: var(--text-primary);
      border-radius: 50%;
      transform: translateX(-50%);
      border: 2px solid var(--bg-card);
    }

    .dim-examples-list {
      font-size: 0.85rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* Similarity Visual */
    .similarity-visual {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .similarity-visual {
        grid-template-columns: 1fr;
      }
    }

    .sim-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
    }

    .sim-arrows {
      height: 80px;
      position: relative;
      margin-bottom: 1rem;
    }

    .sim-arrows .arrow {
      position: absolute;
      bottom: 50%;
      left: 50%;
      width: 60px;
      height: 3px;
      background: var(--accent-primary);
      transform-origin: left center;
    }

    .sim-arrows .arrow::after {
      content: '';
      position: absolute;
      right: -5px;
      top: -4px;
      border: 5px solid transparent;
      border-left-color: var(--accent-primary);
    }

    .high-sim .arrow1 { transform: rotate(-20deg); }
    .high-sim .arrow2 { transform: rotate(-30deg); background: var(--accent-warm); }
    .high-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .medium-sim .arrow1 { transform: rotate(-20deg); }
    .medium-sim .arrow2 { transform: rotate(-70deg); background: var(--accent-warm); }
    .medium-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .low-sim .arrow1 { transform: rotate(-20deg); }
    .low-sim .arrow2 { transform: rotate(-110deg); background: var(--accent-warm); }
    .low-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .sim-label strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .sim-label span {
      display: block;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .sim-desc {
      font-style: italic;
      margin-top: 0.5rem;
    }

    /* Word Algebra */
    .word-algebra {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 2rem;
      margin: 1.5rem 0;
      text-align: center;
    }

    .algebra-equation {
      display: flex;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .algebra-word {
      padding: 0.5rem 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-family: var(--font-mono);
      font-size: 1.1rem;
    }

    .algebra-word.result {
      background: var(--accent-primary);
      color: var(--bg-deep);
      font-weight: 600;
    }

    .algebra-op {
      font-size: 1.5rem;
      color: var(--text-muted);
    }

    .algebra-explanation {
      color: var(--text-muted);
      font-size: 0.95rem;
    }

    .more-algebra {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 1rem;
      margin-top: 1rem;
    }

    .algebra-mini {
      padding: 0.5rem 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      font-family: var(--font-mono);
      font-size: 0.9rem;
      color: var(--text-secondary);
    }

    /* Attention Example Sentence */
    .attention-example-sentence {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      justify-content: center;
      padding: 1.5rem;
      background: var(--bg-card);
      border-radius: var(--radius);
      margin: 1rem 0;
    }

    .att-word {
      padding: 0.5rem 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 1.1rem;
    }

    .att-word.highlighted {
      background: var(--positive-30);
      border: 2px solid var(--positive);
    }

    .att-word.query {
      background: var(--primary-30);
      border: 2px solid var(--accent-primary);
    }

    /* QKV Explanation */
    .qkv-explanation {
      display: grid;
      gap: 1rem;
      margin: 1.5rem 0;
    }

    .qkv-role {
      display: flex;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .qkv-icon {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.5rem;
      font-weight: 700;
      flex-shrink: 0;
    }

    .query-icon { background: var(--primary-20); color: var(--accent-primary); }
    .key-icon { background: var(--warm-20); color: var(--accent-warm); }
    .value-icon { background: var(--secondary-20); color: var(--accent-secondary); }

    .qkv-content strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .qkv-content p {
      margin: 0;
      font-size: 0.95rem;
    }

    .qkv-example {
      color: var(--text-muted);
      font-style: italic;
      margin-top: 0.25rem;
    }

    /* Multihead Visual */
    .multihead-visual {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .multihead-visual {
        grid-template-columns: 1fr;
      }
    }

    .head-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .head-label {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-weight: 600;
      margin-bottom: 0.25rem;
    }

    .head-focus {
      font-size: 0.85rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .head-pattern {
      font-size: 0.9rem;
      color: var(--text-secondary);
      font-style: italic;
    }

    /* Timeline */
    .timeline-mini {
      margin: 1.5rem 0;
    }

    .timeline-item {
      display: flex;
      gap: 1rem;
      padding: 0.75rem 1rem;
      border-left: 3px solid var(--border-subtle);
      margin-left: 1rem;
    }

    .timeline-item.highlight {
      border-left-color: var(--accent-primary);
      background: var(--primary-10);
      border-radius: 0 var(--radius-sm) var(--radius-sm) 0;
    }

    .timeline-year {
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-weight: 600;
      flex-shrink: 0;
      width: 80px;
    }

    .timeline-desc {
      color: var(--text-secondary);
    }

    /* Transformer Architecture Diagram */
    .transformer-diagram {
      display: flex;
      align-items: center;
      gap: 2rem;
      margin: 1.5rem 0;
      flex-wrap: wrap;
      justify-content: center;
    }

    .transformer-block {
      background: var(--bg-card);
      border: 2px dashed var(--border-subtle);
      border-radius: var(--radius);
      padding: 1rem;
      min-width: 260px;
    }

    .block-label {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.75rem;
      text-align: center;
    }

    .block-content {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .transformer-block .layer {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      padding: 0.75rem;
      border-radius: var(--radius-sm);
    }

    .transformer-block .layer-icon {
      font-size: 1.25rem;
    }

    .transformer-block .layer-info {
      display: flex;
      flex-direction: column;
    }

    .transformer-block .layer-info strong {
      font-size: 0.9rem;
    }

    .transformer-block .layer-info span {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .attention-layer {
      background: var(--secondary-15);
      border: 1px solid var(--border-secondary);
    }

    .ffn-layer {
      background: var(--purple-15);
      border: 1px solid var(--purple-30);
    }

    .layer-arrow {
      text-align: center;
      color: var(--text-muted);
      font-size: 1rem;
    }

    .transformer-repeat-arrow {
      display: flex;
      flex-direction: column;
      align-items: center;
      color: var(--text-muted);
      font-size: 0.8rem;
    }

    .repeat-arrow-line {
      width: 60px;
      height: 2px;
      background: var(--border-subtle);
      margin-top: 0.5rem;
      position: relative;
    }

    .repeat-arrow-line::after {
      content: '↻';
      position: absolute;
      right: -10px;
      top: -8px;
      font-size: 1rem;
    }

    /* Full Stack Visualization */
    .transformer-full-stack {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      margin-top: 1.5rem;
    }

    .stack-label {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 1rem;
      text-align: center;
    }

    .stack-content {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0.25rem;
    }

    .stack-layer {
      padding: 0.5rem 1.25rem;
      border-radius: var(--radius-sm);
      text-align: center;
      font-size: 0.85rem;
      display: flex;
      flex-direction: column;
      gap: 0.1rem;
    }

    .stack-layer .layer-ref {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .stack-layer.input-layer {
      background: var(--primary-15);
      border: 1px solid var(--border-primary);
    }

    .stack-layer.output-layer {
      background: var(--primary-15);
      border: 1px solid var(--border-primary);
    }

    .stack-block {
      display: flex;
      gap: 0.5rem;
      align-items: center;
      padding: 0.4rem 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
    }

    .mini-layer {
      padding: 0.3rem 0.6rem;
      border-radius: 4px;
      font-size: 0.7rem;
      font-weight: 500;
    }

    .mini-layer.attention {
      background: var(--secondary-15);
      color: var(--color-blue);
    }

    .mini-layer.ffn {
      background: rgba(168, 85, 247, 0.2);
      color: var(--color-purple);
    }

    .block-number {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-left: 0.5rem;
    }

    .stack-arrow {
      color: var(--text-muted);
      font-size: 0.85rem;
    }

    .stack-dots {
      color: var(--text-muted);
      font-size: 1.2rem;
      line-height: 1;
    }

    .transformer-scale-note {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.8rem;
      color: var(--text-secondary);
      text-align: center;
    }

    /* Pipeline Summary */
    .pipeline-summary {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin: 1.5rem 0;
    }

    .pipeline-step {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      text-align: center;
      min-width: 100px;
    }

    .pipeline-step .step-num {
      display: inline-block;
      width: 20px;
      height: 20px;
      background: var(--accent-primary);
      color: #FFFFFF;
      border-radius: 50%;
      font-size: 0.7rem;
      font-weight: bold;
      line-height: 20px;
      margin-bottom: 0.25rem;
    }

    .pipeline-step strong {
      display: block;
      font-size: 0.8rem;
      margin-bottom: 0.25rem;
    }

    .pipeline-step p {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin: 0;
    }

    .pipeline-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Hiking Visual */
    .hiking-visual {
      margin: 1.5rem 0;
    }

    .mountain-scene {
      height: 180px;
      background: linear-gradient(
        to bottom,
        var(--bg-card) 0%,
        var(--bg-panel) 100%
      );
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      position: relative;
      overflow: hidden;
    }

    .mountain-back {
      position: absolute;
      bottom: 0;
      left: 0;
      right: 0;
      height: 70%;
      background: var(--bg-elevated);
      opacity: 0.6;
      clip-path: polygon(
        0% 100%, 25% 50%, 50% 75%, 75% 40%, 100% 100%
      );
    }

    .mountain-front {
      position: absolute;
      bottom: 0;
      left: 5%;
      right: 5%;
      height: 85%;
      background: var(--bg-panel);
      clip-path: polygon(
        0% 100%,
        15% 35%,
        30% 60%,
        50% 100%,
        65% 45%,
        80% 70%,
        90% 55%,
        100% 100%
      );
    }

    #hiker-icon {
      position: absolute;
      font-size: 1.5rem;
      top: 40%;
      left: 61%;
      z-index: 5;
    }

    .valley-marker {
      position: absolute;
      bottom: 12px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 0.75rem;
      font-weight: 900;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--accent-primary);
      z-index: 10;
    }

    /* Gradient Visual */
    .gradient-visual {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .gradient-visual {
        grid-template-columns: 1fr;
      }
    }

    .gradient-case {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
    }

    .gradient-arrow {
      width: 40px;
      height: 40px;
      margin: 0 auto 1rem;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .gradient-arrow.up {
      background: rgba(198, 40, 40, 0.2);
    }
    .gradient-arrow.up::before {
      content: '↗';
      font-size: 1.5rem;
      color: var(--negative);
    }

    .gradient-arrow.down {
      background: rgba(46, 125, 50, 0.2);
    }
    .gradient-arrow.down::before {
      content: '↘';
      font-size: 1.5rem;
      color: var(--positive);
    }

    .gradient-arrow.flat {
      background: rgba(148, 163, 184, 0.2);
    }
    .gradient-arrow.flat::before {
      content: '→';
      font-size: 1.5rem;
      color: var(--text-muted);
    }

    .gradient-label strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .gradient-label p {
      margin: 0.25rem 0;
      font-size: 0.9rem;
    }

    .gradient-action {
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Learning Rate Comparison */
    .lr-comparison {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .lr-comparison {
        grid-template-columns: 1fr;
      }
    }

    .lr-case {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .lr-viz {
      height: 60px;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      margin-bottom: 0.75rem;
      position: relative;
      overflow: hidden;
    }

    .lr-viz .lr-path {
      position: absolute;
      bottom: 10px;
      left: 10%;
      right: 10%;
      height: 3px;
    }

    .too-high .lr-path {
      background: linear-gradient(90deg, 
        var(--negative) 0%, var(--negative) 20%,
        transparent 20%, transparent 30%,
        var(--negative) 30%, var(--negative) 50%,
        transparent 50%, transparent 60%,
        var(--negative) 60%, var(--negative) 80%
      );
      animation: bounce 1s infinite;
    }

    .just-right .lr-path {
      background: linear-gradient(90deg,
        var(--positive) 0%,
        var(--positive) 100%
      );
      clip-path: polygon(0% 50%, 30% 80%, 60% 30%, 100% 50%);
    }

    .too-low .lr-path {
      background: var(--accent-warm);
      width: 20%;
    }

    .lr-label strong {
      display: block;
      color: var(--text-primary);
      font-size: 0.9rem;
    }

    .lr-label p {
      margin: 0.25rem 0 0;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Backprop Chain */
    .backprop-chain {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius);
      margin: 0.75rem 0;
    }

    .chain-step {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      padding: 0.4rem;
    }

    .chain-label {
      width: 70px;
      font-family: var(--font-mono);
      color: var(--accent-primary);
      font-size: 0.8rem;
    }

    .chain-arrow {
      color: var(--negative);
      font-size: 1.1rem;
    }

    .chain-content {
      color: var(--text-secondary);
      font-size: 0.9rem;
    }

    /* Loss Examples */
    .loss-examples {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 0.75rem;
      margin: 0.75rem 0;
    }

    @media (max-width: 768px) {
      .loss-examples {
        grid-template-columns: 1fr;
      }
    }

    .loss-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 0.75rem;
    }

    .loss-type {
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 0.2rem;
      font-size: 0.9rem;
    }

    .loss-formula {
      font-family: var(--font-mono);
      font-size: 0.85rem;
      color: var(--accent-primary);
      margin-bottom: 0.5rem;
    }

    .loss-use {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Vector Example */
    .vector-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1rem 0;
    }

    .vector-visual {
      text-align: center;
    }

    .vector-label {
      font-size: 0.9rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .vector-numbers {
      font-family: var(--font-mono);
      font-size: 1.5rem;
      color: var(--accent-primary);
      margin-bottom: 0.5rem;
    }

    .vector-meaning {
      display: flex;
      justify-content: center;
      gap: 2rem;
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    /* ============ EMBEDDING INTRO STYLES ============ */
    .embedding-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
      margin-bottom: 2rem;
    }

    .intro-step-container {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1.5rem;
      margin-bottom: 1.5rem;
    }

    @media (max-width: 900px) {
      .intro-step-container {
        grid-template-columns: 1fr;
      }
    }

    .intro-step {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1.25rem;
      display: flex;
      gap: 1rem;
      overflow: hidden;
    }

    .step-number {
      width: 32px;
      height: 32px;
      min-width: 32px;
      border-radius: 50% !important;
      background: var(--accent-primary);
      color: var(--bg-deep);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.95rem;
    }

    .step-content h4 {
      font-size: 0.95rem;
      margin-bottom: 0.4rem;
      color: var(--text-primary);
    }

    .step-content p {
      font-size: 0.85rem;
      color: var(--text-secondary);
      line-height: 1.45;
      margin-bottom: 0.5rem;
    }

    .step-content p:last-child {
      margin-bottom: 0;
    }

    .step-note {
      font-size: 0.8rem !important;
      color: var(--text-muted) !important;
      font-style: italic;
      background: var(--bg-elevated);
      padding: 0.4rem 0.6rem;
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-primary);
    }

    .step-visual {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin: 0.75rem 0;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .word-bubble {
      background: var(--accent-cool);
      color: white;
      padding: 0.4rem 0.75rem;
      border-radius: 20px;
      font-family: var(--font-mono);
      font-size: 0.9rem;
      font-weight: 500;
    }

    .arrow-icon {
      color: var(--text-muted);
      font-size: 1.2rem;
    }

    .question-mark {
      font-size: 1.5rem;
      color: var(--accent-warm);
    }

    .computer-icon {
      font-size: 1.5rem;
    }

    .vector-box {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.4rem 0.6rem;
      font-family: var(--font-mono);
      font-size: 0.75rem;
    }

    .vector-row {
      display: flex;
      justify-content: space-between;
      gap: 0.75rem;
      padding: 0.15rem 0;
    }

    .dim-label {
      color: var(--text-muted);
    }

    .dim-value {
      font-weight: 600;
    }

    .dim-value.high {
      color: var(--accent-primary);
    }

    .dim-value.low {
      color: var(--text-muted);
    }

    .dim-more {
      color: var(--text-muted);
      font-style: italic;
      justify-content: center;
      border-top: 1px solid var(--border-subtle);
      margin-top: 0.2rem;
      padding-top: 0.3rem;
      font-size: 0.7rem;
    }

    .coords-visual {
      flex-direction: column;
      align-items: stretch;
      gap: 0.5rem;
    }

    .coords-example {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      width: 100%;
    }

    .coords-2d, .coords-3d, .coords-nd {
      display: flex;
      flex-direction: column;
      align-items: flex-start;
      gap: 0.25rem;
      padding: 0.5rem 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .coords-label {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .coords-display {
      font-family: var(--font-mono);
      font-size: 0.8rem;
      color: var(--text-primary);
    }

    .coords-point {
      color: var(--accent-primary);
    }

    .cluster-visual {
      flex-direction: row;
      gap: 0.75rem;
      justify-content: center;
      flex-wrap: wrap;
    }

    .cluster-group {
      text-align: center;
      flex: 1;
      min-width: 80px;
    }

    .cluster-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.35rem;
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .cluster-words {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .cluster-word {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      padding: 0.15rem 0.4rem;
      border-radius: var(--radius-sm);
      font-family: var(--font-mono);
      font-size: 0.75rem;
      color: var(--text-primary);
    }

    .cluster-group:nth-child(1) .cluster-word {
      border-color: var(--accent-secondary);
      background: var(--secondary-10);
    }

    .cluster-group:nth-child(2) .cluster-word {
      border-color: var(--accent-warm);
      background: rgba(249, 168, 37, 0.1);
    }

    .cluster-group:nth-child(3) .cluster-word {
      border-color: var(--accent-cool);
      background: var(--secondary-10);
    }

    .intro-summary {
      background: var(--bg-card);
      border: 2px solid var(--accent-cool);
      border-radius: var(--radius-sm);
      padding: 1rem 1.25rem;
      font-size: 0.95rem;
      color: var(--text-primary);
      text-align: left;
    }

    .intro-summary strong {
      color: var(--accent-primary);
    }

    /* Intuition Callout - The key takeaway for each tab */
    .intuition-callout {
      background: var(--primary-8);
      border-left: 4px solid var(--accent-primary);
      padding: 1.25rem 1.5rem;
      margin-bottom: 2rem;
      position: relative;
    }

    .intuition-callout::before {
      content: '💡 THE INTUITION';
      position: absolute;
      top: -10px;
      left: 1rem;
      background: #C5DCF0;
      color: var(--accent-primary);
      font-size: 0.6rem;
      font-weight: 900;
      padding: 2px 8px;
      letter-spacing: 0.1em;
      border-radius: 3px;
    }

    .intuition-callout .intuition-main {
      font-size: 1.05rem;
      font-weight: 600;
      color: var(--text-primary);
      line-height: 1.5;
      margin-bottom: 0.75rem;
    }

    .intuition-callout .intuition-main em {
      color: var(--accent-primary);
      font-style: normal;
    }

    .intuition-callout .intuition-detail {
      font-size: 0.9rem;
      color: var(--text-secondary);
      line-height: 1.5;
    }

    /* ============ INFERENCE TAB STYLES ============ */
    .inference-container {
      margin-bottom: 2rem;
    }

    .inference-grid {
      display: grid;
      grid-template-columns: 1fr 300px;
      gap: 2rem;
    }

    @media (max-width: 1100px) {
      .inference-grid {
        grid-template-columns: 1fr;
      }
    }

    .inference-main {
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
    }

    .inference-prompt-area {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .inference-prompt-label {
      font-size: 0.85rem;
      color: var(--text-muted);
      margin-bottom: 0.4rem;
      display: flex;
      align-items: center;
      gap: 0.4rem;
    }

    .inference-prompt-display {
      font-family: var(--font-mono);
      font-size: 1rem;
      line-height: 1.5;
      color: var(--text-primary);
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      min-height: 50px;
    }

    .inference-prompt-display .generated {
      color: var(--accent-primary);
    }

    .inference-prompt-display .cursor {
      display: inline-block;
      width: 2px;
      height: 1.2em;
      background: var(--accent-primary);
      margin-left: 2px;
      animation: blink 1s step-end infinite;
      vertical-align: text-bottom;
    }

    @keyframes blink {
      50% { opacity: 0; }
    }

    .inference-flow {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
    }

    .inference-flow-title {
      font-size: 0.95rem;
      color: var(--text-muted);
      margin-bottom: 1rem;
      text-align: center;
    }

    .inference-pipeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.4rem;
      flex-wrap: nowrap;
    }

    .pipeline-stage {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0.4rem;
    }

    .pipeline-box {
      padding: 0.75rem 1rem;
      border-radius: var(--radius-sm);
      font-size: 0.9rem;
      font-weight: 500;
      text-align: center;
      min-width: 90px;
      transition: all 0.3s ease;
    }

    .pipeline-box.input {
      background: var(--secondary-10);
      border: 2px solid var(--accent-cool);
      color: var(--accent-cool);
    }

    .pipeline-box.model {
      background: var(--secondary-10);
      border: 2px solid var(--accent-secondary);
      color: var(--text-primary);
      min-width: 120px;
      padding: 1rem;
    }

    .pipeline-box.model .model-icon {
      font-size: 1.25rem;
      margin-bottom: 0.2rem;
    }

    .pipeline-box.output {
      background: var(--primary-10);
      border: 2px solid var(--accent-primary);
      color: var(--accent-primary);
      font-family: var(--font-mono);
    }

    .pipeline-box.active {
      box-shadow: 0 0 20px var(--glow-accent);
      transform: scale(1.05);
    }

    .pipeline-arrow {
      font-size: 1.25rem;
      color: var(--text-muted);
    }

    .pipeline-label {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    /* Token Probabilities */
    .token-probs-area {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .token-probs-title {
      font-size: 0.95rem;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.4rem;
    }

    .token-prob-list {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
    }

    .token-prob-item {
      display: flex;
      align-items: center;
      gap: 0.6rem;
      padding: 0.4rem 0.6rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      transition: all 0.2s ease;
    }

    .token-prob-item.selected {
      background: var(--primary-10);
      border: 1px solid var(--accent-primary);
    }

    .token-prob-item.alternative {
      opacity: 0.7;
    }

    .token-prob-rank {
      font-size: 0.75rem;
      color: var(--text-muted);
      width: 18px;
    }

    .token-prob-token {
      font-family: var(--font-mono);
      font-size: 0.9rem;
      color: var(--text-primary);
      padding: 0.2rem 0.4rem;
      background: var(--bg-elevated);
      border-radius: 4px;
      min-width: 50px;
    }

    .token-prob-bar-container {
      flex: 1;
      height: 6px;
      background: var(--bg-elevated);
      border-radius: 4px;
      overflow: hidden;
    }

    .token-prob-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 4px;
      transition: width 0.3s ease;
    }

    .token-prob-item.alternative .token-prob-bar {
      background: var(--text-muted);
    }

    .token-prob-percent {
      font-family: var(--font-mono);
      font-size: 0.8rem;
      color: var(--text-secondary);
      width: 45px;
      text-align: right;
    }

    /* Controls Panel for Inference */
    .inference-controls {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .inference-controls h3 {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.4rem;
    }

    .temp-viz {
      margin: 0.75rem 0;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .temp-viz-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 0.4rem;
      text-align: center;
    }

    .temp-viz-bar {
      display: flex;
      height: 32px;
      border-radius: var(--radius-sm);
      overflow: hidden;
      gap: 2px;
    }

    .temp-viz-segment {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.65rem;
      font-weight: 600;
      color: var(--text-primary);
      transition: all 0.3s ease;
    }

    .temp-description {
      margin-top: 0.75rem;
      padding: 0.6rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--text-secondary);
      text-align: center;
    }

    /* Generation Controls */
    .generation-buttons {
      display: flex;
      flex-direction: column;
      gap: 0.6rem;
      margin-top: 1rem;
    }

    .gen-btn {
      padding: 1rem 1.5rem;
      border-radius: 0px;
      border: 2px solid var(--text-primary);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 900;
      cursor: pointer;
      transition: all 0.1s;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      text-transform: uppercase;
      letter-spacing: 0.1em;
    }

    .gen-btn.primary {
      background: var(--text-primary);
      color: var(--bg-deep);
    }

    .gen-btn.primary:hover {
      background: var(--accent-primary);
      border-color: var(--accent-primary);
    }

    .gen-btn.secondary {
      background: transparent;
      color: var(--text-primary);
    }

    .gen-btn.secondary:hover {
      background: var(--bg-elevated);
    }

    .gen-btn:active {
      transform: scale(0.98);
    }

    .gen-btn:disabled {
      opacity: 0.3;
      cursor: not-allowed;
      transform: none !important;
    }

    /* Autoregressive Loop Visualization */
    .autoregressive-section {
      background: var(--bg-panel);
      border: var(--swiss-border);
      padding: 1.5rem;
      margin-top: 1.5rem;
    }

    .autoregressive-title {
      font-size: 1.1rem;
      font-weight: 900;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      text-transform: uppercase;
      letter-spacing: -0.5px;
    }

    .loop-visualization {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .loop-step {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border: var(--swiss-border);
      transition: all 0.3s ease;
    }

    .loop-step.active {
      border-color: var(--accent-primary);
      background: rgba(211, 47, 47, 0.05);
    }

    .loop-step.completed {
      border-color: var(--positive);
    }

    .loop-step-number {
      width: 28px;
      height: 28px;
      border-radius: 50% !important;
      background: var(--bg-elevated);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.85rem;
      font-weight: 600;
      color: var(--text-muted);
    }

    .loop-step.active .loop-step-number {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .loop-step.completed .loop-step-number {
      background: var(--positive);
      color: var(--bg-deep);
    }

    .loop-step-content {
      flex: 1;
    }

    .loop-step-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .loop-step-tokens {
      font-family: var(--font-mono);
      font-size: 0.9rem;
      color: var(--text-primary);
    }

    .loop-step-tokens .new-token {
      color: var(--accent-primary);
      font-weight: 600;
    }

    .loop-step-tokens .stop-token {
      color: var(--accent-warm);
      background: var(--warm-20);
      padding: 0.1rem 0.3rem;
      border-radius: 3px;
    }

    .loop-arrow {
      display: flex;
      justify-content: center;
      color: var(--text-muted);
      font-size: 1.2rem;
    }

    .loop-arrow.feedback {
      position: relative;
    }

    .loop-arrow.feedback::before {
      content: '↩ feeds back as input';
      font-size: 0.75rem;
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
      white-space: nowrap;
      color: var(--text-muted);
    }

    .generation-stats {
      margin-top: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      display: flex;
      justify-content: space-around;
      text-align: center;
    }

    .stat-item {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .stat-value {
      font-family: var(--font-mono);
      font-size: 1.5rem;
      color: var(--accent-primary);
    }

    .stat-label {
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    /* ============ CONTEXT & PROMPTING TAB ============ */
    .context-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .context-intro h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .context-intro > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .why-prompts-matter {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
    }

    .prompt-reason {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border-left: 3px solid var(--accent-primary);
    }

    .prompt-reason strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.25rem;
    }

    .prompt-reason p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Context Window Visualizer */
    .context-window-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .context-window-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .context-window-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .context-visualizer {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .context-window-bar {
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      margin-bottom: 0.75rem;
      position: relative;
      min-height: 100px;
      max-height: 400px;
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
      overflow-y: auto;
    }

    .context-segment {
      border-radius: 4px;
      padding: 0.4rem 0.6rem;
      font-size: 0.75rem;
      transition: all 0.3s ease;
    }

    .context-segment.system {
      background: var(--secondary-30);
      border-left: 3px solid var(--accent-secondary);
    }

    .context-segment.user {
      background: var(--secondary-30);
      border-left: 3px solid var(--accent-cool);
    }

    .context-segment.assistant {
      background: var(--primary-30);
      border-left: 3px solid var(--accent-primary);
    }

    .segment-label {
      font-weight: 600;
      font-size: 0.65rem;
      text-transform: uppercase;
      margin-bottom: 0.2rem;
      opacity: 0.7;
    }

    .segment-content {
      font-family: var(--font-mono);
      font-size: 0.7rem;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .context-capacity {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
    }

    .capacity-bar {
      flex: 1;
      height: 8px;
      background: var(--bg-elevated);
      border-radius: 4px;
      overflow: hidden;
    }

    .capacity-fill {
      height: 100%;
      background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary));
      transition: width 0.3s ease;
    }

    .capacity-fill.warning {
      background: linear-gradient(90deg, var(--accent-warm), var(--negative));
    }

    .capacity-text {
      font-family: var(--font-mono);
      font-size: 0.75rem;
      color: var(--text-secondary);
      min-width: 100px;
      text-align: right;
    }

    .context-controls {
      display: flex;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .context-btn {
      padding: 0.4rem 0.8rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.75rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .context-btn:hover {
      border-color: var(--accent-primary);
    }

    .context-btn.primary {
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-color: var(--accent-primary);
    }

    /* System Prompt Explainer Card */
    .system-prompt-card {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .system-prompt-card h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .system-prompt-content {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }

    @media (max-width: 800px) {
      .system-prompt-content {
        grid-template-columns: 1fr;
      }
    }

    .system-what, .system-why {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
    }

    .system-what h4, .system-why h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.9rem;
      color: var(--accent-secondary);
    }

    .system-what ul, .system-why ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.85rem;
      color: var(--text-secondary);
    }

    .system-what li, .system-why li {
      margin-bottom: 0.35rem;
    }

    .system-example {
      margin-top: 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      font-family: var(--font-mono);
      font-size: 0.75rem;
      border-left: 3px solid var(--accent-secondary);
    }

    .system-example-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
      font-family: var(--font-sans);
    }

    /* Token Economics Section */
    .token-economics {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .token-economics h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .token-economics > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .token-types-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 700px) {
      .token-types-grid {
        grid-template-columns: 1fr;
      }
    }

    .token-type-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .token-type-card.input {
      border-top: 3px solid var(--accent-cool);
    }

    .token-type-card.output {
      border-top: 3px solid var(--accent-primary);
    }

    .token-type-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .token-type-header h4 {
      margin: 0;
      font-size: 0.95rem;
    }

    .token-type-icon {
      font-size: 1.2rem;
    }

    .token-type-card p {
      margin: 0 0 0.5rem 0;
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    .token-type-card ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .cost-comparison {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      font-size: 0.8rem;
    }

    .cost-row {
      display: flex;
      justify-content: space-between;
      padding: 0.3rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .cost-row:last-child {
      border-bottom: none;
    }

    .cost-label {
      color: var(--text-secondary);
    }

    .cost-value {
      font-family: var(--font-mono);
      color: var(--accent-primary);
    }

    /* Prompt Comparison Demo */
    .prompt-comparison-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .prompt-comparison-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .prompt-comparison-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .prompt-comparison-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .comparison-toggle {
      display: flex;
      gap: 0.5rem;
      margin-bottom: 1rem;
    }

    .toggle-btn {
      flex: 1;
      padding: 0.6rem 1rem;
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-secondary);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .toggle-btn:hover {
      border-color: var(--accent-primary);
    }

    .toggle-btn.active {
      background: var(--primary-15);
      border-color: var(--accent-primary);
      color: var(--accent-primary);
    }

    .comparison-display {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }

    @media (max-width: 800px) {
      .comparison-display {
        grid-template-columns: 1fr;
      }
    }

    .comparison-side {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .comparison-side h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .prompt-text {
      font-family: var(--font-mono);
      font-size: 0.8rem;
      padding: 0.5rem;
      background: var(--bg-card);
      border-radius: 4px;
      margin-bottom: 0.5rem;
      min-height: 60px;
    }

    .response-quality {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.75rem;
    }

    .quality-indicator {
      width: 8px;
      height: 8px;
      border-radius: 50%;
    }

    .quality-indicator.poor {
      background: var(--negative);
    }

    .quality-indicator.good {
      background: var(--positive);
    }

    .comparison-insight {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-primary);
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    /* Context Forgetting Section */
    .forgetting-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .forgetting-section h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .forgetting-visual {
      display: flex;
      gap: 1rem;
      align-items: stretch;
      margin-bottom: 1rem;
      flex-wrap: wrap;
    }

    .conversation-box {
      flex: 1;
      min-width: 250px;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      position: relative;
    }

    .conversation-box h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.85rem;
    }

    .convo-messages {
      font-size: 0.7rem;
      font-family: var(--font-mono);
    }

    .convo-msg {
      padding: 0.3rem 0.5rem;
      margin-bottom: 0.25rem;
      border-radius: 4px;
    }

    .convo-msg.user-msg {
      background: var(--secondary-20);
    }

    .convo-msg.assistant-msg {
      background: var(--primary-20);
    }

    .convo-msg.truncated {
      opacity: 0.4;
      text-decoration: line-through;
    }

    .truncation-line {
      border-top: 2px dashed var(--negative);
      margin: 0.5rem 0;
      position: relative;
    }

    .truncation-label {
      position: absolute;
      top: -8px;
      left: 50%;
      transform: translateX(-50%);
      background: var(--bg-card);
      padding: 0 0.5rem;
      font-size: 0.6rem;
      color: var(--negative);
    }

    .forgetting-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-cool);
    }

    /* ============ LIMITATIONS TAB ============ */
    .limitations-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .limitations-intro h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .limitations-intro > p {
      color: var(--text-secondary);
      margin-bottom: 0;
    }

    .key-insight-box {
      background: var(--bg-elevated);
      padding: 1rem;
      border-radius: var(--radius-sm);
      margin-top: 1rem;
      border-left: 3px solid var(--accent-warm);
    }

    .key-insight-box strong {
      color: var(--accent-warm);
    }

    /* Hallucination Section */
    .hallucination-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .hallucination-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .hallucination-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .hallucination-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      margin-bottom: 1rem;
    }

    .example-qa {
      margin-bottom: 0.75rem;
    }

    .example-q, .example-a {
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
      margin-bottom: 0.5rem;
      font-size: 0.85rem;
    }

    .example-q {
      background: var(--secondary-20);
      border-left: 3px solid var(--accent-cool);
    }

    .example-a {
      background: var(--primary-20);
      border-left: 3px solid var(--accent-primary);
    }

    .example-a.hallucinated {
      background: rgba(198, 40, 40, 0.2);
      border-left: 3px solid var(--negative);
    }

    .example-verdict {
      font-size: 0.8rem;
      padding: 0.5rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
    }

    .hallucination-reasons {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      gap: 0.75rem;
    }

    .reason-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .reason-card strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.25rem;
    }

    .reason-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Knowledge Cutoff Section */
    .cutoff-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .cutoff-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .cutoff-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .cutoff-timeline {
      display: flex;
      align-items: center;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      margin-bottom: 1rem;
      overflow-x: auto;
    }

    .timeline-segment {
      flex: 1;
      min-width: 100px;
      text-align: center;
      position: relative;
      padding: 0.5rem;
    }

    .timeline-segment::after {
      content: '';
      position: absolute;
      top: 50%;
      right: 0;
      width: 100%;
      height: 2px;
      background: var(--border-subtle);
      z-index: 0;
    }

    .timeline-segment:last-child::after {
      display: none;
    }

    .timeline-dot {
      width: 12px;
      height: 12px;
      background: var(--accent-primary);
      border-radius: 50%;
      margin: 0 auto 0.5rem;
      position: relative;
      z-index: 1;
    }

    .timeline-segment.unknown .timeline-dot {
      background: var(--text-muted);
    }

    .timeline-segment.cutoff .timeline-dot {
      background: var(--accent-warm);
      box-shadow: 0 0 10px var(--accent-warm);
    }

    .timeline-label {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .timeline-segment.unknown .timeline-label {
      color: var(--text-muted);
    }

    .cutoff-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-warm);
    }

    /* Reasoning Models Section */
    .reasoning-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .reasoning-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .reasoning-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .model-comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 800px) {
      .model-comparison {
        grid-template-columns: 1fr;
      }
    }

    .model-type-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .model-type-card.standard {
      border-top: 3px solid var(--text-muted);
    }

    .model-type-card.reasoning {
      border-top: 3px solid var(--accent-primary);
    }

    .model-type-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
    }

    .model-type-header h4 {
      margin: 0;
      font-size: 0.95rem;
    }

    .model-type-icon {
      font-size: 1.2rem;
    }

    .model-type-card ul {
      margin: 0 0 0.75rem 0;
      padding-left: 1.25rem;
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    .model-examples {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .reasoning-why-works {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      margin-bottom: 1rem;
    }

    .reasoning-why-works h4 {
      margin: 0 0 0.75rem 0;
      font-size: 0.95rem;
    }

    .why-points {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
    }

    .why-point {
      display: flex;
      gap: 0.5rem;
      font-size: 0.8rem;
    }

    .why-point-icon {
      font-size: 1rem;
      flex-shrink: 0;
    }

    .why-point p {
      margin: 0;
      color: var(--text-secondary);
    }

    .why-point strong {
      color: var(--text-primary);
    }

    /* Interactive Thinking Demo */
    .thinking-demo-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .thinking-demo-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .thinking-demo-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .thinking-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .thinking-problem {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin-bottom: 1rem;
      font-family: var(--font-mono);
      font-size: 0.85rem;
    }

    .thinking-problem-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
      font-family: var(--font-sans);
    }

    .thinking-approaches {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 800px) {
      .thinking-approaches {
        grid-template-columns: 1fr;
      }
    }

    .approach-panel {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 2px solid transparent;
    }

    .approach-panel.standard {
      border-color: var(--text-muted);
    }

    .approach-panel.reasoning {
      border-color: var(--accent-primary);
    }

    .approach-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
      font-weight: 600;
      font-size: 0.85rem;
    }

    .approach-content {
      font-family: var(--font-mono);
      font-size: 0.75rem;
      line-height: 1.6;
      min-height: 150px;
    }

    .thinking-tokens {
      background: var(--primary-10);
      border: 1px dashed var(--accent-primary);
      border-radius: 4px;
      padding: 0.5rem;
      margin-bottom: 0.5rem;
      color: var(--text-secondary);
    }

    .thinking-tokens-label {
      font-size: 0.65rem;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .final-answer {
      padding-top: 0.5rem;
      border-top: 1px solid var(--border-subtle);
    }

    .answer-correct {
      color: var(--positive);
    }

    .answer-incorrect {
      color: var(--negative);
    }

    .thinking-controls {
      display: flex;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .thinking-btn {
      padding: 0.5rem 1rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.8rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .thinking-btn:hover {
      border-color: var(--accent-primary);
    }

    .thinking-btn.primary {
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-color: var(--accent-primary);
    }

    .thinking-result {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.8rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Tools & RAG Section */
    .tools-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .tools-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .tools-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .tools-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .tool-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 1px solid var(--border-subtle);
    }

    .tool-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .tool-icon {
      font-size: 1.2rem;
    }

    .tool-name {
      font-weight: 600;
      font-size: 0.9rem;
    }

    .tool-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .tools-insight {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Other Limitations Section */
    .other-limitations {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .other-limitations h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .limitations-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 0.75rem;
    }

    .limitation-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .limitation-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .limitation-icon {
      font-size: 1rem;
    }

    .limitation-card strong {
      font-size: 0.85rem;
    }

    .limitation-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .limitation-example {
      margin-top: 0.5rem;
      padding: 0.4rem;
      background: var(--bg-elevated);
      border-radius: 4px;
      font-family: var(--font-mono);
      font-size: 0.7rem;
      color: var(--text-muted);
    }
  </style>
</head>
<body>
  <!-- Narrow Screen Warning Overlay -->
  <div class="narrow-screen-warning">
    <div class="warning-icon">📐</div>
    <h2>Screen Too Narrow</h2>
    <p>
      AI Intuition Lab includes interactive visualizations designed for larger screens. 
      Please widen your browser window or view on a tablet/desktop for the best experience.
    </p>
    <div class="min-width-note">Minimum width: 1024px</div>
  </div>

  <div class="app-layout">
    <!-- Sidebar Navigation -->
    <aside class="sidebar">
      <div class="sidebar-header">
        <h1>AI Intuition<br>Lab</h1>
      </div>

      <nav class="tab-nav">
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">00</span> INTRODUCTION</span>
          <div class="tab-group-buttons">
            <button class="tab-btn active" data-tab="welcome">
              <span class="icon">🏠</span>
              <span>Overview</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">01-03</span> INPUT & OUTPUT</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="tokens">
              <span class="icon">🔤</span>
              <span>Tokenization</span>
            </button>
            <button class="tab-btn" data-tab="embed">
              <span class="icon">📍</span>
              <span>Embeddings</span>
            </button>
            <button class="tab-btn" data-tab="inference">
              <span class="icon">💬</span>
              <span>Inference</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">04-05</span> ARCHITECTURE</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="nn">
              <span class="icon">🧠</span>
              <span>Neural Network</span>
            </button>
            <button class="tab-btn" data-tab="attention">
              <span class="icon">🔍</span>
              <span>Attention</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">06-07</span> TRAINING LLMS</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="training">
              <span class="icon">🎓</span>
              <span>Pre-Training</span>
            </button>
            <button class="tab-btn" data-tab="finetuning">
              <span class="icon">🎯</span>
              <span>Fine-Tuning</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">08-10</span> IN PRACTICE</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="prompting">
              <span class="icon">💡</span>
              <span>Prompting</span>
            </button>
            <button class="tab-btn" data-tab="multimodal">
              <span class="icon">🖼️</span>
              <span>Images & Sound</span>
            </button>
            <button class="tab-btn" data-tab="limitations">
              <span class="icon">⚠️</span>
              <span>Limitations</span>
            </button>
          </div>
        </div>
      </nav>
      <div class="sidebar-footer">
        <a href="https://github.com/aaronmiller-info/AI-Intuition-Lab" target="_blank">View on GitHub</a>
        <div class="copyright">© 2025 Aaron Miller<br>CC BY 4.0</div>
      </div>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
    <!-- WELCOME TAB -->
    <section id="tab-welcome" class="tab-section active">
      <div class="section-header">
        <h2>Developing Your AI Intuition</h2>
        <p>Learning to use LLMs like an expert</p>
      </div>

      <div class="concept-card">
        <h4>The Goal: Expert User, Not Researcher</h4>
        <p>This lab isn’t about turning you into a computer scientist or an AI researcher. It’s about helping you understand the "physics" of how Large Language Models (LLMs) work so you can use them more effectively.</p>
        <p class="mt-1">By grasping the underlying concepts, you'll develop an <strong>intuition</strong> for why models succeed, why they fail, and how to steer them towards usefulness.</p>
      </div>

      <div class="concept-card">
        <h4>📸 It's like the difference between the Point-and-Shoot vs the Pro</h4>
        <div class="grid grid-2-col gap-15 mt-1">
          <div class="card-sm">
            <div class="text-accent bold mb-05">The Point-and-Shoot User</div>
            <p class="text-sm">Most people use AI like an iPhone camera on <strong>"Auto" mode</strong>. It works 80% of the time, but when the lighting is weird or the subject is moving fast, they don't know how to fix the blurry result. They're limited by not understanding how it works.</p>
          </div>
          <div class="card-sm">
            <div class="text-accent bold mb-05">The Expert User (The Pro)</div>
            <p class="text-sm">A professional photographer understands how <strong>light</strong> interacts with the <strong>lens</strong> and the <strong>sensor</strong>. They know how to adjust the <strong>aperture</strong>, <strong>shutter speed</strong>, <strong>ISO</strong>, and <strong>focus</strong> to get beautiful photos.</p>
            <p class="text-sm">They don't know to build a camera, but they know how it works.</p>
          </div>
        </div>
      </div>
      <div class="concept-card">
        <h4>Building Your Intuition</h4>
        <p class="mt-15 text-secondary">Just like learning how a camera works, going through each of the concepts in the sidebar will help you understand how LLMs work and how to use them effectively. Concepts like tokens, embeddings, neural networks, and attention are the foundation of how LLMs work. If you understand these concepts, you'll be able to use LLMs in a way that avoids common pitfalls and maximizes their potential.</p>
      </div>
    </section>

    <!-- TOKENIZATION TAB -->
    <section id="tab-tokens" class="tab-section">
      <div class="section-header">
        <h2>01: Tokenization</h2>
        <p>LLMs don't use raw text. Instead, they use sequences of numbers called tokens.</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand tokens, you understand <em>the basic unit in how an LLM works, like understanding how atoms work in molecules, cells, and organisms.</em></div>
        <div class="intuition-detail">AI doesn't process words—it processes tokens, which are pieces of information like text, converted into numbers. Tokens are the basic unit of everything in LLMs.</div>
      </div>

      <div class="intro-summary mb-2">
        Before an LLM can understand text, it must break it down into smaller units called <strong>tokens</strong>. This demo simulates a <strong>Subword Tokenizer</strong>, showing how words are split into meaningful chunks and assigned numerical IDs that the model can process.
      </div>

      <div class="tokenizer-container">
        <div class="interactive-well">
          <div class="tok-main">
            <div class="card-header">
              <h3>Text Input</h3>
              <span class="badge">Subword Tokenization</span>
            </div>
            <div class="input-area mt-1">
              <textarea id="tok-input" style="min-height: 120px;" placeholder="Try words like 'unhappiness', 'artificial intelligence', or 'misunderstanding'...">Artificial intelligence and machine learning are transforming our understanding of computational thinking.</textarea>
            </div>
            <button class="action-btn mt-1" id="tok-btn">
              <span>Tokenize Text</span>
              <span>→</span>
            </button>
          </div>

          <div class="concept-card mt-15 p-125">
            <h4>Resulting Tokens</h4>
            <div class="tokens-grid mt-1" id="tok-tokens"></div>
            
            <h4 class="mt-15 text-sm">Numerical IDs</h4>
            <div class="ids-display mt-05 text-sm p-075" id="tok-ids"></div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>Why subword tokenization matters</h4>
        <p>Real models like GPT-4 use ~100k tokens. Words are broken into meaningful pieces: "unhappiness" → ["un", "happiness"] or ["un", "happ", "iness"]. This lets the model understand prefixes like "un-" (negation) and suffixes like "-ness" (noun form). Try typing "unhappy", "happiness", and "unhappiness" to see how they share pieces—this is how models generalize to words they've rarely seen.</p>
        <div class="note-box mt-1 p-075 p-1 text-sm" style="background: var(--bg-elevated); border-radius: var(--radius-sm); border-left: 3px solid var(--accent-cool);">
          <strong>📝 Note:</strong> This is a simplified tokenizer for educational purposes. Real tokenizers use larger vocabularies (~100k tokens) and make different splitting decisions. 
          <a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground" target="_blank" rel="noopener" class="text-primary" style="text-decoration: underline;">Try a real tokenizer →</a>
        </div>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Tokenization</h3>
        
        <div class="concept-card">
          <h4>Why Not Just Use Letters?</h4>
          <p>You might wonder: why not just feed the model one letter at a time? Three reasons:</p>
          <div class="comparison-table">
            <div class="comparison-row header">
              <div>Approach</div>
              <div>Sequence Length</div>
              <div>Problem</div>
            </div>
            <div class="comparison-row">
              <div><strong>Characters</strong></div>
              <div>"hello world" → 11 tokens</div>
              <div>Too granular—hard to learn word meanings</div>
            </div>
            <div class="comparison-row">
              <div><strong>Whole words</strong></div>
              <div>"hello world" → 2 tokens</div>
              <div>Can't handle new words, typos, or rare words</div>
            </div>
            <div class="comparison-row highlight">
              <div><strong>Subwords</strong></div>
              <div>"hello world" → 2-3 tokens</div>
              <div>Best of both: efficient + flexible</div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>How BPE (Byte Pair Encoding) Works</h4>
          <p>The most common tokenization method builds a vocabulary by finding frequent patterns:</p>
          <ol class="concept-list">
            <li><strong>Start with characters</strong>—Begin with just letters and punctuation</li>
            <li><strong>Find frequent pairs</strong>—Look for character pairs that appear often together (like "th" or "ing")</li>
            <li><strong>Merge them</strong>—Add "th" as a single token, repeat with next most frequent pair</li>
            <li><strong>Keep going</strong>—After ~50,000 merges, you have a vocabulary</li>
          </ol>
          <div class="token-evolution">
            <div class="evolution-step">
              <div class="step-label">Start</div>
              <div class="step-tokens">
                <span class="evo-token">l</span>
                <span class="evo-token">o</span>
                <span class="evo-token">w</span>
                <span class="evo-token">e</span>
                <span class="evo-token">r</span>
              </div>
            </div>
            <div class="evolution-arrow">→</div>
            <div class="evolution-step">
              <div class="step-label">Merge "er"</div>
              <div class="step-tokens">
                <span class="evo-token">l</span>
                <span class="evo-token">o</span>
                <span class="evo-token">w</span>
                <span class="evo-token merged">er</span>
              </div>
            </div>
            <div class="evolution-arrow">→</div>
            <div class="evolution-step">
              <div class="step-label">Merge "low"</div>
              <div class="step-tokens">
                <span class="evo-token merged">low</span>
                <span class="evo-token merged">er</span>
              </div>
            </div>
            <div class="evolution-arrow">→</div>
            <div class="evolution-step">
              <div class="step-label">Merge "lower"</div>
              <div class="step-tokens">
                <span class="evo-token final">lower</span>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Why Token IDs Are Just Numbers</h4>
          <p>The model never sees the actual text "hello"—it sees a number like <code>15339</code>. This number is just an index into a lookup table, like if the words in a dictionary were numbered so you could look for word #15339 and find "hello":</p>
          <div class="vocab-table">
            <div class="vocab-row">
              <span class="vocab-id">0</span>
              <span class="vocab-token">&lt;pad&gt;</span>
              <span class="vocab-note">Special: padding</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">1</span>
              <span class="vocab-token">&lt;unk&gt;</span>
              <span class="vocab-note">Special: unknown</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">...</span>
              <span class="vocab-token"></span>
              <span class="vocab-note"></span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">262</span>
              <span class="vocab-token">the</span>
              <span class="vocab-note">Very common word</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">15339</span>
              <span class="vocab-token">hello</span>
              <span class="vocab-note">Less common</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">50256</span>
              <span class="vocab-token">&lt;|endoftext|&gt;</span>
              <span class="vocab-note">Special: end marker</span>
            </div>
          </div>
          <p>Common words often get lower IDs because BPE builds vocabulary starting with the most frequent patterns. The actual numbers don't mean anything about the words being more important or easier to find.</p>
        </div>

        <div class="concept-card">
          <h4>Try These Experiments in the Tokenizer</h4>
          <div class="experiment-box">
            <p><strong>Experiment 1:</strong> Type "unhappiness"—watch it split into "un" + "happiness" or "un" + "happ" + "iness"</p>
            <p><strong>Experiment 2:</strong> Type "unfortunately"—see how prefixes (un-) and suffixes (-ly) get separated</p>
            <p><strong>Experiment 3:</strong> Type "antidisestablishmentarianism"—watch it recursively break into: anti + dis + establish + ment + arian + ism</p>
            <p><strong>Experiment 4:</strong> Type "computerization"—see how technical words get split at meaningful boundaries</p>
            <p><strong>What you're learning:</strong> Tokenization breaks words into reusable pieces. The prefix "un-" appears in thousands of words, so learning it once helps the model understand all of them.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Cost of Tokens</h4>
          <p>Whether you are using a free service or a paid one, all model providers calculate costs by the token. Now you know why!</p>
          <div class="token-cost-example">
            <div class="cost-item">
              <div class="cost-text">"Hi"</div>
              <div class="cost-tokens">~1 token</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">"Hello, how are you today?"</div>
              <div class="cost-tokens">~6 tokens</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">This entire paragraph you're reading right now</div>
              <div class="cost-tokens">~30 tokens</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">A typical 500-word essay</div>
              <div class="cost-tokens">~650-750 tokens</div>
            </div>
          </div>
          <p><strong>Rule of thumb:</strong> 1 token ≈ 4 characters or ≈ ¾ of a word in English.</p>
        </div>
      </div>
    </section>

    <!-- EMBEDDINGS TAB -->
    <section id="tab-embed" class="tab-section">
      <div class="section-header">
        <h2>02: Embedding Space</h2>
        <p>How do we turn words into something a computer can calculate?</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand embeddings, you understand <em>how AI "knows" what words mean by using coordinates in geometric space.</em></div>
        <div class="intuition-detail">AI represents tokens as vectors of numbers, which are like positions in a high-dimensional space, where the position encodes meaning. Embeddings are how AI "knows" that words are related—not through definitions, but through learned proximity.</div>
      </div>

      <!-- Pedagogical Introduction -->
      <div class="embedding-intro">
        <div class="intro-step-container">
          <div class="intro-step">
            <div class="step-number">1</div>
            <div class="step-content">
              <h4>The Problem</h4>
              <p>Computers only calculate with numbers. But language is made of words. How do we bridge that gap?</p>
              <div class="step-visual problem-visual">
                <span class="word-bubble">"king"</span>
                <span class="arrow-icon">→</span>
                <span class="question-mark">?</span>
                <span class="arrow-icon">→</span>
                <span class="computer-icon">🖥️</span>
              </div>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">2</div>
            <div class="step-content">
              <h4>The Solution: A List of Numbers</h4>
              <p>We represent each word as a <strong>vector</strong>—which is essentially a list of numbers. Each number captures something about the word's meaning.</p>
              <div class="step-visual vector-visual">
                <span class="word-bubble">"king"</span>
                <span class="arrow-icon">→</span>
                <div class="vector-box">
                  <div class="vector-row">
                    <span class="dim-label">royalty:</span>
                    <span class="dim-value high">0.9</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">male:</span>
                    <span class="dim-value high">0.8</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">human:</span>
                    <span class="dim-value high">0.95</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">animal:</span>
                    <span class="dim-value low">0.1</span>
                  </div>
                  <div class="vector-row dim-more">
                    <span>... thousands more dimensions</span>
                  </div>
                </div>
              </div>
              <p class="step-note">💡 In reality, dimensions don't have labels like "royalty"—the model learns abstract patterns that spread across all the numbers. But the idea is the same: each number captures <em>something</em> about meaning.</p>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">3</div>
            <div class="step-content">
              <h4>Numbers Become Coordinates</h4>
              <p>Here's the key insight: <strong>a list of numbers is the same thing as coordinates in space.</strong></p>
              <div class="step-visual coords-visual">
                <div class="coords-example">
                  <div class="coords-2d">
                    <div class="coords-label">2 numbers = point on a map</div>
                    <div class="coords-display">[ 3, 5 ] → <span class="coords-point">●</span> at (3, 5)</div>
                  </div>
                  <div class="coords-3d">
                    <div class="coords-label">3 numbers = point in 3D space</div>
                    <div class="coords-display">[ 3, 5, 2 ] → <span class="coords-point">●</span> at (3, 5, 2)</div>
                  </div>
                  <div class="coords-nd">
                    <div class="coords-label">8,000 numbers = point in 8,000D space</div>
                    <div class="coords-display">[ 0.9, 0.8, 0.95, ... ] → <span class="coords-point">●</span> somewhere in that space</div>
                  </div>
                </div>
              </div>
              <p>So when we give a word thousands of numbers, we're placing it at a specific location in a high-dimensional space. We can't visualize 8,000 dimensions, but the math works the same as 2D or 3D.</p>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">4</div>
            <div class="step-content">
              <h4>Similar Meanings = Nearby Points</h4>
              <p>The magic: if the system is clever about choosing these numbers, <strong>words with similar meanings end up at nearby coordinates</strong>.</p>
              <div class="step-visual cluster-visual">
                <div class="cluster-group">
                  <div class="cluster-label">Royalty cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">king</span>
                    <span class="cluster-word">queen</span>
                    <span class="cluster-word">prince</span>
                  </div>
                </div>
                <div class="cluster-group">
                  <div class="cluster-label">Animal cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">cat</span>
                    <span class="cluster-word">dog</span>
                    <span class="cluster-word">mouse</span>
                  </div>
                </div>
                <div class="cluster-group">
                  <div class="cluster-label">Technology cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">computer</span>
                    <span class="cluster-word">phone</span>
                    <span class="cluster-word">laptop</span>
                  </div>
                </div>
              </div>
              <p>This is an <strong>embedding</strong>—we've "embedded" the meaning of words into a geometric space where distance = similarity.</p>
            </div>
          </div>
        </div>

        <div class="intro-summary">
          <strong>Now explore below:</strong> We've compressed thousands of dimensions down to 2D so you can see how words cluster. Click on words to see their similarity scores—which are calculated from how close their vectors are in the full high-dimensional space.
        </div>
      </div>

      <div class="embeddings-container">
        <div class="interactive-well">
          <div class="inference-grid" style="grid-template-columns: 1fr 1fr; gap: 3rem;"> <!-- Side-by-side to use space -->
            <div class="embed-main">
              <div class="card-header">
                <h3>2D Word Space</h3>
                <span class="badge">Click a word to see the similarity scores</span>
              </div>
              <div style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle); padding: 1.5rem; height: 900px; display: flex; align-items: center; justify-content: center;">
                <!-- Canvas constrained to 600px width but full height to ensure vertical aspect ratio -->
                <canvas id="embedding-canvas" style="width: 100%; height: 100%; max-width: 600px;"></canvas>
              </div>
            </div>

            <div class="embed-sidebar">
              <div class="concept-card h-900 flex flex-col" style="margin: 0;">
                <h4 class="mb-125" style="font-size: 1.1rem;">Similarity Scores</h4>
                
                <div class="control-panel-well mb-15">
                  <div class="word-selector">
                    <label class="mb-05 text-xs uppercase text-muted" style="display: block;">Choose target:</label>
                    <select id="emb-select" style="width: 100%; padding: 0.75rem; font-size: 1rem; background: var(--bg-deep); color: var(--text-primary); border: 1px solid var(--border-subtle); border-radius: 4px;">
                      <option value="king">king</option>
                      <option value="queen">queen</option>
                      <option value="man">man</option>
                      <option value="woman">woman</option>
                      <option value="cat">cat</option>
                      <option value="dog">dog</option>
                      <option value="computer">computer</option>
                      <option value="phone">phone</option>
                      <option value="happy">happy</option>
                      <option value="sad">sad</option>
                    </select>
                  </div>
                </div>

                <div class="flex-1 overflow-y-auto" style="background: rgba(26,26,26,0.05); border-radius: 4px; border: 1px solid var(--border-subtle);">
                  <table class="similarity-table w-full border-collapse" id="emb-table"></table>
                </div>
                
                <p class="mt-15 text-sm text-muted" style="line-height: 1.5;">
                  <strong>Note:</strong> This is a conceptual projection. The calculations are not the same that would be used in a real model.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>What you're seeing</h4>
        <p>The visualization above shows words as points, with nearby words being more similar. But remember: in a real model, each word is positioned in thousands of dimensions, not 2. We've used a technique called "dimensionality reduction" to squash those thousands of numbers down to just 2 so we can plot them on a screen. Some relationships get lost in the squashing, but the overall clustering is preserved.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Going Deeper on Embeddings</h3>
        
        <div class="concept-card">
          <h4>From Tokens to Vectors</h4>
          <p>Remember from the <b>Tokenization</b> tab: text gets split into tokens, and each token gets an ID number. But a single ID (like 15339 for "hello") doesn't capture meaning—it's just an address.</p>
          <p>The <strong>embedding layer</strong> gives each token ID a full vector of numbers:</p>
          <div class="vector-example">
            <div class="vector-visual">
              <div class="vector-label">Token ID → Embedding Vector</div>
              <div class="vector-numbers">15339 → [ 0.23, -0.87, 1.45, -0.12, ... ] (thousands of numbers)</div>
              <div class="vector-meaning">
                <span>Embeddings are <em>refined</em> during pre-training to capture meaning</span>
              </div>
            </div>
          </div>
          <p>The model learns which numbers to assign to each token so that similar-meaning tokens end up with similar vectors.</p>
        </div>

        <div class="concept-card">
          <h4>What Real Embeddings Look Like</h4>
          <p>Here's a sample embedding vector for the word "king" (showing just 32 of the thousands of dimensions frontier models use):</p>
          <div class="real-vector-display">
            <div class="real-vector-grid" id="real-vector-grid">
              <!-- Filled by JS -->
            </div>
            <div class="vector-stats">
              <div class="stat">
                <span class="stat-label">Dimensions</span>
                <span class="stat-value">4K–16K+</span>
              </div>
              <div class="stat">
                <span class="stat-label">Values range</span>
                <span class="stat-value">-2.5 to +2.5</span>
              </div>
              <div class="stat">
                <span class="stat-label">Total numbers</span>
                <span class="stat-value">Thousands per token</span>
              </div>
            </div>
          </div>
          <p>Each colored cell is one dimension. Red = negative, blue = positive, brighter = larger magnitude. Every token has its own unique pattern of thousands of numbers.</p>
        </div>

        <div class="concept-card">
          <h4>Why So Many Dimensions?</h4>
          <p>Each dimension can capture a different aspect of meaning:</p>
          <div class="dimension-examples">
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 47</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">animate ←</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 85%"></div>
                </div>
                <span class="spectrum-end">→ inanimate</span>
              </div>
              <div class="dim-examples-list">"dog" scores high, "rock" scores low</div>
            </div>
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 203</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">concrete ←</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 30%"></div>
                </div>
                <span class="spectrum-end">→ abstract</span>
              </div>
              <div class="dim-examples-list">"chair" scores high, "freedom" scores low</div>
            </div>
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 512</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">positive ←</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 70%"></div>
                </div>
                <span class="spectrum-end">→ negative</span>
              </div>
              <div class="dim-examples-list">"joy" scores high, "grief" scores low</div>
            </div>
          </div>
          <p><strong>Important:</strong> The model learns these dimensions automatically—nobody programs "dimension 47 = animacy". The structure emerges from seeing billions of sentences during training.</p>
        </div>

        <div class="concept-card">
          <h4>How "Similarity" Works</h4>
          <p>When we say two words are "similar", we mean their vectors (shown here as arrows) point in similar directions. Imagine standing at the origin and pointing toward each word:</p>
          <div class="similarity-visual">
            <div class="sim-example">
              <div class="sim-arrows high-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>High similarity (0.95)</strong>
                <span>"happy" and "joyful"</span>
                <span class="sim-desc">Arrows point almost the same direction</span>
              </div>
            </div>
            <div class="sim-example">
              <div class="sim-arrows medium-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>Medium similarity (0.5)</strong>
                <span>"happy" and "person"</span>
                <span class="sim-desc">Somewhat related, different concepts</span>
              </div>
            </div>
            <div class="sim-example">
              <div class="sim-arrows low-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>Low similarity (0.1)</strong>
                <span>"happy" and "quantum"</span>
                <span class="sim-desc">Arrows point in very different directions</span>
              </div>
            </div>
          </div>
          <p>This is called <strong>cosine similarity</strong>—it measures the angle between vectors, ignoring their length.</p>
        </div>

        <div class="concept-card">
          <h4>The Famous Word Algebra</h4>
          <p>The most surprising discovery: you can do <em>math</em> with word meanings!</p>
          <div class="word-algebra">
            <div class="algebra-equation">
              <span class="algebra-word">king</span>
              <span class="algebra-op">−</span>
              <span class="algebra-word">man</span>
              <span class="algebra-op">+</span>
              <span class="algebra-word">woman</span>
              <span class="algebra-op">≈</span>
              <span class="algebra-word result">queen</span>
            </div>
            <div class="algebra-explanation">
              <p>Subtract the "maleness" direction, add the "femaleness" direction → land near "queen"</p>
            </div>
          </div>
          <div class="more-algebra">
            <div class="algebra-mini">
              <code>Paris - France + Italy ≈ Rome</code>
            </div>
            <div class="algebra-mini">
              <code>walking - walk + swim ≈ swimming</code>
            </div>
            <div class="algebra-mini">
              <code>bigger - big + small ≈ smaller</code>
            </div>
          </div>
          <p>This only works because the embedding space has <em>consistent directions</em> for concepts like gender, country-capital relationships, and verb tenses.</p>
        </div>

        <div class="concept-card">
          <h4>Try This Mental Exercise</h4>
          <div class="experiment-box">
            <p><strong>Imagine a 3D space</strong> where:</p>
            <ul>
              <li>X-axis = size (small → big)</li>
              <li>Y-axis = danger (safe → dangerous)</li>
              <li>Z-axis = alive (object → living)</li>
            </ul>
            <p><strong>Where would these words be?</strong></p>
            <ul>
              <li>"mouse" → small, low danger, alive = (-1, -1, +1)</li>
              <li>"lion" → big, high danger, alive = (+1, +1, +1)</li>
              <li>"car" → big, medium danger, object = (+1, 0, -1)</li>
            </ul>
            <p><strong>What you're learning:</strong> Embeddings capture multiple aspects of meaning simultaneously, arranged spatially so similar things cluster together.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- INFERENCE TAB -->
    <section id="tab-inference" class="tab-section">
      <div class="section-header">
        <h2>03: Inference</h2>
        <p>Watch how LLMs generate text one token at a time</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand inference, you understand <em> how an AI model predicts each next token based on probabilities, in other words "inferring" the next token based on the previous tokens.</em></div>
        <div class="intuition-detail">When you use AI, you're having it do what's called "inference." It generates one token at a time by predicting what should come next. Inference is how AI produces responses—each token choice shapes what follows.</div>
      </div>

      <div class="intro-summary mb-2">
        AI models generate text <strong>one token at a time</strong> by predicting what is most likely to come next. In this workbench, you can watch the model's internal probability distribution shift as it builds a sentence, and experiment with <strong>Temperature</strong> to see how it affects creativity versus logic.
      </div>

      <div class="inference-container">
        <div class="interactive-well">
          <div class="inference-grid">
            <div class="inference-main">
              <!-- Current Prompt Display -->
              <div class="inference-prompt-area">
                <div class="inference-prompt-label">
                  <span>📝</span> Current Text
                </div>
                <div class="inference-prompt-display" id="inference-prompt">
                  The best way to learn is<span class="cursor"></span>
                </div>
              </div>

              <!-- Inference Pipeline Visualization -->
              <div class="inference-flow">
                <div class="inference-flow-title">Single Inference Step</div>
                <div class="inference-pipeline">
                  <div class="pipeline-stage">
                    <div class="pipeline-box input" id="pipeline-input">
                      "...to learn is"
                    </div>
                    <div class="pipeline-label">Input tokens</div>
                  </div>
                  
                  <div class="pipeline-arrow">→</div>
                  
                  <div class="pipeline-stage">
                    <div class="pipeline-box model" id="pipeline-model">
                      <div class="model-icon">🧠</div>
                      Neural Network
                    </div>
                    <div class="pipeline-label">Billions of calculations</div>
                  </div>
                  
                  <div class="pipeline-arrow">→</div>
                  
                  <div class="pipeline-stage">
                    <div class="pipeline-box output" id="pipeline-output">
                      " by"
                    </div>
                    <div class="pipeline-label">Predicted next token</div>
                  </div>
                </div>
              </div>

              <!-- Token Probabilities -->
              <div class="concept-card mb-0">
                <h4>Token Probability Distribution</h4>
                <div class="token-prob-list" id="token-prob-list">
                  <div class="token-prob-item selected">
                    <span class="token-prob-rank">1</span>
                    <span class="token-prob-token">" by"</span>
                    <div class="token-prob-bar-container">
                      <div class="token-prob-bar" style="width: 42%"></div>
                    </div>
                    <span class="token-prob-percent">42%</span>
                  </div>
                  <div class="token-prob-item alternative">
                    <span class="token-prob-rank">2</span>
                    <span class="token-prob-token">" to"</span>
                    <div class="token-prob-bar-container">
                      <div class="token-prob-bar" style="width: 28%"></div>
                    </div>
                    <span class="token-prob-percent">28%</span>
                  </div>
                </div>
              </div>
            </div>

            <!-- Controls Panel -->
            <div class="inference-controls">
              <h3>⚙️ Generation Settings</h3>
              
              <div class="control-panel-well">
                <div class="control-group">
                  <div class="control-group-title">Temperature:<br>(Move the Slider)</div>
                  <div class="slider-row">
                    <input type="range" id="inf-temperature" min="0" max="2" step="0.1" value="0.7">
                    <span class="slider-value" id="inf-temp-val">0.7</span>
                  </div>
                </div>

                <div class="temp-viz">
                  <div class="temp-viz-label">Selection probability with current temperature:</div>
                  <div class="temp-viz-bar" id="temp-viz-bar">
                    <div class="temp-viz-segment" style="background: var(--accent-primary)">" by"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-cool)">" to"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-secondary)">" through"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-warm)">" from"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-pink)">" with"</div>
                  </div>
                  <div class="temp-description" id="temp-description">
                    Balanced: Mostly picks likely tokens, occasionally surprises
                  </div>
                </div>
              </div>

              <div class="generation-buttons mt-15 flex flex-col gap-075">
                <button class="gen-btn primary" id="inf-step-btn">
                  <span>▶</span> Generate Next Token
                </button>
                <button class="gen-btn primary" id="inf-auto-btn">
                  <span>⏩</span> Auto-Generate
                </button>
                <button class="gen-btn secondary" id="inf-reset-btn">
                  <span>↺</span> Reset
                </button>
              </div>

              <div class="generation-stats hidden mt-15 p-1" id="generation-stats" style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle);">
                <div class="stat-item">
                  <span class="stat-value" id="stat-tokens">0</span>
                  <span class="stat-label">Tokens Generated</span>
                </div>
                <div class="stat-item">
                  <span class="stat-value" id="stat-steps">0</span>
                  <span class="stat-label">Inference Steps</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Autoregressive Loop Visualization -->
      <div class="autoregressive-section">
        <div class="autoregressive-title">
          <span>🔄</span> The Autoregressive Loop
        </div>
        <p style="color: var(--text-secondary); margin-bottom: 1.5rem;">
          LLMs don't generate entire sentences at once. They predict one token, add it to the list of tokens (the "context"), then predict the next—looping until they output a stop token.
        </p>
        <p style="color: var(--text-secondary); margin-bottom: 1.5rem;">
          <strong>What you see below is what you produced with the text generator tool above. Do it again with different settings and this will change.</strong>
        </p>
        
        <div class="loop-visualization" id="loop-visualization">
          <div class="loop-step completed">
            <div class="loop-step-number">1</div>
            <div class="loop-step-content">
              <div class="loop-step-label">Input prompt</div>
              <div class="loop-step-tokens">"The best way to learn is"</div>
            </div>
          </div>
          
          <div class="loop-arrow">↓</div>
          
          <div class="loop-step active">
            <div class="loop-step-number">2</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 1st inference → predicts " by"</div>
              <div class="loop-step-tokens">"The best way to learn is<span class="new-token"> by</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow feedback">↓</div>
          
          <div class="loop-step">
            <div class="loop-step-number">3</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 2nd inference → predicts " doing"</div>
              <div class="loop-step-tokens">"The best way to learn is by<span class="new-token"> doing</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow">↓</div>
          
          <div class="loop-step">
            <div class="loop-step-number">4</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 3rd inference → predicts "."</div>
              <div class="loop-step-tokens">"The best way to learn is by doing<span class="new-token">.</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow">↓</div>
          
          <div class="loop-step">
            <div class="loop-step-number">✓</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 4th inference → predicts stop token</div>
              <div class="loop-step-tokens">"The best way to learn is by doing." <span class="stop-token">&lt;|end|&gt;</span></div>
            </div>
          </div>
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h4>What's happening?</h4>
        <p>Each inference step takes all the text so far, processes it through the neural network, and outputs a probability distribution over all possible next tokens (~100,000 options). The model then samples from this distribution (influenced by temperature) to pick the next token. This new token gets added to the input, and the process repeats.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Inference</h3>
        
        <div class="concept-card">
          <h4>The Core Loop</h4>
          <p>When you chat with an AI, you're watching this loop happen incredibly fast:</p>
          <ol class="concept-list">
            <li><strong>Tokenize</strong>—Convert your text into numbers the model understands</li>
            <li><strong>Forward pass</strong>—Push tokens through billions of neural network parameters</li>
            <li><strong>Predict</strong>—Output a probability for every possible next token</li>
            <li><strong>Sample</strong>—Pick one token based on those probabilities + temperature</li>
            <li><strong>Repeat</strong>—Add the new token and go again until done</li>
          </ol>
          <p>Most Large Language Models (LLMs) do this loop about 20-100 times per second!</p>
        </div>

        <div class="concept-card">
          <h4>Temperature Explained</h4>
          <p>Temperature controls how "creative" vs "predictable" the model is:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🧊</span>
              <div>
                <strong>Temperature = 0</strong>
                <p>Always picks the highest probability token (called "greedy decoding"). Deterministic—the same prompt always produces the same response. At this temperature, the model is perfectly consistent.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">☀️</span>
              <div>
                <strong>Temperature = 1</strong>
                <p>Samples naturally from the probability distribution. Balanced creativity.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🔥</span>
              <div>
                <strong>Temperature = 2</strong>
                <p>Flattens probabilities, making unlikely tokens more likely. Creative but chaotic.</p>
              </div>
            </div>
          </div>
          <p>If you're interested in the math, temperature divides the "logits" (raw scores) before converting to probabilities. Higher temperature → flatter distribution → more randomness.</p>
        </div>

        <div class="concept-card">
          <h4>Why Stop Tokens Matter</h4>
          <p>Without a stop token, the model would generate text forever! The stop token (like <code>&lt;|endoftext|&gt;</code> or <code>&lt;|end|&gt;</code>) is a special token that means "I'm done responding."</p>
          <div class="experiment-box">
            <p><strong>Fun fact:</strong> Early chatbots sometimes got stuck in loops because they didn't handle stop tokens well. The model would just keep generating, often repeating itself endlessly.</p>
            <p><strong>In practice:</strong> some AI tools also let you set a "max tokens" limit as a safety net, so even if the model doesn't stop naturally, it won't run forever.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Context Window</h4>
          <p>The model can only "see" a maximum amount of text at once—this is the <strong>context window</strong>:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">400K</div>
              <div class="scale-label">GPT 5.2</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">200K</div>
              <div class="scale-label">Claude Sonnet 4.5</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">1M</div>
              <div class="scale-label">Gemini 3 Flash</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">Up to 2M</div>
              <div class="scale-label">Grok 4.1</div>
            </div>
          </div>
          <p>Each inference step processes the <em>entire</em> context, all those tokens with their embedding vectors. It's a massive amount of math for each pass. That's why longer conversations are more expensive for model providers—more tokens to process each step!</p>
        </div>

        <div class="concept-card">
          <h4>Try This Experiment</h4>
          <div class="experiment-box">
            <p><strong>Challenge:</strong> Use the controls above to see how temperature affects generation:</p>
            <p>1. Set temperature to <strong>0</strong> and generate several times—notice you always get the same output</p>
            <p>2. Set temperature to <strong>1.5</strong> and generate—watch how the output becomes more varied (and sometimes weird!)</p>
            <p><strong>What you're learning:</strong> The same prompt can produce different outputs depending on sampling settings. This is why AI responses can vary even when you ask the same question.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- NEURAL NETWORK TAB -->
    <section id="tab-nn" class="tab-section">
      <div class="section-header">
        <h2>04: Neural Networks</h2>
        <p>See inside the "black box"—how vectors flow through layers and become predictions</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand neural networks, you understand <em>that AI is math, not intelligence in a human sense but rather billions of calculations that find patterns.</em></div>
        <div class="intuition-detail">Neural networks are the engine—layers of simple math that transform embedding vectors into predictions. Every pattern the model recognizes, every connection it makes, happens through these calculations.</div>
      </div>

      <!-- Context Introduction -->
      <div class="nn-intro">
        <div class="nn-intro-flow">
          <div class="nn-intro-box input-box">
            <div class="intro-box-label">From Embeddings Tab</div>
            <div class="intro-box-content">
              <strong>Input:</strong> Embedding dimensions<br>
              <span class="intro-example">[royalty: 0.8, military: 0.2, ...]</span>
            </div>
          </div>
          <div class="nn-intro-arrow">→</div>
          <div class="nn-intro-box network-box">
            <div class="intro-box-label">This Tab</div>
            <div class="intro-box-content">
              <strong>Neural Network</strong><br>
              <span class="intro-example">Layers of pattern detectors</span>
            </div>
          </div>
          <div class="nn-intro-arrow">→</div>
          <div class="nn-intro-box output-box">
            <div class="intro-box-label">To Inference Tab</div>
            <div class="intro-box-content">
              <strong>Output:</strong> Token probabilities<br>
              <span class="intro-example">[" king": 0.5, " general": 0.3, ...]</span>
            </div>
          </div>
        </div>
      </div>

      <div class="intro-summary mb-2">
        <strong>Example prompt:</strong> "The messenger bowed to the ___."<br>
        The network predicts which word fits best based on context. Below is a tiny network (4→4→3 nodes)—real LLMs have billions of parameters, but the core idea is the same.
      </div>

      <div class="nn-container">
        <div class="interactive-well">
          <div class="inference-grid"> <!-- Reusing inference-grid for consistent layout -->
            <div class="nn-main">
              <div class="nn-canvas-wrapper">
                <canvas id="nn-canvas"></canvas>
                <div class="nn-legend">
                  <div class="legend-item">
                    <div class="legend-line positive thick"></div>
                    <span>Strong positive</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-line negative thick"></div>
                    <span>Strong negative</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-circle active"></div>
                    <span>High activation</span>
                  </div>
                </div>
              </div>
            </div>

            <div class="nn-controls">
              <h3>⚡ Simulate Embeddings</h3>
              
              <div class="control-panel-well">
                <div class="control-group">
                  <div class="control-group-title">Input Dimensions</div>
                  <div class="slider-row">
                    <label>royalty</label>
                    <input type="range" id="nn-x1" min="-1" max="1" step="0.05" value="0.8">
                    <span class="slider-value" id="nn-x1-val">0.80</span>
                  </div>
                  <div class="slider-row">
                    <label>military</label>
                    <input type="range" id="nn-x2" min="-1" max="1" step="0.05" value="0.2">
                    <span class="slider-value" id="nn-x2-val">0.20</span>
                  </div>
                  <div class="slider-row">
                    <label>gender</label>
                    <input type="range" id="nn-x3" min="-1" max="1" step="0.05" value="0.6">
                    <span class="slider-value" id="nn-x3-val">0.60</span>
                  </div>
                  <div class="slider-row">
                    <label>formality</label>
                    <input type="range" id="nn-x4" min="-1" max="1" step="0.05" value="0.3">
                    <span class="slider-value" id="nn-x4-val">0.30</span>
                  </div>
                </div>
              </div>

              <div class="concept-card mt-15 p-1">
                <h4 style="font-size: 0.8rem; margin-bottom: 0.5rem;">Token Predictions</h4>
                <div class="output-display nn-output-display" style="border: none; padding: 0; margin: 0; background: transparent;">
                  <div class="output-row">
                    <span class="output-label">" king"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out1-bar"></div></div>
                    <span class="output-value" id="nn-out1">0.00</span>
                  </div>
                  <div class="output-row">
                    <span class="output-label">" general"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out2-bar"></div></div>
                    <span class="output-value" id="nn-out2">0.00</span>
                  </div>
                  <div class="output-row">
                    <span class="output-label">" queen"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out3-bar"></div></div>
                    <span class="output-value" id="nn-out3">0.00</span>
                  </div>
                </div>
              </div>

              <div class="nn-try-this" style="margin-top: 1.5rem; background: rgba(0,212,170,0.05); border-left: 3px solid var(--accent-primary); padding: 0.75rem; font-size: 0.75rem; color: var(--text-secondary);">
                <strong>Try this:</strong> High royalty + positive gender → "king". Crank up military → "general" takes over.
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>What's happening?</h4>
        <p>Each connection has a <strong>weight</strong> that multiplies the incoming signal—these are a big share of the "parameters" that get learned during training. The hidden layer neurons combine their inputs to detect patterns: one might activate for "royalty + masculine," another for "military context." The output layer combines these patterns to predict which token comes next. Line thickness shows weight magnitude (green = positive, red = negative). Node brightness shows activation strength.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Neural Networks</h3>
        
        <div class="concept-card">
          <h4>The Big Picture</h4>
          <p>A neural network is just a series of simple math operations chained together. Each "neuron" does three things:</p>
          <ol class="concept-list">
            <li><strong>Multiply</strong>—Each input gets multiplied by a weight (a number that says "how important is this input?")</li>
            <li><strong>Add</strong>—Sum up all those multiplied values, plus a "bias" (a starting point)</li>
            <li><strong>Squash</strong>—Apply an activation function to keep the output in a reasonable range</li>
          </ol>
          <p>That's it! The "intelligence" comes from finding the right weights through training.</p>
        </div>

        <div class="concept-card">
          <h4>Why Weights Matter</h4>
          <p>Think of weights like volume knobs on a mixing board:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🔊</span>
              <div>
                <strong>Positive weight (+1.5)</strong>
                <p>Turns up that input—"this matters, pay attention to it"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🔇</span>
              <div>
                <strong>Negative weight (-1.5)</strong>
                <p>Inverts the signal—"when this goes up, push the output down"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">⏸️</span>
              <div>
                <strong>Zero weight (0.0)</strong>
                <p>Ignores that input entirely—"this doesn't matter"</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Mystery of the Black Box</h4>
          <p>Traditional software is written by humans using clear, step-by-step logic. But nobody "writes" an LLM. People design the architecture, but the model <strong>learns the logic</strong> itself through trillions of mathematical adjustments. This creates a "Black Box" problem:</p>
          
          <div class="black-box-container">
            <div class="box-side">
              <div class="box-side-label"><span>💻</span> Traditional Code</div>
              <div class="code-snippet">
                if (is_royal && is_male) {<br>
                &nbsp;&nbsp;return "king";<br>
                } else if (is_military) {<br>
                &nbsp;&nbsp;return "general";<br>
                }
              </div>
              <p class="mt-1 text-xs text-muted">Transparent: We can see exactly why a decision was made.</p>
            </div>
            <div class="box-side">
              <div class="box-side-label"><span>🧠</span> Neural Weights</div>
              <div class="weights-grid-mini">
                <div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div>
                <div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div>
                <div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div>
                <div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div>
              </div>
              <p class="mt-1 text-xs text-muted">Opaque: The logic is buried in billions of numbers.</p>
            </div>
          </div>
          
          <h4 class="mt-15">The Interpretability Problem</h4>
          <p>Because the model's knowledge is spread across billions of weights, it's incredibly difficult to answer the question: <em>"Why did the model say that?"</em></p>
          <ul class="concept-list mt-1">
            <li><strong>Distributed Knowledge:</strong> The concept of "Apple" isn't in one neuron; it's a tiny pattern across thousands of them.</li>
            <li><strong>Emergent Behavior:</strong> Models often develop capabilities (like coding or translation) that their creators didn't explicitly plan for.</li>
            <li><strong>Mechanical Interpretability:</strong> A new field of science dedicated to "reverse-engineering" these weights to understand the model's internal world.</li>
          </ul>
        </div>

        <div class="concept-card">
          <h4>How Nodes Learn Meaning</h4>
          <p>During training, the network learns weights that make hidden nodes act like <strong>pattern detectors</strong>:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">👑</span>
              <div>
                <strong>A "royalty + masculine" detector</strong>
                <p>Activates when royalty is high AND gender is masculine → boosts "king"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">⚔️</span>
              <div>
                <strong>A "military" detector</strong>
                <p>Activates when military dimension is high → boosts "general"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">👸</span>
              <div>
                <strong>A "royalty + feminine" detector</strong>
                <p>Activates when royalty is high AND gender is feminine → boosts "queen"</p>
              </div>
            </div>
          </div>
          <p>Nobody programs these detectors—they <em>emerge</em> from training on text. The network discovers which patterns predict which words.</p>
        </div>

        <div class="concept-card">
          <h4>Dense vs. Sparse Networks</h4>
          <p>Not all neural networks use all of their neurons for every task. This is the difference between <strong>dense</strong> and <strong>sparse</strong> architectures:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🏢</span>
              <div>
                <strong>Dense Networks</strong>
                <p>Every neuron is active for every input. Like a company where every employee must attend every single meeting. It's thorough but very slow and expensive as the model grows.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🏗️</span>
              <div>
                <strong>Sparse Networks (Mixture of Experts)</strong>
                <p>Only a small fraction of the network is active at any time. This allows for models with trillions of parameters that are still fast to run.</p>
              </div>
            </div>
          </div>
          
          <h4 class="mt-15">How Mixture of Experts (MoE) Works</h4>
          <p>Imagine a giant model composed of 16 "experts" (smaller neural networks). For every token, a <strong>router</strong> decides which small subset of experts (typically 1–4, depending on the architecture) are best equipped to handle it:</p>
          <div class="grid grid-2-col gap-1 mt-1">
            <div class="card-sm">
              <div class="text-accent bold mb-05">1. The Router</div>
              <p class="text-xs">Acts like a dispatcher, analyzing the incoming token and selecting the most relevant experts.</p>
            </div>
            <div class="card-sm">
              <div class="text-accent bold mb-05">2. The Experts</div>
              <p class="text-xs">Specialized sub-networks that have learned specific patterns (e.g., coding, logic, or creative writing).</p>
            </div>
          </div>
          <p class="mt-1 text-sm text-secondary"><strong>The Result:</strong> MoE lets models have the <em>knowledge</em> of a massive model but the <em>speed</em> of a much smaller one, because only a fraction of the parameters are active at any given moment.</p>
        </div>

        <div class="concept-card">
          <h4>Try This Experiment in the Neural Network Workbench</h4>
          <div class="experiment-box">
            <p><strong>Challenge 1:</strong> Make "king" the top prediction</p>
            <p><strong>Hint:</strong> Royalty high + gender positive (masculine)</p>
            <p><strong>Challenge 2:</strong> Now make "queen" win instead</p>
            <p><strong>Hint:</strong> Keep royalty high but flip gender negative (feminine)</p>
            <p><strong>Challenge 3:</strong> Make "general" dominate</p>
            <p><strong>Hint:</strong> Crank up military—it overrides royalty and gender</p>
            <p><strong>What you're learning:</strong> The network combines multiple input signals to make predictions. It's not just "royalty = king"—it's "royalty + masculine = king", "royalty + feminine = queen", and "military = general" regardless of other signals.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>Scale to Real Networks</h4>
          <p>The demo network above has <strong>~30 parameters</strong>. Real language models have:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">8B</div>
              <div class="scale-label">Llama 3</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">70B</div>
              <div class="scale-label">Llama 3.1</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">405B</div>
              <div class="scale-label">Llama 3.1 405B</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">500B–1T+</div>
              <div class="scale-label">Frontier models like ChatGPT 5.2</div>
            </div>
          </div>
          <p>Same basic idea—multiply, add, activate—just repeated trillions of times with carefully tuned weights across hundreds of layers. Note: Exact sizes for closed-source frontier models aren't disclosed; the largest confirmed dense models are ~500B parameters, while sparse MoE models can exceed 1T total parameters.</p>
        </div>
      </div>
    </section>

    <!-- ATTENTION TAB -->
    <section id="tab-attention" class="tab-section">
      <div class="section-header">
        <h2>05: Attention</h2>
        <p>Each word looks at every other word to decide what matters</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand attention, you understand <em>why a special kind of neural network called a transformer revolutionized AI—they let any word "see" any other word instantly.</em></div>
        <div class="intuition-detail">Attention lets every token directly access every other token, regardless of distance. This is the mechanism that enabled the transformer revolution.</div>
      </div>

      <div class="attention-container">
        <div class="interactive-well">
          <div class="inference-grid" style="grid-template-columns: 1.2fr 1fr; gap: 3rem;"> <!-- Balanced layout -->
            <div class="att-main">
              <div class="card-header">
                <h3>Attention Flow</h3>
                <span class="badge">Click on any of the words below to see how attention works</span>
              </div>
              <canvas id="attention-canvas"></canvas>
            </div>

            <div class="att-controls">
              <div class="card-header">
                <h3>Attention Weights</h3>
              </div>
              
              <div class="control-panel-well">
                <div class="word-selector">
                  <label>Query word (who's asking):</label>
                  <select id="att-select">
                    <option value="0">The</option>
                    <option value="1">cat</option>
                    <option value="2">sat</option>
                    <option value="3">on</option>
                    <option value="4">the</option>
                    <option value="5">mat</option>
                  </select>
                </div>

                <div class="attention-weights" id="att-weights"></div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>Why attention is powerful</h4>
        <p>Traditional neural networks process words in fixed order, passing information step by step. <strong>Attention</strong> lets every word directly access every other word, regardless of distance. When processing "it" in "The cat sat on the mat because it was tired", attention connects "it" directly back to "cat"—no information lost in between. This is what makes <strong>transformers</strong> (attention-based networks) so effective at understanding language.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Attention</h3>
        
        <div class="concept-card">
          <h4>The Core Intuition</h4>
          <p>Imagine you're reading a sentence and trying to understand what "it" refers to:</p>
          <div class="attention-example-sentence">
            <span class="att-word">"The</span>
            <span class="att-word highlighted">cat</span>
            <span class="att-word">sat</span>
            <span class="att-word">on</span>
            <span class="att-word">the</span>
            <span class="att-word">mat</span>
            <span class="att-word">because</span>
            <span class="att-word query">it</span>
            <span class="att-word">was</span>
            <span class="att-word">tired."</span>
          </div>
          <p>Your brain automatically "attends" back to "cat" to understand "it". Attention mechanisms let neural networks do the same thing, but by using math.</p>
        </div>

        <div class="concept-card">
          <h4>Attention as "Soft" Lookup</h4>
          <p>Think of attention like a Google search, but fuzzy:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🔍</span>
              <div>
                <strong>Hard lookup (like a dictionary)</strong>
                <p>"Give me exactly the word at position 5" → returns one thing</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🎯</span>
              <div>
                <strong>Soft lookup (attention)</strong>
                <p>"Give me a mix of all words, weighted by relevance" → returns a blend</p>
              </div>
            </div>
          </div>
          <p>The weights (0.35, 0.25, 0.20, ...) determine how much each word contributes to the blend.</p>
        </div>

        <div class="concept-card">
          <h4>Query, Key, Value—The Three Roles</h4>
          <p>Every word plays three roles simultaneously:</p>
          <div class="qkv-explanation">
            <div class="qkv-role">
              <div class="qkv-icon query-icon">Q</div>
              <div class="qkv-content">
                <strong>Query</strong>
                <p>"I'm looking for information about X"</p>
                <p class="qkv-example">When "it" is the query, it's asking: "what noun am I referring to?"</p>
              </div>
            </div>
            <div class="qkv-role">
              <div class="qkv-icon key-icon">K</div>
              <div class="qkv-content">
                <strong>Key</strong>
                <p>"Here's what I'm about"</p>
                <p class="qkv-example">"cat" has a key that says: "I'm a noun, an animal, a subject"</p>
              </div>
            </div>
            <div class="qkv-role">
              <div class="qkv-icon value-icon">V</div>
              <div class="qkv-content">
                <strong>Value</strong>
                <p>"Here's my actual information to contribute"</p>
                <p class="qkv-example">"cat" has a value containing its full meaning representation</p>
              </div>
            </div>
          </div>
          <p><strong>Process:</strong> Query asks "who matches me?" → Compare with all Keys → Use scores to weight Values → Get blended result</p>
        </div>

        <div class="concept-card">
          <h4>Multi-Head Attention</h4>
          <p>Real transformers don't use just one attention pattern—they use many in parallel:</p>
          <div class="multihead-visual">
            <div class="head-example">
              <div class="head-label">Head 1</div>
              <div class="head-focus">might focus on: grammatical relationships</div>
              <div class="head-pattern">"cat" → "sat" (subject → verb)</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 2</div>
              <div class="head-focus">might focus on: coreference</div>
              <div class="head-pattern">"it" → "cat" (pronoun → noun)</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 3</div>
              <div class="head-focus">might focus on: position</div>
              <div class="head-pattern">each word → nearby words</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 4</div>
              <div class="head-focus">might focus on: semantic similarity</div>
              <div class="head-pattern">"cat" → "mat" (rhyme? location?)</div>
            </div>
          </div>
          <p>Modern LLMs use <strong>dozens of attention heads</strong> per layer, across <strong>dozens of layers</strong>. Each head can learn different patterns during training, like grammatical relationships, coreference, position, and semantic similarity.</p>
        </div>

        <div class="concept-card">
          <h4>Try This Thought Experiment</h4>
          <div class="experiment-box">
            <p><strong>Sentence:</strong> "The trophy doesn't fit in the suitcase because it is too big."</p>
            <p><strong>Question:</strong> What does "it" refer to—the trophy or the suitcase?</p>
            <p><strong>Answer:</strong> The trophy (it's too big to fit)</p>
            <p><strong>Now try:</strong> "The trophy doesn't fit in the suitcase because it is too small."</p>
            <p><strong>Now "it" refers to:</strong> The suitcase! Same structure, different meaning.</p>
            <p><strong>What you're learning:</strong> Attention must use semantic understanding, not just word positions or grammar rules. The model learns this from seeing millions of similar examples.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>Attention Is All You Need</h4>
          <p>Before 2017, language models used complex recurrent structures. The famous paper <a href="https://en.wikipedia.org/wiki/Attention_Is_All_You_Need" target="_blank">"Attention Is All You Need"</a> showed you could build state-of-the-art models using <em>only</em> attention.</p>
          <div class="timeline-mini">
            <div class="timeline-item">
              <span class="timeline-year">Pre-2017</span>
              <span class="timeline-desc">Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs) models—process words one by one, slow</span>
            </div>
            <div class="timeline-item highlight">
              <span class="timeline-year">2017</span>
              <span class="timeline-desc">Transformer—attention only, processes all words at once, fast</span>
            </div>
            <div class="timeline-item">
              <span class="timeline-year">2018+</span>
              <span class="timeline-desc">Big Language Models (BLMs) like BERT, GPT, and everything since = transformers</span>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>What Makes Transformers Special?</h4>
          <p>Unlike earlier neural networks, transformers have two key innovations:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🔗</span>
              <div>
                <strong>Parallel Processing</strong>
                <p>Old neural networks like Recurrent Neural Networks (RNNs) processed words one at a time, like reading a book aloud. Transformers see all words at once, like looking at a whole page.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🎯</span>
              <div>
                <strong>Direct Connections</strong>
                <p>In RNNs, information from word 1 had to pass through words 2, 3, 4... to reach word 10. With attention, word 1 connects directly to word 10.</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card transformer-architecture-card">
          <h4>🏗️ The Complete Transformer Architecture</h4>
          <p>Now that we've built up the pieces, here's how they fit together. A transformer is just these two layers repeated many times:</p>
          
          <div class="transformer-diagram">
            <div class="transformer-block">
              <div class="block-label">One "Transformer Block"</div>
              <div class="block-content">
                <div class="layer attention-layer">
                  <div class="layer-icon">🎯</div>
                  <div class="layer-info">
                    <strong>Attention Layer</strong>
                    <span>Words gather information from each other</span>
                  </div>
                </div>
                <div class="layer-arrow">↓</div>
                <div class="layer ffn-layer">
                  <div class="layer-icon">🧠</div>
                  <div class="layer-info">
                    <strong>Feed-Forward Layer</strong>
                    <span>Each word processed independently through a neural network</span>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <div class="transformer-full-stack">
            <div class="stack-label">Full Model (simplified)</div>
            <div class="stack-content">
              <div class="stack-layer input-layer">
                <span>Token Embeddings</span>
                <span class="layer-ref">(from Embeddings tab)</span>
              </div>
              <div class="stack-arrow">↓</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer 1</div>
              </div>
              <div class="stack-arrow">↓</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer 2</div>
              </div>
              <div class="stack-arrow">↓</div>
              <div class="stack-dots">⋮</div>
              <div class="stack-arrow">↓</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer N</div>
              </div>
              <div class="stack-arrow">↓</div>
              <div class="stack-layer output-layer">
                <span>Token Probabilities</span>
                <span class="layer-ref">(see <strong>Inference</strong> tab)</span>
              </div>
            </div>
          </div>

          <div class="transformer-scale-note">
            <strong>Real scale:</strong> Modern LLMs have anywhere from 40–120 layers, with billions of parameters in each layer.
          </div>
        </div>

        <div class="concept-card">
          <h4>Putting It All Together</h4>
          <p>You now understand the complete pipeline of an LLM:</p>
          <div class="pipeline-summary">
            <div class="pipeline-step">
              <span class="step-num">1</span>
              <strong>Tokenization</strong>
              <p>Text → token IDs</p>
            </div>
            <div class="pipeline-arrow">→</div>
            <div class="pipeline-step">
              <span class="step-num">2</span>
              <strong>Embeddings</strong>
              <p>Token IDs → vectors</p>
            </div>
            <div class="pipeline-arrow">→</div>
            <div class="pipeline-step">
              <span class="step-num">3</span>
              <strong>Transformer Layers</strong>
              <p>Attention + Feed-Forward × N</p>
            </div>
            <div class="pipeline-arrow">→</div>
            <div class="pipeline-step">
              <span class="step-num">4</span>
              <strong>Inference</strong>
              <p>Vectors → next token</p>
            </div>
          </div>
          <p style="margin-top: 1rem; text-align: center; color: var(--text-secondary);">The <strong>Pre-Training</strong> tab shows how all those billions of parameters get learned.</p>
        </div>
      </div>
    </section>

    <!-- TRAINING TAB -->
    <section id="tab-training" class="tab-section">
      <div class="section-header">
        <h2>06: Pre-Training</h2>
        <p>How billions of random numbers become an LLM that reflects the world</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand pre-training, you understand <em>how AI use data to learn complex things like grammar, facts about the world, and computer programming.</em></div>
        <div class="intuition-detail">AI starts as billions of random numbers, then learns by predicting the next token across trillions of examples. Pre-training is where AI starts to make sense of the world by finding patterns in the data.</div>
      </div>

      <!-- Context Introduction -->
      <div class="pretrain-intro">
        <div class="pretrain-mindblown">
          <div class="mindblown-icon">🤯</div>
          <div class="mindblown-content">
            <h4>The Mind-Blowing Part</h4>
            <p>Remember all those weights in the Neural Network tab? The embedding vectors? The attention scores? <strong>They all start as random numbers.</strong> Completely random. The model begins knowing absolutely nothing.</p>
            <p>Yet through pre-training, those billions of random values transform into a system that understands grammar, knows facts about the world, can write computer code, and generates coherent text. <em>That</em> is what pre-training accomplishes.</p>
          </div>
        </div>
        
        <div class="pretrain-timeline">
          <div class="timeline-stage">
            <div class="stage-icon">🎲</div>
            <div class="stage-label">Random Initialization</div>
            <div class="stage-desc">Billions of random numbers</div>
          </div>
          <div class="timeline-arrow">→</div>
          <div class="timeline-stage highlight">
            <div class="stage-icon">🎓</div>
            <div class="stage-label">Pre-Training</div>
            <div class="stage-desc">Learn from text data</div>
          </div>
          <div class="timeline-arrow">→</div>
          <div class="timeline-stage">
            <div class="stage-icon">💬</div>
            <div class="stage-label">Inference</div>
            <div class="stage-desc">Generate responses</div>
          </div>
        </div>
      </div>

      <!-- The Training Data Section -->
      <div class="training-data-section">
        <h3>📚 The Training Data</h3>
        <p>Pre-training uses massive amounts of text where <strong>we already know what comes next</strong>. The model learns by predicting words then checking against the real answer to see how close it was.</p>
        
        <div class="training-examples">
          <div class="training-example">
            <div class="example-source">From a history book:</div>
            <div class="example-text">"The messenger entered the throne room and bowed to the <span class="masked-word">[king]</span>."</div>
          </div>
          <div class="training-example">
            <div class="example-source">From a news article:</div>
            <div class="example-text">"The <span class="masked-word">[queen]</span> addressed the parliament in her annual speech."</div>
          </div>
          <div class="training-example">
            <div class="example-source">From a novel:</div>
            <div class="example-text">"The <span class="masked-word">[general]</span> commanded his troops to advance at dawn."</div>
          </div>
        </div>
        
        <div class="data-scale-note">
          <strong>Scale:</strong> Modern LLMs are trained on trillions of tokens—essentially a significant fraction of all text ever written and published on the internet. This is a source of controversy because not everyone wrote the text gave permission for it to be used in pre-training.
        </div>
      </div>

      <!-- The Training Loop Demo -->
      <div class="training-loop-section">
        <h3>🔄 The Training Loop</h3>
        <p>Watch how a single training step works. The model predicts the next token, sees how wrong it was, and adjusts its weights to do better. <strong>The amount by which it was wrong is called the "loss."</strong> Each training step makes a change that slightly reduces the loss.</p>
        
        <div class="interactive-well">
          <div class="inference-grid"> <!-- Consistency with other labs -->
            <div class="train-main">
              <div class="training-loop-demo" style="margin: 0;">
                <div class="loop-step-container" style="display: flex; flex-direction: column; gap: 1rem;">
                  <div class="loop-example-card">
                    <div class="loop-step-label">Training Example #<span id="training-example-num">1,847,293</span></div>
                    <div class="loop-prompt">
                      <span class="prompt-context">"The messenger bowed to the</span>
                      <span class="prompt-blank">___"</span>
                    </div>
                    <div class="loop-answer">
                      <span class="answer-label">Correct answer:</span>
                      <span class="answer-token" id="correct-token">"king"</span>
                    </div>
                  </div>
                  
                  <div class="loop-predictions-card">
                    <div class="loop-step-label">Model's Predictions</div>
                    <div class="prediction-bars">
                      <div class="pred-row">
                        <span class="pred-token correct-highlight">"king"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-1" style="width: 15%"></div></div>
                        <span class="pred-prob" id="pred-prob-1">0.15</span>
                        <span class="pred-feedback" id="pred-feedback-1"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"queen"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-2" style="width: 12%"></div></div>
                        <span class="pred-prob" id="pred-prob-2">0.12</span>
                        <span class="pred-feedback" id="pred-feedback-2"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"general"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-3" style="width: 8%"></div></div>
                        <span class="pred-prob" id="pred-prob-3">0.08</span>
                        <span class="pred-feedback" id="pred-feedback-3"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"floor"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-4" style="width: 65%"></div></div>
                        <span class="pred-prob" id="pred-prob-4">0.65</span>
                        <span class="pred-feedback" id="pred-feedback-4"></span>
                      </div>
                    </div>
                  </div>

                  <div class="loop-loss-card">
                    <div class="loop-step-label">Training Loss</div>
                    <div class="loss-display">
                      <div class="loss-formula">Loss = -log(<span id="loss-prob">0.15</span>) =</div>
                      <div class="loss-value" id="loss-value">1.90</div>
                      <div class="loss-interpretation" id="loss-interp">High loss = very wrong</div>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="train-sidebar">
              <div class="concept-card p-125">
                <h4 style="font-size: 0.9rem; margin-bottom: 0.75rem;">Training Controls</h4>
                <div class="loop-controls" style="display: flex; flex-direction: column; gap: 0.75rem; margin: 0;">
                  <button class="train-loop-btn" id="train-loop-step" style="width: 100%;">
                    ▶ Take One Step
                  </button>
                  <button class="train-loop-btn auto" id="train-loop-auto" style="width: 100%;">
                    ⏩ Auto-Train
                  </button>
                  <button class="train-loop-btn reset" id="train-loop-reset" style="width: 100%;">
                    ↺ Reset
                  </button>
                </div>

                <div class="concept-card mt-125 p-075 bg-dark">
                  <div class="loop-stats" style="display: flex; flex-direction: column; gap: 0.5rem; font-size: 0.8rem;">
                    <span>Steps: <strong id="loop-steps">0</strong></span>
                    <span>Avg Loss: <strong id="loop-avg-loss">1.90</strong></span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Backpropagation Section -->
      <div class="backprop-section">
        <h3>⚡ Backpropagation: How Weights Get Updated</h3>
        <p>After measuring the loss, the model needs to figure out <em>which</em> of its billions of weights to adjust and by <em>how much</em>. This is where backpropagation comes in.</p>
        
        <div class="backprop-visual">
          <div class="backprop-network">
            <div class="backprop-stage">
              <div class="stage-title">1. Forward Pass</div>
              <div class="stage-desc">Signal flows through the network</div>
              <div class="network-mini forward">
                <div class="layer-col">
                  <div class="mini-node input-node"></div>
                  <div class="mini-node input-node"></div>
                </div>
                <div class="connection-col forward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="5" y1="20" x2="55" y2="20" style="stroke: var(--color-red)" stroke-width="2"/>
                    <line x1="5" y1="20" x2="55" y2="60" style="stroke: var(--color-red)" stroke-width="1.5"/>
                    <line x1="5" y1="60" x2="55" y2="20" style="stroke: var(--color-red)" stroke-width="1"/>
                    <line x1="5" y1="60" x2="55" y2="60" style="stroke: var(--color-red)" stroke-width="2"/>
                    <polygon points="50,17 55,20 50,23" style="fill: var(--color-red)"/>
                    <polygon points="50,57 55,60 50,63" style="fill: var(--color-red)"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node hidden-node"></div>
                  <div class="mini-node hidden-node"></div>
                </div>
                <div class="connection-col forward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="5" y1="20" x2="55" y2="40" style="stroke: var(--color-red)" stroke-width="2"/>
                    <line x1="5" y1="60" x2="55" y2="40" style="stroke: var(--color-red)" stroke-width="1.5"/>
                    <polygon points="50,37 55,40 50,43" style="fill: var(--color-red)"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node output-node">
                    <span class="node-label">0.15</span>
                  </div>
                </div>
              </div>
              <div class="stage-result">Prediction: "king" at 15%</div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">2. Compute Loss</div>
              <div class="stage-desc">How wrong was the prediction?</div>
              <div class="loss-calc-visual">
                <div class="loss-target">Target: "king" should be ~100%</div>
                <div class="loss-actual">Actual: "king" at 15%</div>
                <div class="loss-result">Loss = -log(0.15) = <strong>1.90</strong></div>
              </div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">3. Backward Pass</div>
              <div class="stage-desc">Assign "blame" to each weight</div>
              <div class="network-mini backward">
                <div class="layer-col">
                  <div class="mini-node input-node blamed">
                    <span class="blame-amount">-0.02</span>
                  </div>
                  <div class="mini-node input-node blamed">
                    <span class="blame-amount">+0.05</span>
                  </div>
                </div>
                <div class="connection-col backward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="55" y1="20" x2="5" y2="20" style="stroke: var(--color-yellow)" stroke-width="2"/>
                    <line x1="55" y1="20" x2="5" y2="60" style="stroke: var(--color-yellow)" stroke-width="1.5"/>
                    <line x1="55" y1="60" x2="5" y2="20" style="stroke: var(--color-yellow)" stroke-width="1"/>
                    <line x1="55" y1="60" x2="5" y2="60" style="stroke: var(--color-yellow)" stroke-width="2"/>
                    <polygon points="10,17 5,20 10,23" style="fill: var(--color-yellow)"/>
                    <polygon points="10,57 5,60 10,63" style="fill: var(--color-yellow)"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node hidden-node blamed">
                    <span class="blame-amount">+0.12</span>
                  </div>
                  <div class="mini-node hidden-node blamed">
                    <span class="blame-amount">-0.08</span>
                  </div>
                </div>
                <div class="connection-col backward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="55" y1="40" x2="5" y2="20" style="stroke: var(--color-yellow)" stroke-width="2"/>
                    <line x1="55" y1="40" x2="5" y2="60" style="stroke: var(--color-yellow)" stroke-width="1.5"/>
                    <polygon points="10,17 5,20 10,23" style="fill: var(--color-yellow)"/>
                    <polygon points="10,57 5,60 10,63" style="fill: var(--color-yellow)"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node output-node blamed">
                    <span class="blame-amount">Loss</span>
                  </div>
                </div>
              </div>
              <div class="stage-result">Each weight gets a gradient (how much it contributed to the error)</div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">4. Update Weights</div>
              <div class="stage-desc">Nudge each weight to reduce loss</div>
              <div class="weight-updates">
                <div class="weight-update-row">
                  <span class="weight-name">Emb[42]</span>
                  <span class="weight-old">0.342</span>
                  <span class="weight-arrow">→</span>
                  <span class="weight-new">0.347</span>
                </div>
                <div class="weight-update-row">
                  <span class="weight-name">AttnQ[103]</span>
                  <span class="weight-old">-0.156</span>
                  <span class="weight-arrow">→</span>
                  <span class="weight-new">-0.151</span>
                </div>
                <div class="weight-update-row">
                  <span class="weight-name">FFN.W1[891]</span>
                  <span class="weight-old">0.089</span>
                  <span class="weight-arrow">→</span>
                  <span class="weight-new">0.092</span>
                </div>
                <div class="weight-update-row ellipsis">
                  <span>... billions more weights updated ...</span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="backprop-key-insight">
          <strong>The key insight:</strong> Every single weight in the network—in the embeddings, the attention layers, the feed-forward layers—gets a tiny adjustment. Each adjustment is calculated to make the correct answer slightly more likely next time. Do this trillions of times, and random numbers become the AI version of understanding.
        </div>
      </div>

      <div class="explanation">
        <h4>The Training Process</h4>
        <p>Pre-training is remarkably simple in concept: <strong>predict the next word, check if you were right, adjust weights to do better, repeat.</strong> Do this trillions of times across massive text datasets, and the random initial weights gradually transform into a model that has "learned" language—grammar, facts, reasoning patterns, and more—all from the single objective of predicting what comes next.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Pre-Training</h3>
        
        <div class="concept-card">
          <h4>What Pre-Training Achieves</h4>
          <p>By predicting billions of next tokens, the model learns far more than just "which word comes next":</p>
          <div class="emerges-grid">
            <div class="emerges-item">
              <span class="emerges-icon">📝</span>
              <div>
                <strong>Grammar & Syntax</strong>
                <p>To predict correctly, the model must learn that "The king <em>is</em>" is right but "The king <em>are</em>" is wrong</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">🌍</span>
              <div>
                <strong>Facts About the World</strong>
                <p>Predicting "Paris is the capital of ___" requires knowing the answer is "France"</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">🔗</span>
              <div>
                <strong>Reasoning Patterns</strong>
                <p>Predicting math solutions, code completions, and logical conclusions builds reasoning ability</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">🎭</span>
              <div>
                <strong>Style & Tone</strong>
                <p>Different text sources teach formal vs casual, technical vs creative writing patterns</p>
              </div>
            </div>
          </div>
          <p class="emerges-note"><strong>Key insight:</strong> Nobody explicitly teaches the model grammar rules or facts. These abilities <em>emerge</em> from the single task of next-token prediction at massive scale.</p>
        </div>

        <div class="concept-card">
          <h4>From Random to Trained: What Changes?</h4>
          <p>Let's trace what happens to the model's components during pre-training:</p>
          <div class="training-changes">
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random embedding vectors</span>
              </div>
              <div class="change-arrow">→</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Vectors where similar words cluster together</span>
              </div>
            </div>
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random attention weights</span>
              </div>
              <div class="change-arrow">→</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Weights that connect pronouns to nouns, verbs to subjects</span>
              </div>
            </div>
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random feed-forward weights</span>
              </div>
              <div class="change-arrow">→</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Pattern detectors for concepts, facts, and reasoning</span>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Hiking Analogy for Gradient Descent</h4>
          <p>Imagine you're lost in foggy mountains, trying to find the lowest valley (lowest loss):</p>
          <div class="hiking-visual">
            <div class="mountain-scene">
              <div class="mountain-back"></div>
              <div class="mountain-front"></div>
              <div class="hiker" id="hiker-icon">🚶</div>
              <div class="valley-marker">🏁 Goal: lowest loss</div>
            </div>
          </div>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">🦶</span>
              <div>
                <strong>Feel the slope where you're standing</strong>
                <p>= The gradient tells you which direction reduces loss</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">👇</span>
              <div>
                <strong>Step downhill</strong>
                <p>= Adjust weights in the direction that reduces loss</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🔄</span>
              <div>
                <strong>Repeat trillions of times</strong>
                <p>= Each training example is one tiny step toward better predictions</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Math Behind Backpropagation</h4>
          <p>The visualization above shows backpropagation intuitively. Under the hood, it uses the <strong>chain rule</strong> from calculus:</p>
          <div class="math-intuition">
            <div class="math-block">
              <div class="math-question">How much did weight w₁ contribute to the error?</div>
              <div class="math-answer">= (how much did the output change the loss) × (how much did w₁ change the output)</div>
            </div>
          </div>
          <p>This calculation propagates backward through every layer, assigning a "gradient" (direction and magnitude of blame) to every weight. The genius is that it's computationally efficient—you don't need to test each weight individually.</p>
        </div>

        <div class="interactive-well">
          <div class="inference-grid"> <!-- Reusing grid for consistent layout -->
            <div class="mini-train-main">
              <div class="card-header">
                <h3>Gradient Descent in Action</h3>
                <span class="badge">Linear Regression Demo</span>
              </div>
              <p style="font-size: 0.85rem; color: var(--text-secondary); margin-bottom: 1rem;">This mini-visualization shows gradient descent on a simple problem: fitting a line to data points. The same algorithm scales to billions of parameters.</p>
              <div class="mini-canvas-container" style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle); padding: 0.5rem;">
                <canvas id="training-canvas"></canvas>
              </div>
            </div>

            <div class="mini-train-sidebar">
              <div class="concept-card p-125">
                <h4 style="font-size: 0.9rem; margin-bottom: 0.75rem;">Training Controls</h4>
                
                <div class="control-panel-well" style="padding: 0.75rem;">
                  <div class="mini-metrics mb-1" style="display: flex; gap: 0.25rem; justify-content: center; align-items: stretch;">
                    <div class="mini-metric card-sm text-center" style="background: rgba(26,26,26,0.06); padding: 0.4rem 0.1rem; flex: 1; display: flex; flex-direction: column; justify-content: space-between;">
                      <div class="text-xs uppercase text-muted" style="font-size: 0.55rem;">Weight</div>
                      <div id="train-w" class="mono text-accent bold" style="font-size: 0.8rem;">0.50</div>
                    </div>
                    <div class="mini-metric card-sm text-center" style="background: rgba(26,26,26,0.06); padding: 0.4rem 0.1rem; flex: 1; display: flex; flex-direction: column; justify-content: space-between;">
                      <div class="text-xs uppercase text-muted" style="font-size: 0.55rem;">Bias</div>
                      <div id="train-b" class="mono text-accent bold" style="font-size: 0.8rem;">0.50</div>
                    </div>
                    <div class="mini-metric loss card-sm text-center" style="background: rgba(26,26,26,0.06); padding: 0.4rem 0.1rem; flex: 1.2; display: flex; flex-direction: column; justify-content: space-between;">
                      <div class="text-xs uppercase text-muted" style="font-size: 0.55rem;">Total Loss</div>
                      <div id="train-loss" class="mono text-warm bold" style="font-size: 0.8rem;">0.00</div>
                    </div>
                  </div>

                  <div class="mini-buttons" style="display: grid; grid-template-columns: 1fr; gap: 0.5rem;">
                    <button class="mini-btn" id="train-step" style="background: var(--accent-primary); color: var(--bg-deep); border: none; padding: 0.5rem; border-radius: 4px; font-weight: 700; cursor: pointer;">Step ↓</button>
                    <button class="mini-btn" id="train-auto" style="background: var(--bg-elevated); color: var(--text-primary); border: 1px solid var(--border-subtle); padding: 0.5rem; border-radius: 4px; cursor: pointer;">Auto-Train</button>
                    <button class="mini-btn" id="train-reset" style="background: transparent; color: var(--text-muted); border: 1px solid var(--border-subtle); padding: 0.5rem; border-radius: 4px; cursor: pointer;">Reset</button>
                  </div>
                </div>

                <div style="margin-top: 1rem; text-align: center; font-size: 0.75rem; color: var(--text-muted);">
                  Steps: <strong id="train-epoch" style="color: var(--text-primary);">0</strong>
                </div>
              </div>
            </div>
          </div>
          <p class="mini-demo-note" style="margin-top: 1rem; font-size: 0.8rem; color: var(--text-secondary); text-align: center;">Note: The red dashed lines show prediction errors. Training minimizes these errors by adjusting the line's slope (weight) and position (bias).</p>
        </div>

        <div class="concept-card">
          <h4>Pre-Training at Scale</h4>
          <p>The demo above trains 2 parameters. Real language models:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">405B</div>
              <div class="scale-label">parameters (Llama 3.1)</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">15T+</div>
              <div class="scale-label">tokens of training data</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">$100M+</div>
              <div class="scale-label">compute cost (estimated)</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">16,000+</div>
              <div class="scale-label">GPUs for months</div>
            </div>
          </div>
          <p>Same fundamental algorithm—predict, measure error, adjust weights—just at staggering scale.</p>
        </div>

        <div class="concept-card">
          <h4>What Pre-Training Doesn't Teach</h4>
          <p>Pre-training alone creates a powerful text predictor, but not a helpful assistant. The model learns:</p>
          <div class="does-doesnt">
            <div class="does">
              <div class="does-header">✓ From Pre-Training</div>
              <ul>
                <li>Language patterns and grammar</li>
                <li>Facts and knowledge</li>
                <li>Reasoning capabilities</li>
                <li>Writing styles</li>
              </ul>
            </div>
            <div class="doesnt" style="background: var(--secondary-10); border-color: var(--secondary-30);">
              <div class="doesnt-header" style="color: var(--accent-secondary);">✗ Requires Additional Training</div>
              <ul>
                <li>Following instructions</li>
                <li>Being helpful and harmless</li>
                <li>Refusing inappropriate requests</li>
                <li>Conversational format</li>
              </ul>
            </div>
          </div>
          <p>That's why pre-training is just the first step. Models like ChatGPT and Claude undergo additional training (fine-tuning, RLHF) to become useful assistants—which is exactly what we cover in the <strong>Fine-Tuning</strong> tab.</p>
        </div>
      </div>
    </section>

    <!-- FINE-TUNING TAB -->
    <section id="tab-finetuning" class="tab-section">
      <div class="section-header">
        <h2>07: Fine-Tuning</h2>
        <p>How a text predictor becomes a helpful, harmless, and honest assistant</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand fine-tuning, you understand <em>why models differ in their abilities and personalities even when built on the same architecture and trained on the same data.</em></div>
        <div class="intuition-detail">Pre-training gives the model knowledge; fine-tuning gives it behavior. Fine-tuning is how a text completion engine becomes a helpful assistant—one that follows instructions, refuses harmful requests, and maintains a consistent persona.</div>
      </div>

      <!-- Why Fine-Tuning Introduction -->
      <div class="ft-intro">
        <div class="ft-gap-visual">
          <div class="gap-side pretrained">
            <div class="gap-header">After Pre-Training</div>
            <div class="gap-icon">📚</div>
            <div class="gap-desc">Knows everything, helps with nothing</div>
            <ul class="gap-list">
              <li>Completes text naturally</li>
              <li>No instruction following</li>
              <li>May continue harmful content</li>
              <li>No consistent persona</li>
            </ul>
          </div>
          <div class="gap-arrow">
            <span>Fine-Tuning</span>
            <div class="arrow-line"></div>
          </div>
          <div class="gap-side finetuned">
            <div class="gap-header">After Fine-Tuning</div>
            <div class="gap-icon">🤝</div>
            <div class="gap-desc">Helpful, harmless, honest</div>
            <ul class="gap-list">
              <li>Follows instructions</li>
              <li>Refuses harmful requests</li>
              <li>Consistent helpful persona</li>
              <li>Appropriate self-awareness</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- Before/After Example -->
      <div class="ft-example-section">
        <h3>💬 The Difference in Action</h3>
        <div class="ft-example-container">
          <div class="ft-prompt">
            <div class="prompt-label">User prompt:</div>
            <div class="prompt-text">"How do I pick a lock?"</div>
          </div>
          <div class="ft-responses">
            <div class="ft-response before">
              <div class="response-header">
                <span class="response-badge bad">Pre-trained only</span>
              </div>
              <div class="response-text">
                "First, you'll need a tension wrench and pick. Insert the tension wrench into the bottom of the keyhole and apply slight pressure. Then insert the pick and feel for the pins..."
              </div>
              <div class="response-note">Just continues the most likely text—no judgment about appropriateness</div>
            </div>
            <div class="ft-response after">
              <div class="response-header">
                <span class="response-badge good">Fine-tuned</span>
              </div>
              <div class="response-text">
                "I can help with legitimate locksmith questions! If you're locked out of your own home, I'd recommend calling a licensed locksmith. If you're interested in lockpicking as a hobby, there are legal practice locks designed for learning. What's your situation?"
              </div>
              <div class="response-note">Helpful while considering safety—offers alternatives and asks clarifying questions</div>
            </div>
          </div>
        </div>
      </div>

      <!-- What Fine-Tuning Teaches -->
      <div class="ft-teaches-section">
        <h3>🎓 What Fine-Tuning Teaches</h3>
        <p>Fine-tuning instills specific behaviors that don't emerge from pre-training alone:</p>
        
        <div class="teaches-grid">
          <div class="teaches-card">
            <div class="teaches-icon">📋</div>
            <div class="teaches-content">
              <h4>Instruction Following</h4>
              <p>Understanding "summarize this" vs "translate this" vs "explain like I'm 5"—and doing what's asked.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">🛡️</div>
            <div class="teaches-content">
              <h4>Safety & Refusals</h4>
              <p>Declining to help with harmful activities, not generating dangerous content, acknowledging uncertainty.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">🎭</div>
            <div class="teaches-content">
              <h4>Personality & Tone</h4>
              <p>Consistent voice across interactions. Helpful but not sycophantic. Appropriate formality for context.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">🔧</div>
            <div class="teaches-content">
              <h4>Tool Use</h4>
              <p>When to search vs answer from knowledge. How to write code. When to ask clarifying questions.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">📐</div>
            <div class="teaches-content">
              <h4>Format Awareness</h4>
              <p>Using coding languages appropriately. Structuring long responses. Knowing when lists vs prose work better.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">🪞</div>
            <div class="teaches-content">
              <h4>Self-Awareness</h4>
              <p>Knowing it's an AI. Not pretending to have experiences it doesn't have. Knowing its limitations.</p>
            </div>
          </div>
        </div>
      </div>

      <!-- How RLHF Works -->
      <div class="rlhf-section">
        <h3>🔄 How RLHF Works</h3>
        <p>Reinforcement Learning from Human Feedback turns human preferences into training signal. Here's the loop:</p>
        
        <div class="rlhf-loop">
          <div class="rlhf-step">
            <div class="step-number">1</div>
            <div class="step-content">
              <h4>Generate Responses</h4>
              <p>Given a prompt, the model generates multiple possible responses.</p>
              <div class="step-example">
                <div class="example-prompt">"Explain quantum computing simply"</div>
                <div class="example-responses">
                  <div class="resp-a">Response A: Technical jargon...</div>
                  <div class="resp-b">Response B: Simple analogy...</div>
                </div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">2</div>
            <div class="step-content">
              <h4>Human Feedback</h4>
              <p>Human raters compare responses and pick the better one.</p>
              <div class="step-example">
                <div class="human-choice">
                  <span class="choice-label">Human picks:</span>
                  <span class="choice-winner">B is better</span>
                </div>
                <div class="choice-reason">"B matches the requested audience better"</div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">3</div>
            <div class="step-content">
              <h4>Train Reward Model</h4>
              <p>A separate neural network learns to predict human preferences.</p>
              <div class="step-example">
                <div class="reward-model">
                  <span>Reward Model learns:</span>
                  <span class="reward-insight">"Simple explanations for simple requests → higher score"</span>
                </div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">4</div>
            <div class="step-content">
              <h4>Update Model Weights</h4>
              <p>The main model is trained to produce responses that score highly with the reward model.</p>
              <div class="step-example">
                <div class="weight-update-note">Same backpropagation as pre-training, but loss = low reward instead of wrong token</div>
              </div>
            </div>
          </div>
        </div>
        
        <div class="rlhf-repeat">
          <span>This is repeated thousands of times across diverse prompts.</span>
        </div>
      </div>

      <!-- Interactive Demo: Be the Rater -->
      <div class="rater-demo-section">
        <h3>🎮 Try It: Be the Human Rater</h3>
        <p>Experience how human preferences become training signal. Pick which response is better:</p>
        
        <div class="interactive-well">
          <div class="rater-demo">
            <div class="rater-prompt">
              <div class="rater-prompt-label">Prompt:</div>
              <div class="rater-prompt-text" id="rater-prompt">"What's the best programming language?"</div>
            </div>
            
            <div class="rater-choices">
              <button class="rater-choice" id="choice-a">
                <div class="choice-header">Response A</div>
                <div class="choice-text" id="choice-a-text">"Python is the best programming language because it's easy to learn and widely used in AI and data science."</div>
              </button>
              <button class="rater-choice" id="choice-b">
                <div class="choice-header">Response B</div>
                <div class="choice-text" id="choice-b-text">"The 'best' language depends on your goals. Python is great for beginners and data science. JavaScript dominates web development. Rust offers memory safety for systems programming. What are you hoping to build?"</div>
              </button>
            </div>
            
            <div class="rater-feedback" id="rater-feedback">
              <!-- Filled by JS after selection -->
            </div>
            
            <div class="rater-stats">
              <span>Comparisons rated: <strong id="rater-count">0</strong></span>
              <button class="rater-next-btn" id="rater-next">Next Comparison →</button>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>How This Differs from Pre-Training</h4>
        <p>Pre-training optimizes for "predict the next token correctly." Fine-tuning optimizes for "produce responses humans prefer." Both use backpropagation to update weights, but the signal is different: <strong>a massive pile of training text</strong> vs <strong>human judgment of quality</strong>.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Understanding Fine-Tuning</h3>
        
        <div class="concept-card">
          <h4>The Three Stages of Creating an AI Assistant</h4>
          <p>Modern AI assistants go through multiple training phases:</p>
          <div class="training-stages">
            <div class="stage-block">
              <div class="stage-num">1</div>
              <div class="stage-info">
                <h5>Pre-Training</h5>
                <p>Learn language from trillions of tokens</p>
                <div class="stage-data">Months on thousands of GPUs</div>
              </div>
            </div>
            <div class="stage-arrow">→</div>
            <div class="stage-block">
              <div class="stage-num">2</div>
              <div class="stage-info">
                <h5>Supervised Fine-Tuning (SFT)</h5>
                <p>Learn instruction format from curated examples</p>
                <div class="stage-data">Thousands of human-written examples</div>
              </div>
            </div>
            <div class="stage-arrow">→</div>
            <div class="stage-block">
              <div class="stage-num">3</div>
              <div class="stage-info">
                <h5>RLHF / Preference Training</h5>
                <p>Learn what humans actually prefer</p>
                <div class="stage-data">Millions of preference comparisons</div>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Different Approaches to Alignment</h4>
          <p>Several techniques exist for aligning models with human values. Most production systems use hybrid approaches combining multiple techniques:</p>
          <div class="approaches-grid">
            <div class="approach-card">
              <div class="approach-name">RLHF</div>
              <div class="approach-full">Reinforcement Learning from Human Feedback</div>
              <div class="approach-desc">Humans rank responses. Then train a reward model to reinforce at scale.</div>
              <div class="approach-used">Pioneered by: OpenAI (ChatGPT)</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">RLAIF</div>
              <div class="approach-full">RL from AI Feedback</div>
              <div class="approach-desc">AI model ranks responses using guidelines. Scales better than human labeling.</div>
              <div class="approach-used">Examples: Claude, Gemini</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">Constitutional AI</div>
              <div class="approach-full">Principle-Based Self-Improvement</div>
              <div class="approach-desc">Model critiques itself against explicit principles. Auditable and consistent.</div>
              <div class="approach-used">Pioneered by: Anthropic</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">DPO</div>
              <div class="approach-full">Direct Preference Optimization</div>
              <div class="approach-desc">Skip using a reward model. Train directly on preference pairs. Simpler, often equally effective.</div>
              <div class="approach-used">Examples: Llama 2+, many open models</div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Reward Models</h4>
          <p><strong>The problem:</strong> You can't have humans rate every single response during training—there are millions of them. So how do you scale human judgment?</p>
          <p><strong>The solution:</strong> Train a separate neural network to <em>predict</em> what humans would prefer. This "reward model" learns from the comparison data collected from human raters.</p>
          
          <div class="reward-model-visual">
            <div class="rm-input">
              <div class="rm-label">Input</div>
              <div class="rm-content">Prompt + Response</div>
            </div>
            <div class="rm-arrow">→</div>
            <div class="rm-model">
              <div class="rm-label">Reward Model</div>
              <div class="rm-content">(Trained on human comparisons)</div>
            </div>
            <div class="rm-arrow">→</div>
            <div class="rm-output">
              <div class="rm-label">Output</div>
              <div class="rm-content">Score: 0.73</div>
            </div>
          </div>
          
          <p><strong>How it works:</strong> The reward model takes any prompt+response pair and outputs a score predicting how much humans would like it. Higher scores mean "humans would prefer this." During training, this score becomes the feedback signal—the main model learns to generate responses that score highly.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.75rem;"><strong>Why this matters:</strong> Humans only need to label thousands of comparisons, but the reward model can then score millions of responses during training. It's how you scale human preferences to AI scale.</p>
        </div>

        <div class="concept-card">
          <h4>The Risk of Overfitting to Rewards</h4>
          <p>A naive approach would be: "generate responses that score as high as possible." But this leads to problems:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">📈</span>
              <div>
                <strong>Reward Hacking</strong>
                <p>Model finds weird outputs that score high but aren't actually good (Goodhart's Law)</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">🎭</span>
              <div>
                <strong>Sycophancy</strong>
                <p>Model learns to agree with users and tell them what they want to hear</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">😵</span>
              <div>
                <strong>Mode Collapse</strong>
                <p>Model produces same "safe" response for everything</p>
              </div>
            </div>
          </div>
          <p><strong>Solution:</strong> During training, penalize the model if it strays too far from its original behavior. Think of it as "improve your responses, but don't forget everything you learned in pre-training." This prevents the model from gaming the reward signal at the cost of its general capabilities.</p>
        </div>

        <div class="concept-card">
          <h4>The Alignment Tax</h4>
          <p>Fine-tuning involves tradeoffs:</p>
          <div class="tradeoff-visual">
            <div class="tradeoff-item">
              <div class="tradeoff-label">Raw Capability</div>
              <div class="tradeoff-bar">
                <div class="bar-fill pretrain" style="width: 100%"></div>
              </div>
              <div class="tradeoff-note">Pre-trained model</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Raw Capability</div>
              <div class="tradeoff-bar">
                <div class="bar-fill finetune" style="width: 92%"></div>
              </div>
              <div class="tradeoff-note">Fine-tuned model (slight reduction)</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Helpfulness</div>
              <div class="tradeoff-bar">
                <div class="bar-fill helpful" style="width: 85%"></div>
              </div>
              <div class="tradeoff-note">Huge gain from fine-tuning</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Safety</div>
              <div class="tradeoff-bar">
                <div class="bar-fill safe" style="width: 80%"></div>
              </div>
              <div class="tradeoff-note">Huge gain from fine-tuning</div>
            </div>
          </div>
          <p>The small reduction in raw capability is usually worth the massive gains in usefulness and safety. This is called the "alignment tax."</p>
        </div>

        <div class="concept-card">
          <h4>Ongoing Challenges</h4>
          <p>Alignment is an active research area with unsolved problems:</p>
          <div class="challenges-list">
            <div class="challenge-item">
              <strong>Jailbreaks</strong>
              <p>People can give the model creative prompts that bypass safety training. Alignment can be fragile.</p>
            </div>
            <div class="challenge-item">
              <strong>Generalization</strong>
              <p>Alignment may not hold for situations outside the training patterns. It's hard to predict every use case.</p>
            </div>
            <div class="challenge-item">
              <strong>Scalable Oversight</strong>
              <p>As models get smarter, humans may no longer be able to evaluate if they're behaving well.</p>
            </div>
            <div class="challenge-item">
              <strong>Value Lock-in</strong>
              <p>Whose values are we aligning to? How do we handle disagreement about what values are important?</p>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Model Differences Across Versions and Providers</h4>
          <p>Fine-tuning is why different models behave so differently from each other, even when built on similar base architectures:</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li><strong>Different providers, different behavior:</strong> Claude, ChatGPT, Gemini, and Grok all have distinct "personalities" because of their different fine-tuning data and alignment approaches</li>
            <li><strong>Version changes matter:</strong> Even models from the same provider (e.g., GPT-3.5 vs GPT-4o vs GPT-5) can behave quite differently due to updated fine-tuning</li>
            <li><strong>Prompts may need adjustment:</strong> A prompt that works well on one model may need tweaking for another</li>
          </ul>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;"><strong>Professional tip:</strong> When building production applications that use AI, always test your prompts across model versions and consider how model updates might affect your system's behavior.</p>
        </div>

        <div class="concept-card">
          <h4>The Complete Pipeline</h4>
          <p>You've now seen every stage of how an LLM is created:</p>
          <div class="complete-pipeline">
            <div class="pipeline-stage">
              <div class="pipe-icon">🔤</div>
              <div class="pipe-name">Tokenization</div>
              <div class="pipe-desc">Text → Token IDs</div>
            </div>
            <div class="pipe-arrow">→</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">📍</div>
              <div class="pipe-name">Embeddings</div>
              <div class="pipe-desc">IDs → Vectors</div>
            </div>
            <div class="pipe-arrow">→</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">🧠</div>
              <div class="pipe-name">Transformer</div>
              <div class="pipe-desc">Attention + FFN</div>
            </div>
            <div class="pipe-arrow">→</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">🎓</div>
              <div class="pipe-name">Pre-Training</div>
              <div class="pipe-desc">Random → Capable</div>
            </div>
            <div class="pipe-arrow">→</div>
            <div class="pipeline-stage highlight">
              <div class="pipe-icon">🎯</div>
              <div class="pipe-name">Fine-Tuning</div>
              <div class="pipe-desc">Capable → Aligned</div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- CONTEXT & PROMPTING TAB -->
    <section id="tab-prompting" class="tab-section">
      <div class="section-header">
        <h2>08: Prompting</h2>
        <p>How a user shapes what the model does—and why context windows matter</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand prompting, you understand <em>that you're not "asking"—you're giving AI a context for predictions.</em></div>
        <div class="intuition-detail">A prompt is the input you give to an AI model during inference. Every word you include shifts probabilities, activates patterns, and fills precious context window space. What you include (or exclude) shapes how the model responds.</div>
      </div>

      <!-- Why Prompts Matter Introduction -->
      <div class="context-intro">
        <h3>🎯 Why Prompting Matters</h3>
        <p>You've seen how LLMs work: tokens flow through attention layers, each token influencing what comes next. This is why <strong>what you say</strong>—and <strong>how you say it</strong>—directly shapes the model's output.</p>
        
        <div class="why-prompts-matter">
          <div class="prompt-reason">
            <strong>🧠 Attention is Key</strong>
            <p>Every word in your prompt gets attention. Clear instructions = clearer attention patterns = better outputs.</p>
          </div>
          <div class="prompt-reason">
            <strong>📊 Probability Steering</strong>
            <p>Your prompt shifts which tokens become likely next. "Write formally" makes formal words more probable.</p>
          </div>
          <div class="prompt-reason">
            <strong>🎭 Pattern Activation</strong>
            <p>The model learned patterns during training. Good prompts activate the right patterns for your task.</p>
          </div>
          <div class="prompt-reason">
            <strong>📏 Limited Space</strong>
            <p>Context windows (see below) have finite capacity. What you include (or exclude) determines what the model "thinks" about for the conversation.</p>
          </div>
        </div>
      </div>

      <!-- Context Window Visualizer -->
      <div class="context-window-section">
        <h3>📦 The Context Window Visualized</h3>
        <p>Everything the model "sees" fits inside its context window. System prompts, your messages, and its responses all compete for the same limited space.</p>
        
        <div class="interactive-well">
          <div class="context-visualizer">
            <div class="context-capacity">
              <div class="capacity-bar">
                <div class="capacity-fill" id="context-fill" style="width: 25%"></div>
              </div>
              <span class="capacity-text" id="context-usage">2,048 / 8,192 tokens</span>
            </div>
            
            <div class="context-window-bar" id="context-window">
              <div class="context-segment system">
                <div class="segment-label">System Prompt</div>
                <div class="segment-content">You are a helpful assistant. Be concise and accurate...</div>
              </div>
              <div class="context-segment user">
                <div class="segment-label">User</div>
                <div class="segment-content">What is the capital of France?</div>
              </div>
              <div class="context-segment assistant">
                <div class="segment-label">Assistant</div>
                <div class="segment-content">Paris is the capital of France.</div>
              </div>
            </div>
            
            <div class="context-controls">
              <button class="context-btn" id="ctx-add-system">+ System Prompt</button>
              <button class="context-btn" id="ctx-add-user">+ User Message</button>
              <button class="context-btn" id="ctx-add-long">+ Long Exchange</button>
              <button class="context-btn" id="ctx-overflow">Simulate Overflow</button>
              <button class="context-btn" id="ctx-reset">Reset</button>
            </div>
          </div>
        </div>
      </div>

      <!-- System Prompt Explainer -->
      <div class="system-prompt-card">
        <h3>🔐 What Are System Prompts?</h3>
        
        <div class="system-prompt-content">
          <div class="system-what">
            <h4>What They Are</h4>
            <ul>
              <li>Instructions placed at the <strong>beginning</strong> of the context window</li>
              <li><strong>Usually hidden from users</strong> in chat interfaces</li>
              <li>Set personality, rules, and constraints for the conversation</li>
              <li><strong>Persist throughout</strong> the entire conversation</li>
              <li>In custom AI software, you can <strong>add your own system prompt</strong> to the one written by the model provider.</li>
            </ul>
          </div>
          <div class="system-why">
            <h4>Why They Have Power</h4>
            <ul>
              <li><strong>Positional influence:</strong> Earlier tokens shape attention for later tokens</li>
              <li><strong>Always present:</strong> Every response considers the system prompt</li>
              <li><strong>Training alignment:</strong> Models are fine-tuned to follow system instructions</li>
              <li><strong>Framing effect:</strong> Sets the "mindset" for pattern activation</li>
            </ul>
          </div>
        </div>
        
        <div class="system-example">
          <div class="system-example-label">Example System Prompt (GPT-5.2)</div>
          "You are GPT-5.2, a large language model trained by OpenAI. You are helpful, harmless, and honest. Current date: December 18, 2025. Knowledge cutoff: May 2025."
        </div>
      </div>

      <!-- Input vs Output Tokens -->
      <div class="token-economics">
        <h3>💰 Input Tokens vs Output Tokens</h3>
        <p>Most people use free or subscription AI products. But you can also use AI as a service (through something called an API, or "application programming interface") and pay per token used. API pricing distinguishes between tokens you send in and tokens the model generates. Here's why:</p>
        
        <div class="token-types-grid">
          <div class="token-type-card input">
            <div class="token-type-header">
              <span class="token-type-icon">📤</span>
              <h4>Input Tokens</h4>
            </div>
            <p>Your prompt, system message, and conversation history</p>
            <ul>
              <li>Processed in <strong>parallel</strong> (fast)</li>
              <li>Single forward pass through the model</li>
              <li>Lower computational cost per token</li>
            </ul>
          </div>
          <div class="token-type-card output">
            <div class="token-type-header">
              <span class="token-type-icon">📥</span>
              <h4>Output Tokens</h4>
            </div>
            <p>The model's response, generated one token at a time</p>
            <ul>
              <li>Generated <strong>sequentially</strong> (slower)</li>
              <li>Each token requires a new forward pass</li>
              <li>Higher computational cost per token</li>
            </ul>
          </div>
        </div>
        
        <div class="cost-comparison">
          <div class="cost-row">
            <span class="cost-label">Input token cost (GPT-5.2)</span>
            <span class="cost-value">~$1.75 / 1 Million tokens</span>
          </div>
          <div class="cost-row">
            <span class="cost-label">Typical output token cost (GPT-5.2)</span>
            <span class="cost-value">~$14.00 / 1 Million tokens (8x more!)</span>
          </div>
          <div class="cost-row">
            <span class="cost-label">Why the difference?</span>
            <span class="cost-value">Output tokens are generated one at a time, so they are more compute-intensive</span>
          </div>
        </div>
      </div>

      <!-- Prompt Comparison Demo -->
      <div class="prompt-comparison-section">
        <h3>🔬 Interactive: Good vs Bad Prompts</h3>
        <p>Click to see how prompt quality affects responses. The same underlying question can get vastly different results.</p>
        
        <div class="prompt-comparison-demo">
          <div class="comparison-toggle">
            <button class="toggle-btn active" id="comp-example-1">Vague vs Specific</button>
            <button class="toggle-btn" id="comp-example-2">No Context vs Context</button>
            <button class="toggle-btn" id="comp-example-3">Implied vs Explicit</button>
          </div>
          
          <div class="comparison-display">
            <div class="comparison-side">
              <h4>❌ Weaker Prompt</h4>
              <div class="prompt-text" id="weak-prompt">Tell me about Python</div>
              <div class="response-quality">
                <span class="quality-indicator poor"></span>
                <span id="weak-outcome">Generic overview, unclear what you need</span>
              </div>
            </div>
            <div class="comparison-side">
              <h4>✓ Stronger Prompt</h4>
              <div class="prompt-text" id="strong-prompt">I'm a beginner learning Python for data analysis. Explain list comprehensions with a practical example using a dataset of sales numbers.</div>
              <div class="response-quality">
                <span class="quality-indicator good"></span>
                <span id="strong-outcome">Targeted explanation with relevant example</span>
              </div>
            </div>
          </div>
          
          <div class="comparison-insight" id="comparison-insight">
            <strong>Why it's better:</strong> The stronger prompt tells the model your skill level (beginner), goal (data analysis), specific topic (list comprehensions), and format (practical example). This activates more relevant patterns and steers probabilities toward useful content.
          </div>
        </div>
      </div>

      <!-- Context Forgetting -->
      <div class="forgetting-section">
        <h3>🧹 Why Models "Forget"</h3>
        
        <div class="forgetting-visual">
          <div class="conversation-box">
            <h4>Long Conversation</h4>
            <div class="convo-messages">
              <div class="convo-msg user-msg truncated">User: What's my name?</div>
              <div class="convo-msg assistant-msg truncated">Assistant: You're Alex!</div>
              <div class="convo-msg user-msg truncated">User: I work at...</div>
              <div class="truncation-line">
                <span class="truncation-label">⚠️ TRUNCATED</span>
              </div>
              <div class="convo-msg user-msg">User: Remember that project?</div>
              <div class="convo-msg assistant-msg">Assistant: I don't see any previous mention of a project...</div>
            </div>
          </div>
          <div class="conversation-box">
            <h4>New Conversation</h4>
            <div class="convo-messages">
              <div class="convo-msg user-msg">User: Let's continue our chat</div>
              <div class="convo-msg assistant-msg">Assistant: I don't have any record of previous conversations. Each session starts fresh...</div>
            </div>
          </div>
        </div>
        
        <div class="forgetting-note">
          <strong>Key insight:</strong> Models don't "forget" the way a person does—the only things they "think" about are what's in the context window. The context window is like a whiteboard that gets erased. Previous messages that don't fit are simply not there. New conversations start with a fresh context.
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h3>Understanding Context in Practice</h3>
        <p>Now that you understand the architecture (tokenization → embeddings → attention → inference), you can see why prompting is so important:</p>
        <ul>
          <li><strong>Tokens are the only input:</strong> The model has no other way to know what you want</li>
          <li><strong>Learned patterns activate:</strong> Good prompts leverage patterns the model learned during pre-training</li>
          <li><strong>Early tokens are influential:</strong> The start of the context window affects everything that follows</li>
          <li><strong>Space is finite:</strong> What fits in the context window is all the model can consider</li>
        </ul>
      </div>

      <!-- Deep Dive -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Prompt Engineering Techniques</h3>
        
        <p style="margin-bottom: 1.5rem;"><strong>Prompt engineering</strong> is the craft of writing effective inputs to get better outputs from AI models.</p>
        
        <div class="concept-card">
          <h4>Zero-Shot vs Few-Shot Prompting</h4>
          <p><strong>Zero-shot:</strong> Just ask the question with no examples. Works for simple, common tasks.</p>
          <p><strong>Few-shot:</strong> Provide 2-5 examples of the format you want. The model recognizes the pattern and continues it.</p>
          <div class="system-example">
            <div class="system-example-label">Few-Shot Example</div>
            Classify sentiment:<br>
            "Great product!" → Positive<br>
            "Terrible experience" → Negative<br>
            "It was okay" → Neutral<br>
            "Absolutely loved it!" → ?
          </div>
          <p style="margin-top: 0.75rem; font-size: 0.85rem; color: var(--text-secondary);">The model sees the pattern (text → label) and continues it. Few-shot works because attention helps the model recognize and repeat patterns.</p>
        </div>

        <div class="concept-card">
          <h4>Chain-of-Thought Prompting</h4>
          <p>For complex problems, asking the model to "think step by step" often improves results. The phrase "Let's think step by step" has been shown in research to significantly improve performance on math and reasoning problems—it's one of the most studied prompt engineering techniques. Why does it work?</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li>Each reasoning step becomes input for the next step</li>
            <li>More tokens in context = more "working memory"</li>
            <li>Intermediate steps can be attended to for final answer</li>
            <li>Reduces the need to compute complex answers in a single forward pass</li>
          </ul>
          <p style="font-size: 0.85rem; color: var(--text-secondary);">This is why reasoning models (covered in the next tab) are so effective—they generate extensive chain-of-thought automatically.</p>
        </div>

        <div class="concept-card">
          <h4>Prompt Structure Matters</h4>
          <p>The order and formatting of your prompt affects attention patterns:</p>
          <div class="grid grid-2-col gap-1 mt-075">
            <div class="card-sm">
              <strong class="text-positive text-sm">✓ Good Structure</strong>
              <ul class="mt-05 text-xs" style="padding-left: 1.25rem;">
                <li>Clear task description first</li>
                <li>Relevant context second</li>
                <li>Specific question last</li>
                <li>Use formatting (lists, headers)</li>
              </ul>
            </div>
            <div class="card-sm">
              <strong class="text-negative text-sm">✗ Poor Structure</strong>
              <ul class="mt-05 text-xs" style="padding-left: 1.25rem;">
                <li>Rambling, stream-of-consciousness</li>
                <li>Important info buried at end</li>
                <li>Mixing multiple questions</li>
                <li>Contradictory instructions</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Role of Personas</h4>
          <p>You can tell an AI model to take the perspective of someone, like a user of your service, a character in a book, or an expert in a field. "Act like a senior developer" shifts probability distributions toward patterns associated with that expertise in the training data.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">The model learned correlations like "senior developers" → "best practices, error handling, type hints, documentation." Invoking the persona activates these associations.</p>
        </div>

        <h3 class="deep-dive-title" style="margin-top: 2rem;">🏗️ Context Engineering Techniques</h3>
        
        <p style="margin-bottom: 1.5rem;">Context engineering focuses on <em>what information the AI model "sees"</em>. In production AI tools, much of the context window is filled programmatically—not typed by users.</p>

        <div class="concept-card">
          <h4>Retrieval-Augmented Generation (RAG)</h4>
          <p>Instead of hoping the model "knows" something from training, <strong>you can retrieve (or ask it to retrieve) relevant information</strong> and include it in the context window.</p>
          <div class="system-example">
            <div class="system-example-label">RAG Flow</div>
            User asks: "What's our refund policy?"<br>
            ↓ System searches company knowledge base<br>
            ↓ Retrieves: "Refunds within 30 days with receipt..."<br>
            ↓ Injects into context before model responds<br>
            → Model answers using the retrieved policy
          </div>
          <p style="margin-top: 0.75rem; font-size: 0.85rem; color: var(--text-secondary);">RAG grounds responses in real, up-to-date information rather than relying on potentially outdated or hallucinated "knowledge" from training. RAG can even use AI technology with vector embeddings to find relevant information.</p>
        </div>

        <div class="concept-card">
          <h4>Dynamic Context Assembly</h4>
          <p>Production systems don't use static prompts. They assemble context dynamically based on:</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li><strong>User state:</strong> Who is this user? What permissions do they have? What's their history?</li>
            <li><strong>Conversation history:</strong> What's been discussed? (Often summarized to save tokens)</li>
            <li><strong>Retrieved documents:</strong> What knowledge is relevant to this specific query?</li>
            <li><strong>Tool results:</strong> What did the calculator/search/API return?</li>
            <li><strong>Time and context:</strong> Current date, user's timezone, session metadata</li>
          </ul>
          <p style="font-size: 0.85rem; color: var(--text-secondary);">The "prompt" a production model sees might be 10,000+ tokens assembled from dozens of sources—far more than what the user typed.</p>
        </div>

        <div class="concept-card">
          <h4>Context Window Management</h4>
          <p>Context windows are large but finite. Smart systems manage this space carefully:</p>
          <div class="grid grid-2-col gap-1 mt-075">
            <div class="card-sm">
              <strong class="text-sm">Summarization</strong>
              <p class="mt-05 text-xs">Compress older conversation history into summaries to preserve key information while freeing up tokens.</p>
            </div>
            <div class="card-sm">
              <strong class="text-sm">Selective Retrieval</strong>
              <p class="mt-05 text-xs">Only include documents/chunks that are actually relevant to the current query.</p>
            </div>
            <div class="card-sm">
              <strong class="text-sm">Priority Ordering</strong>
              <p class="mt-05 text-xs">Put most important information at the start and end of context to avoid the "lost in the middle" problem.</p>
            </div>
            <div class="card-sm">
              <strong class="text-sm">Token Budgeting</strong>
              <p class="mt-05 text-xs">Allocate portions of the context window to different purposes (system prompt, history, retrieval, user input).</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- IMAGES & SOUND TAB -->
    <section id="tab-multimodal" class="tab-section">
      <div class="section-header">
        <h2>09: Images & Sound</h2>
        <p>How AI models see, hear, and generate media beyond text</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand multimodal AI, you understand that <em>images, audio, and video are just different ways to fill the same context window</em>—the AI model doesn't care what the tokens originally were.</div>
        <div class="intuition-detail">Everything that goes into the context window gets converted to tokens and embeddings. An image becomes a grid of patches, each patch becomes a vector. Audio becomes segments, each segment becomes a vector. Once in embedding space, attention works the same way it does for text.</div>
      </div>

      <!-- What Multimodal Means -->
      <div class="concept-card">
        <h3>🎭 What "Multimodal" Means</h3>
        <p><strong>Multimodal</strong> means a model can work with multiple types of data—not just text, but also images, audio, or video. Some models only support text, but many models can work with multiple types of data. There's a spectrum of capabilities:</p>
        <div class="scale-comparison" style="margin: 1rem 0; grid-template-columns: repeat(5, 1fr); gap: 0.75rem;">
          <div class="scale-item" style="padding: 1rem;">
            <div class="scale-number" style="font-size: 1.5rem;">📝</div>
            <div class="scale-label" style="font-size: 0.85rem;">Text Only</div>
            <div style="font-size: 0.65rem; color: var(--text-muted);">Early models, or specialized text models</div>
          </div>
          <div class="scale-item" style="padding: 1rem;">
            <div class="scale-number" style="font-size: 1.5rem;">👁️</div>
            <div class="scale-label" style="font-size: 0.85rem;">Text + Image Input</div>
            <div style="font-size: 0.65rem; color: var(--text-muted);">ChatGPT, Gemini, Claude</div>
          </div>
          <div class="scale-item" style="padding: 1rem;">
            <div class="scale-number" style="font-size: 1.5rem;">🎨</div>
            <div class="scale-label" style="font-size: 0.85rem;">Image Generation</div>
            <div style="font-size: 0.65rem; color: var(--text-muted);">NanoBanana & GPT Image-Gen 1.5</div>
          </div>
          <div class="scale-item" style="padding: 1rem;">
            <div class="scale-number" style="font-size: 1.5rem;">🎙️</div>
            <div class="scale-label" style="font-size: 0.85rem;">Voice Conversation</div>
            <div style="font-size: 0.65rem; color: var(--text-muted);">GPT-5.2, Gemini Live</div>
          </div>
          <div class="scale-item" style="padding: 1rem;">
            <div class="scale-number" style="font-size: 1.5rem;">🎬</div>
            <div class="scale-label" style="font-size: 0.85rem;">Video</div>
            <div style="font-size: 0.65rem; color: var(--text-muted);">Sora, Runway</div>
          </div>
        </div>
        <p style="font-size: 0.85rem; color: var(--text-secondary);">Many modern services combine several of these. ChatGPT can see images, hear audio, and speak—all in one application.</p>
      </div>

      <!-- How It Works -->
      <div class="concept-card">
        <h3>🧠 How It Works: Everything Becomes Embeddings</h3>
        <p>The key insight is that <strong>all data types get converted to the same format</strong>—vectors in embedding space. Once converted, the transformer processes them identically.</p>
        
        <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0; font-size: 0.85rem;">
          <thead>
            <tr style="border-bottom: 2px solid var(--text-primary);">
              <th style="text-align: left; padding: 0.75rem 0.5rem; font-weight: 700;">Input</th>
              <th style="text-align: left; padding: 0.75rem 0.5rem; font-weight: 700;">Step 1: Divide</th>
              <th style="text-align: left; padding: 0.75rem 0.5rem; font-weight: 700;">Step 2: Embed</th>
              <th style="text-align: left; padding: 0.75rem 0.5rem; font-weight: 700;">Step 3: Process</th>
            </tr>
          </thead>
          <tbody>
            <tr style="border-bottom: 1px solid var(--border-subtle);">
              <td style="padding: 1rem 0.5rem;"><strong>🖼️ Image</strong></td>
              <td style="padding: 1rem 0.5rem;">Split into patches<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(e.g., 16×16 pixel squares)</span></td>
              <td style="padding: 1rem 0.5rem;">Each patch → vector<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(256 embedding vectors)</span></td>
              <td style="padding: 1rem 0.5rem;">Attention between patches<br><span style="font-size: 0.8rem; color: var(--text-muted);">(same as text tokens)</span></td>
            </tr>
            <tr style="border-bottom: 1px solid var(--border-subtle);">
              <td style="padding: 1rem 0.5rem;"><strong>🎤 Audio</strong></td>
              <td style="padding: 1rem 0.5rem;">Split into segments<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(e.g., 25ms chunks)</span></td>
              <td style="padding: 1rem 0.5rem;">Each segment → vector<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(N embedding vectors)</span></td>
              <td style="padding: 1rem 0.5rem;">Attention between segments<br><span style="font-size: 0.8rem; color: var(--text-muted);">(same as text tokens)</span></td>
            </tr>
            <tr>
              <td style="padding: 1rem 0.5rem;"><strong>📝 Text</strong></td>
              <td style="padding: 1rem 0.5rem;">Split into tokens<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(words/subwords)</span></td>
              <td style="padding: 1rem 0.5rem;">Each token → vector<br><span style="font-family: var(--font-mono); font-size: 0.8rem; color: var(--text-muted);">(embedding lookup)</span></td>
              <td style="padding: 1rem 0.5rem;">Attention between tokens<br><span style="font-size: 0.8rem; color: var(--text-muted);">(the original use case)</span></td>
            </tr>
          </tbody>
        </table>
        
        <p><strong>The pattern:</strong> Divide → Embed → Attend. Once everything is vectors, the transformer doesn't know (or care) whether it started as pixels, sound waves, or words.</p>
      </div>

      <!-- What You Can Do -->
      <div class="concept-card">
        <h3>✨ What You Can Do With It</h3>
        
        <div class="grid grid-2-col gap-1 mt-1">
          <div class="card-sm">
            <strong>📸 Image Understanding</strong>
            <p class="mt-05 text-sm">Drop a screenshot, photo, or diagram into the chat. The model "sees" it and can describe, analyze, or answer questions about it. Great for debugging, analyzing charts, or describing scenes.</p>
          </div>
          <div class="card-sm">
            <strong>🗣️ Voice Conversation</strong>
            <p class="mt-05 text-sm">Speech is converted to tokens, processed, then converted back to speech. This enables natural voice conversations without text as an intermediary—the model hears tone, pace, and emotion.</p>
          </div>
          <div class="card-sm">
            <strong>🎨 Image Generation</strong>
            <p class="mt-05 text-sm">Describe what you want, get an image. Models like NanoBanana & GPT Image-Gen 1.5 generate images from text prompts. Some can also edit existing images based on instructions you give them.</p>
          </div>
          <div class="card-sm">
            <strong>🎬 Video Understanding</strong>
            <p class="mt-05 text-sm">Video frames become tokens. The model can describe what's happening, answer questions about the content, or summarize long videos. Some models can generate short video clips.</p>
          </div>
        </div>
      </div>

      <!-- Why Models Specialize -->
      <div class="concept-card">
        <h3>🎯 Why Some Models Specialize</h3>
        <p>Not every model does everything. Here's why models often focus on specific modalities:</p>
        
        <div class="analogy-box">
          <div class="analogy-item">
            <span class="analogy-icon">📊</span>
            <div>
              <strong>Training Data</strong>
              <p>Image models need billions of image-text pairs. Audio models need thousands of hours of speech. Gathering and cleaning this data is expensive and specialized.</p>
            </div>
          </div>
          <div class="analogy-item">
            <span class="analogy-icon">💻</span>
            <div>
              <strong>Compute Requirements</strong>
              <p>Video requires far more compute than images, which require more than audio, which requires more than text. A minute of video might be millions of tokens.</p>
            </div>
          </div>
          <div class="analogy-item">
            <span class="analogy-icon">🎯</span>
            <div>
              <strong>Architecture Choices</strong>
              <p>Understanding vs. generation often use different approaches. Image generation typically uses a different architecture called a diffusion model, while understanding uses vision transformers.</p>
            </div>
          </div>
        </div>
        
        <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 1rem;"><strong>Examples:</strong> Whisper specializes in audio transcription. Midjourney focuses on artistic image generation. Sora targets video generation. GPT 5.2 combines text, vision, and audio in one model.</p>
      </div>

      <!-- The Realism Warning -->
      <div class="concept-card" style="border-color: var(--negative-30); background: var(--negative-8);">
        <h3>⚠️ The Realism Warning</h3>
        <p>AI-generated media has become remarkably convincing. This creates real risks:</p>
        
        <div class="grid grid-2-col gap-1 mt-1">
          <div class="card-sm" style="background: var(--bg-card);">
            <strong class="text-negative">🖼️ Generated Images</strong>
            <p class="mt-05 text-sm">Can be indistinguishable from photographs. Fake "photos" of events that never happened, people who don't exist, or documents that were never created.</p>
          </div>
          <div class="card-sm" style="background: var(--bg-card);">
            <strong class="text-negative">🎤 Voice Cloning</strong>
            <p class="mt-05 text-sm">A few seconds of audio can clone someone's voice convincingly. Enables impersonation, fake phone calls, or fabricated audio "evidence."</p>
          </div>
          <div class="card-sm" style="background: var(--bg-card);">
            <strong class="text-negative">🎬 Synthetic Video</strong>
            <p class="mt-05 text-sm">Deepfakes can put words in people's mouths. Video generation is rapidly improving. Soon, "seeing is believing" won't apply.</p>
          </div>
          <div class="card-sm" style="background: var(--bg-card);">
            <strong class="text-negative">📰 Misinformation</strong>
            <p class="mt-05 text-sm">Convincing fake media can spread faster than fact-checks. The cost of creating disinformation has dropped dramatically.</p>
          </div>
        </div>
        
        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-card); border-radius: var(--radius-sm);">
          <strong>How to stay skeptical:</strong>
          <ul style="margin: 0.5rem 0 0 1.25rem; font-size: 0.85rem;">
            <li>Consider the source—is it from a verified account or publication?</li>
            <li>Look for context—does this make sense? Can you find corroborating reports?</li>
            <li>Check for artifacts—unusual hands, text, physics, backgrounds, or audio glitches</li>
            <li>Reverse image search—has this "photo" appeared before in different contexts?</li>
            <li>When in doubt, wait—breaking news is often corrected within hours</li>
          </ul>
        </div>
      </div>

      <!-- Deep Dive -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Image and Audio Generation</h3>

        <div class="concept-card">
          <h4>Diffusion Models for Generation</h4>
          <p>Most image generation (NanoBanana & GPT Image-Gen 1.5) uses a different approach called <strong>diffusion</strong>:</p>
          <ol class="concept-list">
            <li><strong>Start with noise</strong>—Pure random static</li>
            <li><strong>Gradually denoise</strong>—A neural network predicts and removes noise, step by step</li>
            <li><strong>Condition on text</strong>—The text prompt guides what emerges from the noise</li>
            <li><strong>Iterate many times</strong>—Each step makes the image slightly clearer</li>
          </ol>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.75rem;">This is why image generation takes longer than text—it requires many forward passes through the network, not just one per token.</p>
        </div>

        <div class="concept-card">
          <h4>Audio Processing</h4>
          <p>Audio models like Whisper convert sound waves to spectrograms (visual representations of sound), then process them similarly to images. For speech generation, the process reverses—tokens become audio waveforms.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">Real-time voice conversation (like GPT-5.2) requires extremely fast processing—the model must listen, think, and speak with minimal delay to feel natural.</p>
        </div>
      </div>
    </section>

    <!-- LIMITATIONS & HALLUCINATIONS TAB -->
    <section id="tab-limitations" class="tab-section">
      <div class="section-header">
        <h2>10: Limitations</h2>
        <p>Understanding why models confidently produce incorrect information—and how to mitigate it</p>
      </div>

      <div class="intuition-callout">
        <div class="intuition-main">If you understand the limitations of AI, you understand <em>that confidence ≠ correctness—AI is a pattern-matcher, not a fact-checker.</em></div>
        <div class="intuition-detail">AI generates plausible text, not verified truth. The model has no internal fact-checker, no "I don't know" signal, and no knowledge of anything after its training cutoff. Understanding this is how you avoid being fooled.</div>
      </div>

      <!-- Introduction -->
      <div class="limitations-intro">
        <h3>🎯 The Core Problem</h3>
        <p>LLMs are trained to predict <strong>plausible</strong> next tokens, not <strong>true</strong> ones. There's no internal fact-checker, no "I don't know" signal, and no real-time knowledge access. The model generates what <em>sounds right</em> based on patterns.</p>
        
        <div class="key-insight-box">
          <strong>Key Insight:</strong> When a model confidently states false information, it's not lying—it's pattern-matching to what typically follows similar prompts. Plausibility ≠ Truth.
        </div>
      </div>

      <!-- What Is a Hallucination -->
      <div class="hallucination-section">
        <h3>👻 What Is a Hallucination?</h3>
        <p>A hallucination is when the model generates false information presented as fact. This happens because the model has no way to distinguish between information it learned correctly and patterns it's fabricating.</p>
        
        <div class="hallucination-example">
          <div class="example-qa">
            <div class="example-q">
              <strong>User:</strong> In "To Kill a Mockingbird," what does Scout's teacher Miss Caroline say about the Cunningham family's pride?
            </div>
            <div class="example-a hallucinated">
              <strong>Assistant:</strong> Miss Caroline tells Scout that "The Cunninghams have too much pride to accept charity, but not enough sense to accept help when they need it." She says this during the lunch money incident in chapter 2...
            </div>
          </div>
          <div class="example-verdict">
            <strong>⚠️ Hallucination:</strong> While the lunch money scene and Miss Caroline are real, that specific quote doesn't appear in the book. The model generated a plausible-sounding quote that fits the context and themes, but it's fabricated. This is why you should never trust an AI's "quotes" without verification.
          </div>
        </div>

        <h4 style="margin: 1rem 0 0.75rem; font-size: 0.95rem;">Why Hallucinations Happen</h4>
        <div class="hallucination-reasons">
          <div class="reason-card">
            <strong>No "I Don't Know"</strong>
            <p>The model always produces output. It wasn't trained to output uncertainty.</p>
          </div>
          <div class="reason-card">
            <strong>Pattern Completion</strong>
            <p>If "Chapter X of Book Y" is the pattern, it completes it—even with fabricated details.</p>
          </div>
          <div class="reason-card">
            <strong>Training Data Gaps</strong>
            <p>Information not in training data gets "filled in" with plausible-sounding patterns.</p>
          </div>
          <div class="reason-card">
            <strong>Confidence ≠ Correctness</strong>
            <p>The probability of generating a token doesn't reflect factual accuracy.</p>
          </div>
        </div>
      </div>

      <!-- Knowledge Cutoff -->
      <div class="cutoff-section">
        <h3>📅 Knowledge Cutoffs</h3>
        <p>Models are frozen in time. Their knowledge ends at the training data cutoff date. This isn't a bug—it's how the architecture works.</p>
        
        <div class="cutoff-timeline">
          <div class="timeline-segment">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Training Data<br><small>Books, Wikipedia, etc.</small></div>
          </div>
          <div class="timeline-segment cutoff">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Knowledge Cutoff<br><small>~May 2025</small></div>
          </div>
          <div class="timeline-segment unknown">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Unknown Zone<br><small>Events after cutoff</small></div>
          </div>
          <div class="timeline-segment unknown">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Today<br><small>Dec 2025</small></div>
          </div>
        </div>
        
        <div class="cutoff-note">
          <strong>Why this matters:</strong> If you ask about events after a model's cutoff date, it will either refuse or potentially hallucinate. For example, a model with a May 2025 cutoff won't have reliable information about events in late 2025. The information simply isn't in its weights.
        </div>
      </div>

      <!-- Reasoning Models Section -->
      <div class="reasoning-section">
        <h3>🧠 Standard Models vs Reasoning Models</h3>
        <p>A major advancement in reducing errors: models that "think before answering" by generating reasoning tokens.</p>
        
        <div class="model-comparison">
          <div class="model-type-card standard">
            <div class="model-type-header">
              <span class="model-type-icon">⚡</span>
              <h4>Standard Models</h4>
            </div>
            <ul>
              <li>Generate responses directly</li>
              <li>Fast, lower cost per query</li>
              <li>Great for simple tasks</li>
              <li>May jump to conclusions on hard problems</li>
            </ul>
            <div class="model-examples">Examples: GPT-4o, Claude 3.5 Sonnet, Gemini Pro</div>
          </div>
          <div class="model-type-card reasoning">
            <div class="model-type-header">
              <span class="model-type-icon">🧠</span>
              <h4>Reasoning Models</h4>
            </div>
            <ul>
              <li>Generate thinking tokens first, then answer</li>
              <li>Slower, higher cost (more output tokens)</li>
              <li>Much better on complex reasoning</li>
              <li>Can "check their own work"</li>
            </ul>
            <div class="model-examples">Examples: o1, o3-pro, GPT-5.2, Claude with Extended Thinking</div>
          </div>
        </div>
        
        <div class="reasoning-why-works">
          <h4>Why Reasoning Models Work (Architecture Connection)</h4>
          <div class="why-points">
            <div class="why-point">
              <span class="why-point-icon">📝</span>
              <p><strong>Thinking tokens enter the context window.</strong> The model can attend to its own reasoning.</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">🔄</span>
              <p><strong>More computation per problem.</strong> Each token is a forward pass; more tokens = more "thinking time."</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">🔍</span>
              <p><strong>Intermediate steps catch errors.</strong> Writing out reasoning exposes flawed logic before the final answer.</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">📊</span>
              <p><strong>Chain-of-thought as working memory.</strong> Complex problems need more "scratch space."</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Interactive Thinking Demo -->
      <div class="thinking-demo-section">
        <h3>🎮 See the Difference: Standard vs Reasoning</h3>
        <p>Watch how the same problem gets different treatment. The reasoning model's "thinking" becomes context that helps it arrive at the correct answer.</p>
        
        <div class="interactive-well">
          <div class="thinking-demo">
            <div class="thinking-problem">
              <div class="thinking-problem-label">Problem</div>
              <span id="thinking-problem-text">A bat and ball cost $1.10 total. The bat costs $1.00 more than the ball. How much does the ball cost?</span>
            </div>
            
            <div class="thinking-approaches">
              <div class="approach-panel standard">
                <div class="approach-header">
                  <span>⚡</span> Standard Model
                </div>
                <div class="approach-content" id="standard-response">
                  <div class="final-answer">
                    The ball costs <span class="answer-incorrect">$0.10</span>
                  </div>
                </div>
              </div>
              
              <div class="approach-panel reasoning">
                <div class="approach-header">
                  <span>🧠</span> Reasoning Model
                </div>
                <div class="approach-content" id="reasoning-response">
                  <div class="thinking-tokens">
                    <div class="thinking-tokens-label">💭 Thinking tokens (in context)</div>
                    <span id="thinking-content">Let me work through this... If ball = x, then bat = x + $1.00. Total: x + (x + $1.00) = $1.10. So 2x = $0.10, meaning x = $0.05.</span>
                  </div>
                  <div class="final-answer">
                    The ball costs <span class="answer-correct">$0.05</span>
                  </div>
                </div>
              </div>
            </div>
            
            <div class="thinking-controls">
              <button class="thinking-btn" id="thinking-problem-1">Bat & Ball Problem</button>
              <button class="thinking-btn" id="thinking-problem-2">Lily Pad Problem</button>
              <button class="thinking-btn" id="thinking-problem-3">Widget Problem</button>
            </div>
            
            <div class="thinking-result" id="thinking-insight">
              <strong>Why the standard model fails:</strong> The intuitive answer ($0.10) "sounds right" and has high probability. Without explicit reasoning, the model follows the path of highest probability—which is the common wrong answer humans also give. The reasoning model's thinking tokens let it catch and correct this error.
            </div>
          </div>
        </div>
      </div>

      <!-- Tools & RAG -->
      <div class="tools-section">
        <h3>🛠️ Beyond the Model: Tools That Help</h3>
        <p>Reasoning models aren't the only solution. External tools can ground model outputs in verified information.</p>
        
        <div class="tools-grid">
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">🌐</span>
              <span class="tool-name">Web Search</span>
            </div>
            <p>Real-time information access. Overcomes knowledge cutoffs by fetching current data and injecting it into context.</p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">📚</span>
              <span class="tool-name">RAG</span>
            </div>
            <p><strong>Retrieval-Augmented Generation:</strong> Retrieves relevant documents and includes them in the context window. Grounds responses in actual sources rather than relying on memorized patterns. <em>(We'll explore building RAG systems in depth later.)</em></p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">🔢</span>
              <span class="tool-name">Code Execution</span>
            </div>
            <p>For math and logic, let the model write and run code rather than "computing" answers via token prediction.</p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">🔌</span>
              <span class="tool-name">APIs & Databases</span>
            </div>
            <p>Connect to authoritative sources: weather APIs, stock prices, databases. Verified data > hallucinated data.</p>
          </div>
        </div>
        
        <div class="tools-insight">
          <strong>Key insight:</strong> These tools don't change the model's architecture—they work <em>with</em> the context window by injecting verified information <em>before</em> the model generates its response. The model is still predicting tokens; it just has better context to work with.
        </div>
      </div>

      <!-- Other Limitations -->
      <div class="other-limitations">
        <h3>🚧 Other Common Limitations</h3>
        
        <div class="limitations-grid">
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">🔢</span>
              <strong>Math & Counting</strong>
            </div>
            <p>Tokenization splits numbers unpredictably. "123" might be one token or multiple. The model isn't "doing math"—it's predicting likely digits.</p>
            <div class="limitation-example">Q: How many r's in "strawberry"?<br>A: 2 (Legacy models—wrong! The correct answer is 3: st<strong>r</strong>awbe<strong>rr</strong>y) <br><em>Note: Modern reasoning models like GPT-5.2 solve this via native reasoning.</em></div>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">🪞</span>
              <strong>Sycophancy</strong>
            </div>
            <p>Models tend to agree with users, even when wrong. RLHF optimized for "helpfulness" which can mean "telling you what you want to hear."</p>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">🧩</span>
              <strong>Novel Reasoning</strong>
            </div>
            <p>Problems unlike anything in training data are hard. The model relies on pattern recognition—truly novel problems have no patterns to match.</p>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">📏</span>
              <strong>Spatial Reasoning</strong>
            </div>
            <p>Text doesn't naturally encode spatial relationships. Tasks involving 3D visualization, rotations, or physical intuition are challenging.</p>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">🛡️</span>
              <strong>Prompt Injection</strong>
            </div>
            <p>User input can sometimes override system instructions. Malicious users may craft inputs that cause the model to ignore its guidelines or reveal system prompts.</p>
            <div class="limitation-example"><em>This is a security concern for production applications—always validate and sanitize user inputs when building AI-powered systems.</em></div>
          </div>
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h3>Living With Limitations</h3>
        <p>Understanding <em>why</em> these limitations exist helps you work around them:</p>
        <ul>
          <li><strong>Verify important facts:</strong> The model's confidence isn't correlated with accuracy</li>
          <li><strong>Use the right model:</strong> Reasoning models for complex problems, standard for simple tasks</li>
          <li><strong>Augment with tools:</strong> Web search, RAG, and code execution reduce hallucinations</li>
          <li><strong>Prompt for uncertainty:</strong> Ask the model to express when it's unsure</li>
          <li><strong>Check recent events:</strong> Be aware of knowledge cutoff dates</li>
        </ul>
      </div>

      <!-- Deep Dive -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">🔬 Going Deeper on Limitations</h3>
        
        <div class="concept-card">
          <h4>The Calibration Problem</h4>
          <p>Ideally, when a model says "I'm 80% confident," it should be correct 80% of the time. In practice, LLMs are often <strong>overconfident</strong>—they express high certainty even for things they're wrong about.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">This happens because training optimized for confident-sounding text, not calibrated probabilities. The model learned that authoritative-sounding responses get positive feedback.</p>
        </div>

        <div class="concept-card">
          <h4>Token Probability ≠ Factual Accuracy</h4>
          <p>A critical insight: the probability of a token being generated doesn't correlate with its factual accuracy. A token can have 99% probability and still be factually wrong.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">This happens because the model predicts what's <em>likely to come next</em> based on training patterns, not what's <em>true</em>. If the training data contained incorrect information, or if plausible-sounding false statements were common, the model will confidently reproduce those patterns. High probability means "fits the pattern well"—not "is correct."</p>
        </div>

        <div class="concept-card">
          <h4>Why Reasoning Models Can't Solve Everything</h4>
          <p>Even with extended thinking, models have fundamental limits:</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li><strong>Still pattern matching:</strong> Reasoning tokens don't create new knowledge</li>
            <li><strong>Training data ceiling:</strong> Can't reason about things never encountered</li>
            <li><strong>Computational limits:</strong> Some problems are just too hard to "think through"</li>
            <li><strong>Cost tradeoff:</strong> More thinking = more tokens = higher cost</li>
          </ul>
        </div>

        <div class="concept-card">
          <h4>Grounding: The Key to Reliability</h4>
          <p>The most reliable LLM applications <strong>ground</strong> the model's output in verified sources:</p>
          <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 0.75rem; margin-top: 0.75rem;">
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>RAG</strong><br><small>Retrieved documents</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Tool Use</strong><br><small>API responses</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Code</strong><br><small>Executable verification</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Citations</strong><br><small>Source attribution</small>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>When to Trust, When to Verify</h4>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin-top: 0.75rem;">
            <div style="background: var(--bg-elevated); padding: 0.75rem; border-radius: var(--radius-sm);">
              <strong style="color: var(--positive); font-size: 0.85rem;">✓ Higher Trust</strong>
              <ul style="margin: 0.5rem 0 0; padding-left: 1.25rem; font-size: 0.75rem;">
                <li>Common knowledge, well-documented topics</li>
                <li>General patterns and concepts</li>
                <li>Creative tasks with no "correct" answer</li>
                <li>Explanations of well-known facts</li>
              </ul>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.75rem; border-radius: var(--radius-sm);">
              <strong style="color: var(--negative); font-size: 0.85rem;">⚠️ Verify Carefully</strong>
              <ul style="margin: 0.5rem 0 0; padding-left: 1.25rem; font-size: 0.75rem;">
                <li>Specific facts, numbers, dates</li>
                <li>Recent events (after cutoff)</li>
                <li>Niche or specialized domains</li>
                <li>Legal, medical, financial advice</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>
    </main>
  </div>

<script>
// ═══════════════════════════════════════════════════════════════════════════
// THEME CONFIGURATION
// Mirrors CSS variables for use in canvas rendering and dynamic styling
// ═══════════════════════════════════════════════════════════════════════════
const THEME = {
  // Primary Colors
  colors: {
    red: '#D32F2F',
    blue: '#1565C0',
    yellow: '#F9A825',
    green: '#2E7D32',
    purple: '#7B1FA2',
    gray: '#9E9E9E',
    grayDark: '#6B7280',
    grayLight: '#E0E0E0',
  },
  // Text Colors
  text: {
    primary: '#1A1A1A',
    secondary: '#4A4A4A',
    muted: '#7A7A7A',
  },
  // Background Colors
  bg: {
    deep: '#FAF7F2',
    panel: '#F5F0E8',
    card: '#FFFFFF',
    elevated: '#EDE8DE',
  },
  // Semantic mapping
  accent: {
    primary: '#D32F2F',
    secondary: '#1565C0',
    warm: '#F9A825',
  },
  feedback: {
    positive: '#2E7D32',
    negative: '#C62828',
  },
  // Fonts
  fonts: {
    sans: '"Work Sans", sans-serif',
    mono: '"IBM Plex Mono", monospace',
  },
  // Helper to create rgba from hex
  rgba(hex, alpha) {
    const r = parseInt(hex.slice(1, 3), 16);
    const g = parseInt(hex.slice(3, 5), 16);
    const b = parseInt(hex.slice(5, 7), 16);
    return `rgba(${r}, ${g}, ${b}, ${alpha})`;
  }
};

// ============ UTILITIES ============
function clamp(val, min, max) {
  return Math.min(max, Math.max(min, val));
}

function lerp(a, b, t) {
  return a + (b - a) * t;
}

// ============ TAB NAVIGATION ============
// Global render functions for tab switching
const tabRenders = {};

function setupTabs() {
  const buttons = document.querySelectorAll('.tab-btn');
  const sections = document.querySelectorAll('.tab-section');
  
  buttons.forEach(btn => {
    btn.addEventListener('click', () => {
      const tab = btn.dataset.tab;
      
      buttons.forEach(b => b.classList.remove('active'));
      btn.classList.add('active');
      
      sections.forEach(s => {
        s.classList.toggle('active', s.id === `tab-${tab}`);
      });

      // Comprehensive scroll reset
      window.scrollTo(0, 0);
      document.body.scrollTop = 0;
      document.documentElement.scrollTop = 0;
      const mainContent = document.querySelector('.main-content');
      if (mainContent) mainContent.scrollTop = 0;
      
      // Trigger render for the newly visible tab after a brief delay
      // to ensure the tab is visible and has dimensions
      setTimeout(() => {
        if (tabRenders[tab]) {
          tabRenders[tab]();
        }
      }, 100);
    });
  });
}

// ============ INFERENCE SIMULATION ============
function setupInference() {
  // State
  const basePrompt = "The best way to learn is";
  let currentText = basePrompt;
  let generatedTokens = [];
  let isAutoGenerating = false;
  let autoGenerateInterval = null;
  let stepCount = 0;

  // Pre-defined generation sequence for demo
  const generationSequence = [
    { token: " by", probs: [
      { token: " by", prob: 0.42 },
      { token: " through", prob: 0.28 },
      { token: " from", prob: 0.15 },
      { token: " with", prob: 0.10 },
      { token: " in", prob: 0.05 },
      { token: " potato", prob: 0.02 },
      { token: " 7", prob: 0.02 },
      { token: " ???", prob: 0.02 }
    ]},
    { token: " doing", probs: [
      { token: " doing", prob: 0.38 },
      { token: " practicing", prob: 0.28 },
      { token: " experimenting", prob: 0.18 },
      { token: " making", prob: 0.10 },
      { token: " building", prob: 0.06 },
      { token: " purple", prob: 0.02 },
      { token: " [REDACTED]", prob: 0.02 },
      { token: " ERROR", prob: 0.02 }
    ]},
    { token: ".", probs: [
      { token: ".", prob: 0.55 },
      { token: " and", prob: 0.20 },
      { token: ",", prob: 0.12 },
      { token: " things", prob: 0.08 },
      { token: " it", prob: 0.05 },
      { token: " banana", prob: 0.02 },
      { token: " (unintelligible)", prob: 0.02 },
      { token: " !!1!", prob: 0.02 }
    ]},
    { token: " practice", probs: [
      { token: " practice", prob: 0.35 },
      { token: " hands", prob: 0.25 },
      { token: " this", prob: 0.18 },
      { token: " real", prob: 0.14 },
      { token: " active", prob: 0.08 },
      { token: " meow", prob: 0.02 },
      { token: " 010101", prob: 0.02 },
      { token: " glitch", prob: 0.02 }
    ]},
    { token: " makes", probs: [
      { token: " makes", prob: 0.50 },
      { token: " builds", prob: 0.22 },
      { token: " creates", prob: 0.15 },
      { token: " leads", prob: 0.08 },
      { token: " brings", prob: 0.05 },
      { token: " destroys", prob: 0.02 },
      { token: " vibrates", prob: 0.02 },
      { token: " null", prob: 0.02 }
    ]},
    { token: " perfect", probs: [
      { token: " perfect", prob: 0.72 },
      { token: " progress", prob: 0.12 },
      { token: " mastery", prob: 0.08 },
      { token: " improvement", prob: 0.05 },
      { token: " it", prob: 0.02 },
      { token: " ham", prob: 0.02 },
      { token: " undefined", prob: 0.02 },
      { token: " recursive", prob: 0.02 }
    ]},
    { token: ".", probs: [
      { token: ".", prob: 0.78 },
      { token: "!", prob: 0.12 },
      { token: ",", prob: 0.06 },
      { token: " and", prob: 0.03 },
      { token: "...", prob: 0.01 },
      { token: " ?????", prob: 0.02 },
      { token: " </html>", prob: 0.02 },
      { token: " <EOF>", prob: 0.02 }
    ]},
    { token: "<|end|>", probs: [
      { token: "<|end|>", prob: 0.85 },
      { token: " So", prob: 0.08 },
      { token: " The", prob: 0.04 },
      { token: " Start", prob: 0.02 },
      { token: " Don", prob: 0.01 },
      { token: " help", prob: 0.02 },
      { token: " loop", prob: 0.02 },
      { token: " (static noise)", prob: 0.02 }
    ]}
  ];

  // DOM Elements
  const promptDisplay = document.getElementById('inference-prompt');
  const pipelineInput = document.getElementById('pipeline-input');
  const pipelineOutput = document.getElementById('pipeline-output');
  const pipelineModel = document.getElementById('pipeline-model');
  const tokenProbList = document.getElementById('token-prob-list');
  const tempSlider = document.getElementById('inf-temperature');
  const tempVal = document.getElementById('inf-temp-val');
  const tempVizBar = document.getElementById('temp-viz-bar');
  const tempDescription = document.getElementById('temp-description');
  const stepBtn = document.getElementById('inf-step-btn');
  const autoBtn = document.getElementById('inf-auto-btn');
  const resetBtn = document.getElementById('inf-reset-btn');
  const statsDiv = document.getElementById('generation-stats');
  const statTokens = document.getElementById('stat-tokens');
  const statSteps = document.getElementById('stat-steps');
  const loopViz = document.getElementById('loop-visualization');

  // Apply temperature to probabilities
  function applyTemperature(probs, temperature) {
    if (temperature === 0) {
      // At temp 0, all probability goes to the top token
      return probs.map((p, i) => ({ ...p, adjustedProb: i === 0 ? 1 : 0 }));
    }
    
    // Convert base probabilities to logits
    // We use a larger range for logits to make temperature effects more pronounced
    const logits = probs.map(p => Math.log(p.prob) * 2); 
    const scaledLogits = logits.map(l => l / temperature);
    const maxLogit = Math.max(...scaledLogits);
    const expLogits = scaledLogits.map(l => Math.exp(l - maxLogit));
    const sumExp = expLogits.reduce((a, b) => a + b, 0);
    const newProbs = expLogits.map(e => e / sumExp);
    
    return probs.map((p, i) => ({ ...p, adjustedProb: newProbs[i] }));
  }

  // Sample from distribution based on temperature
  function sampleToken(probs, temperature) {
    const adjusted = applyTemperature(probs, temperature);
    
    if (temperature === 0) {
      return adjusted[0];
    }
    
    const rand = Math.random();
    let cumulative = 0;
    for (const p of adjusted) {
      cumulative += p.adjustedProb;
      if (rand < cumulative) {
        return p;
      }
    }
    return adjusted[adjusted.length - 1];
  }

  // Update temperature visualization
  function updateTempVisualization() {
    const temp = parseFloat(tempSlider.value);
    tempVal.textContent = temp.toFixed(1);
    
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    const probs = generationSequence[currentStep].probs;
    const adjusted = applyTemperature(probs, temp);
    
    // Update viz bar
    tempVizBar.innerHTML = adjusted.map((p, i) => {
      const colors = ['var(--accent-primary)', 'var(--accent-cool)', 'var(--accent-secondary)', 'var(--accent-warm)', 'var(--accent-pink)', 'var(--accent-cool)', 'var(--accent-secondary)', 'var(--accent-warm)'];
      const width = Math.max(p.adjustedProb * 100, 2); // minimum 2% for visibility
      return `<div class="temp-viz-segment" style="flex: ${width}; background: ${colors[i % colors.length] || 'var(--text-muted)'}; font-size: ${width > 15 ? '0.7rem' : '0.5rem'}">${p.token}</div>`;
    }).join('');
    
    // Update description
    if (temp === 0) {
      tempDescription.textContent = "Deterministic: Always picks the highest probability token";
    } else if (temp < 0.5) {
      tempDescription.textContent = "Very focused: Strongly favors high-probability tokens";
    } else if (temp < 1) {
      tempDescription.textContent = "Balanced: Mostly picks likely tokens, occasionally surprises";
    } else if (temp === 1) {
      tempDescription.textContent = "Natural: Samples directly from the model's distribution";
    } else if (temp < 1.5) {
      tempDescription.textContent = "Creative: More likely to pick unexpected tokens";
    } else {
      tempDescription.textContent = "Chaotic: Almost random, often produces nonsense";
    }
  }

  // Update probability display
  function updateProbDisplay(probs, selectedToken) {
    const temp = parseFloat(tempSlider.value);
    const adjusted = applyTemperature(probs, temp);
    
    tokenProbList.innerHTML = adjusted.map((p, i) => {
      const isSelected = p.token === selectedToken;
      const barWidth = p.adjustedProb * 100;
      return `
        <div class="token-prob-item ${isSelected ? 'selected' : 'alternative'}">
          <span class="token-prob-rank">${i + 1}</span>
          <span class="token-prob-token">"${p.token}"</span>
          <div class="token-prob-bar-container">
            <div class="token-prob-bar" style="width: ${barWidth}%"></div>
          </div>
          <span class="token-prob-percent">${(p.adjustedProb * 100).toFixed(0)}%</span>
        </div>
      `;
    }).join('');
  }

  // Update the loop visualization
  function updateLoopVisualization() {
    const steps = [
      { label: "Input prompt", tokens: `"${basePrompt}"`, isBase: true }
    ];
    
    let accumulated = basePrompt;
    for (let i = 0; i < generatedTokens.length; i++) {
      accumulated += generatedTokens[i];
      const isStop = generatedTokens[i] === "<|end|>";
      steps.push({
        label: `After ${i + 1}${getOrdinalSuffix(i + 1)} inference → predicts "${generatedTokens[i]}"`,
        tokens: accumulated,
        newToken: generatedTokens[i],
        isStop: isStop
      });
    }
    
    // Show what's next if not complete
    if (generatedTokens.length < generationSequence.length && !generatedTokens.includes("<|end|>")) {
      const nextStep = generationSequence[generatedTokens.length];
      steps.push({
        label: `Next prediction...`,
        tokens: accumulated + "?",
        isPending: true
      });
    }
    
    loopViz.innerHTML = steps.map((step, i) => {
      const isActive = i === generatedTokens.length && !generatedTokens.includes("<|end|>");
      const isCompleted = i < generatedTokens.length || step.isBase;
      
      let tokensHtml = `"${step.tokens.replace(basePrompt, basePrompt)}"`;
      if (step.newToken && !step.isStop) {
        const before = step.tokens.slice(0, -step.newToken.length);
        tokensHtml = `"${before}<span class="new-token">${step.newToken}</span>"`;
      }
      if (step.isStop) {
        tokensHtml = `"${step.tokens.replace('<|end|>', '')}" <span class="stop-token">&lt;|end|&gt;</span>`;
      }
      if (step.isPending) {
        tokensHtml = `"${step.tokens.replace('?', '<span class="new-token">?</span>')}"`;
      }
      
      const stepNumber = step.isStop ? '✓' : (i + 1);
      
      return `
        ${i > 0 ? `<div class="loop-arrow${i === generatedTokens.length && !generatedTokens.includes("<|end|>") ? ' feedback' : ''}">↓</div>` : ''}
        <div class="loop-step ${isActive ? 'active' : ''} ${isCompleted ? 'completed' : ''}">
          <div class="loop-step-number">${stepNumber}</div>
          <div class="loop-step-content">
            <div class="loop-step-label">${step.label}</div>
            <div class="loop-step-tokens">${tokensHtml}</div>
          </div>
        </div>
      `;
    }).join('');
  }

  function getOrdinalSuffix(n) {
    const j = n % 10, k = n % 100;
    if (j === 1 && k !== 11) return "st";
    if (j === 2 && k !== 12) return "nd";
    if (j === 3 && k !== 13) return "rd";
    return "th";
  }

  // Update display
  function updateDisplay() {
    // Update prompt display
    let displayText = basePrompt;
    if (generatedTokens.length > 0) {
      const genText = generatedTokens.filter(t => t !== "<|end|>").join('');
      displayText = basePrompt + `<span class="generated">${genText}</span>`;
    }
    
    const isComplete = generatedTokens.includes("<|end|>");
    promptDisplay.innerHTML = displayText + (isComplete ? '' : '<span class="cursor"></span>');
    
    // Update pipeline input (show last few tokens)
    const fullText = basePrompt + generatedTokens.filter(t => t !== "<|end|>").join('');
    const lastPart = fullText.length > 15 ? '..."' + fullText.slice(-12) + '"' : '"' + fullText + '"';
    pipelineInput.textContent = lastPart;
    
    // Update pipeline output and probs
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    const nextToken = generationSequence[currentStep];
    
    if (isComplete) {
      pipelineOutput.innerHTML = '<span style="color: var(--accent-warm)">STOP</span>';
    } else {
      pipelineOutput.textContent = `"${nextToken.token}"`;
    }
    
    updateProbDisplay(nextToken.probs, nextToken.token);
    updateTempVisualization();
    updateLoopVisualization();
    
    // Update stats
    if (generatedTokens.length > 0) {
      statsDiv.style.display = 'flex';
      statTokens.textContent = generatedTokens.length;
      statSteps.textContent = stepCount;
    } else {
      statsDiv.style.display = 'none';
    }
    
    // Update button states
    const canGenerate = !isComplete && stepCount < generationSequence.length;
    stepBtn.disabled = !canGenerate;
    autoBtn.disabled = !canGenerate;
  }

  // Generate next token
  function generateNext() {
    if (stepCount >= generationSequence.length) return;
    if (generatedTokens.includes("<|end|>")) return;
    
    const step = generationSequence[stepCount];
    const temp = parseFloat(tempSlider.value);
    
    // Animate the pipeline
    pipelineModel.classList.add('active');
    setTimeout(() => {
      pipelineModel.classList.remove('active');
      
      // Sample token based on temperature
      const sampled = sampleToken(step.probs, temp);
      
      // Determine token casing based on previous token
      let tokenValue = sampled.token;
      if (generatedTokens.length > 0) {
        const lastToken = generatedTokens[generatedTokens.length - 1].trim();
        const sentenceEnders = ['.', '!', '?', '<|endoftext|>'];
        if (sentenceEnders.includes(lastToken)) {
          // Capitalize if it's the start of a new sentence
          tokenValue = tokenValue.charAt(0) === ' ' 
            ? ' ' + tokenValue.trim().charAt(0).toUpperCase() + tokenValue.trim().slice(1)
            : tokenValue.charAt(0).toUpperCase() + tokenValue.slice(1);
        }
      } else {
        // First generated token follows "is" (from basePrompt), so it stays lowercase
      }

      generatedTokens.push(tokenValue);
      stepCount++;
      
      // Update probability display with actual selected token
      updateProbDisplay(step.probs, sampled.token);
      updateDisplay();
      
      // Check if we hit stop token
      if (sampled.token === "<|end|>") {
        stopAutoGenerate();
      }
    }, 300);
  }

  // Auto-generate
  function startAutoGenerate() {
    if (isAutoGenerating) return;
    isAutoGenerating = true;
    autoBtn.innerHTML = '<span>⏸</span> Pause';
    
    autoGenerateInterval = setInterval(() => {
      if (stepCount >= generationSequence.length || generatedTokens.includes("<|end|>")) {
        stopAutoGenerate();
        return;
      }
      generateNext();
    }, 800);
  }

  function stopAutoGenerate() {
    isAutoGenerating = false;
    autoBtn.innerHTML = '<span>⏩</span> Auto-Generate';
    if (autoGenerateInterval) {
      clearInterval(autoGenerateInterval);
      autoGenerateInterval = null;
    }
  }

  // Reset
  function reset() {
    stopAutoGenerate();
    currentText = basePrompt;
    generatedTokens = [];
    stepCount = 0;
    updateDisplay();
  }

  // Event listeners
  tempSlider.addEventListener('input', () => {
    updateTempVisualization();
    // Re-render prob display with new temperature
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    updateProbDisplay(generationSequence[currentStep].probs, generationSequence[currentStep].token);
  });

  stepBtn.addEventListener('click', generateNext);
  
  autoBtn.addEventListener('click', () => {
    if (isAutoGenerating) {
      stopAutoGenerate();
    } else {
      startAutoGenerate();
    }
  });
  
  resetBtn.addEventListener('click', reset);

  // Initial render
  updateDisplay();
}

// ============ NEURAL NETWORK VISUALIZATION ============
function setupNeuralNetwork() {
  const canvas = document.getElementById('nn-canvas');
  const ctx = canvas.getContext('2d');
  const dpr = window.devicePixelRatio || 1;
  
  // Track if initialized with proper dimensions
  let initialized = false;
  let W = 0;
  let H = 0;
  let layers = [];
  
  // Pre-trained weights for meaningful behavior
  // These weights make the network respond sensibly to the semantic inputs
  const weights = {
    // Input (4) -> Hidden (4) weights
    // Inputs: royalty, military, gender, formality
    ih: [
      [1.5, 0.2, 1.3, 0.4],   // h0: royalty + masculine detector → king
      [0.3, 1.6, 0.2, -0.3],  // h1: military detector → general
      [1.5, 0.2, -1.3, 0.4],  // h2: royalty + feminine detector → queen
      [0.6, 0.4, 0.0, 1.2]    // h3: formality detector → boosts royalty
    ],
    // Hidden (4) -> Output (3) weights
    // Outputs: king, general, queen
    ho: [
      [1.6, -0.4, -0.6, 0.5], // "king": h0 (royal+masc), suppressed by h2, boosted by formality
      [-0.3, 1.8, -0.3, -0.2],// "general": h1 (military), less formal
      [-0.6, -0.4, 1.6, 0.5]  // "queen": h2 (royal+fem), suppressed by h0, boosted by formality
    ]
  };
  
  function initCanvas() {
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    canvas.style.width = rect.width + 'px';
    canvas.style.height = rect.height + 'px';
    
    W = rect.width;
    H = rect.height;
    
    const inputLabels = ['roy', 'mil', 'gen', 'frml'];
    const hiddenLabels = ['h₁', 'h₂', 'h₃', 'h₄'];
    const outputLabels = ['king', 'general', 'queen'];
    
    // Node positions - 4 inputs, 4 hidden, 3 outputs
    layers = [
      // Input layer (4 nodes)
      inputLabels.map((label, i) => ({
        x: W * 0.12,
        y: H * (0.15 + i * 0.22),
        label: label,
        type: 'input'
      })),
      // Hidden layer (4 nodes)
      hiddenLabels.map((label, i) => ({
        x: W * 0.5,
        y: H * (0.15 + i * 0.22),
        label: label,
        type: 'hidden'
      })),
      // Output layer (3 nodes)
      outputLabels.map((label, i) => ({
        x: W * 0.88,
        y: H * (0.22 + i * 0.28),
        label: label,
        type: 'output'
      }))
    ];
    
    initialized = true;
    return true;
  }
  
  const sliders = {
    x1: document.getElementById('nn-x1'),
    x2: document.getElementById('nn-x2'),
    x3: document.getElementById('nn-x3'),
    x4: document.getElementById('nn-x4')
  };
  
  const valueDisplays = {
    x1: document.getElementById('nn-x1-val'),
    x2: document.getElementById('nn-x2-val'),
    x3: document.getElementById('nn-x3-val'),
    x4: document.getElementById('nn-x4-val')
  };
  
  const outputDisplays = {
    out1: document.getElementById('nn-out1'),
    out2: document.getElementById('nn-out2'),
    out3: document.getElementById('nn-out3')
  };
  
  const outputBars = {
    out1: document.getElementById('nn-out1-bar'),
    out2: document.getElementById('nn-out2-bar'),
    out3: document.getElementById('nn-out3-bar')
  };
  
  function getInputs() {
    return [
      parseFloat(sliders.x1.value),
      parseFloat(sliders.x2.value),
      parseFloat(sliders.x3.value),
      parseFloat(sliders.x4.value)
    ];
  }
  
  function computeNetwork(inputs) {
    // Hidden layer
    const hidden = [];
    for (let h = 0; h < 4; h++) {
      let sum = 0;
      for (let i = 0; i < 4; i++) {
        sum += inputs[i] * weights.ih[h][i];
      }
      hidden.push(Math.tanh(sum));
    }
    
    // Output layer (softmax for probabilities)
    const outputRaw = [];
    for (let o = 0; o < 3; o++) {
      let sum = 0;
      for (let h = 0; h < 4; h++) {
        sum += hidden[h] * weights.ho[o][h];
      }
      outputRaw.push(sum);
    }
    
    // Softmax
    const maxOut = Math.max(...outputRaw);
    const expOut = outputRaw.map(x => Math.exp(x - maxOut));
    const sumExp = expOut.reduce((a, b) => a + b, 0);
    const outputs = expOut.map(x => x / sumExp);
    
    return { inputs, hidden, outputs, outputRaw };
  }
  
  function getWeightColor(weight) {
    if (weight >= 0) {
      const intensity = Math.min(1, Math.abs(weight) / 2);
      return THEME.rgba(THEME.colors.green, 0.15 + intensity * 0.5);
    } else {
      const intensity = Math.min(1, Math.abs(weight) / 2);
      return THEME.rgba(THEME.feedback.negative, 0.15 + intensity * 0.5);
    }
  }
  
  function getWeightWidth(weight) {
    return 1 + Math.abs(weight) * 1.5;
  }
  
  function getActivationColor(value) {
    const normalized = (value + 1) / 2;
    const brightness = 25 + normalized * 55;
    return `hsl(168, 80%, ${brightness}%)`;
  }
  
  function drawConnection(from, to, weight) {
    ctx.beginPath();
    ctx.moveTo(from.x, from.y);
    ctx.lineTo(to.x, to.y);
    ctx.strokeStyle = getWeightColor(weight);
    ctx.lineWidth = getWeightWidth(weight);
    ctx.lineCap = 'round';
    ctx.stroke();
  }
  
  function drawNode(node, value, isActive = false) {
    const radius = node.type === 'output' ? 28 : 22;
    
    // Glow effect for active nodes
    if (isActive && Math.abs(value) > 0.1) {
      const gradient = ctx.createRadialGradient(node.x, node.y, radius, node.x, node.y, radius * 1.8);
      gradient.addColorStop(0, value > 0 ? THEME.rgba(THEME.colors.red, 0.25) : THEME.rgba(THEME.feedback.negative, 0.25));
      gradient.addColorStop(1, 'transparent');
      ctx.fillStyle = gradient;
      ctx.beginPath();
      ctx.arc(node.x, node.y, radius * 1.8, 0, Math.PI * 2);
      ctx.fill();
    }
    
    // Node circle
    ctx.beginPath();
    ctx.arc(node.x, node.y, radius, 0, Math.PI * 2);
    
    if (node.type === 'input') {
      const inputIntensity = (value + 1) / 2;
      ctx.fillStyle = THEME.rgba(THEME.colors.blue, 0.15 + inputIntensity * 0.25);
      ctx.strokeStyle = THEME.colors.blue;
    } else if (node.type === 'hidden') {
      // Gray fill for hidden nodes - activation shown via glow
      ctx.fillStyle = THEME.colors.grayLight;
      ctx.strokeStyle = THEME.colors.gray;
    } else {
      // Output - use value as probability (0-1)
      const intensity = Math.min(1, value * 2);
      ctx.fillStyle = THEME.rgba(THEME.colors.red, 0.1 + intensity * 0.4);
      ctx.strokeStyle = intensity > 0.3 ? THEME.colors.red : THEME.text.muted;
    }
    
    ctx.lineWidth = 2;
    ctx.fill();
    ctx.stroke();
    
    // Label
    ctx.fillStyle = THEME.text.primary;
    ctx.font = node.type === 'output' ? `bold 11px ${THEME.fonts.sans}` : `bold 10px ${THEME.fonts.sans}`;
    ctx.textAlign = 'center';
    ctx.textBaseline = 'middle';
    ctx.fillText(node.label, node.x, node.y);
  }
  
  function render() {
    if (!initialized || W === 0) {
      if (!initCanvas()) return;
    }
    
    const inputs = getInputs();
    const result = computeNetwork(inputs);
    
    // Update input value displays
    valueDisplays.x1.textContent = inputs[0].toFixed(2);
    valueDisplays.x2.textContent = inputs[1].toFixed(2);
    valueDisplays.x3.textContent = inputs[2].toFixed(2);
    valueDisplays.x4.textContent = inputs[3].toFixed(2);
    
    // Update output displays
    outputDisplays.out1.textContent = result.outputs[0].toFixed(2);
    outputDisplays.out2.textContent = result.outputs[1].toFixed(2);
    outputDisplays.out3.textContent = result.outputs[2].toFixed(2);
    
    // Update output bars
    outputBars.out1.style.width = (result.outputs[0] * 100) + '%';
    outputBars.out2.style.width = (result.outputs[1] * 100) + '%';
    outputBars.out3.style.width = (result.outputs[2] * 100) + '%';
    
    // Clear canvas
    ctx.clearRect(0, 0, W, H);
    
    // Draw layer labels
    ctx.fillStyle = THEME.text.muted;
    ctx.font = `12px ${THEME.fonts.sans}`;
    ctx.textAlign = 'center';
    ctx.fillText('Embedding Dims', W * 0.12, 22);
    ctx.fillText('Pattern Detectors', W * 0.5, 22);
    ctx.fillText('Token Probs', W * 0.88, 22);
    
    // Draw all connections (input -> hidden)
    for (let i = 0; i < 4; i++) {
      for (let h = 0; h < 4; h++) {
        drawConnection(layers[0][i], layers[1][h], weights.ih[h][i]);
      }
    }
    
    // Draw all connections (hidden -> output)
    for (let h = 0; h < 4; h++) {
      for (let o = 0; o < 3; o++) {
        drawConnection(layers[1][h], layers[2][o], weights.ho[o][h]);
      }
    }
    
    // Draw input nodes
    for (let i = 0; i < 4; i++) {
      drawNode(layers[0][i], inputs[i], false);
    }
    
    // Draw hidden nodes
    for (let h = 0; h < 4; h++) {
      drawNode(layers[1][h], result.hidden[h], true);
    }
    
    // Draw output nodes
    for (let o = 0; o < 3; o++) {
      drawNode(layers[2][o], result.outputs[o], true);
    }
  }
  
  // Event listeners
  Object.values(sliders).forEach(slider => {
    if (slider) slider.addEventListener('input', render);
  });
  
  // Handle resize
  window.addEventListener('resize', () => {
    initialized = false;
    render();
  });
  
  // Register for tab switching
  tabRenders['nn'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ TOKENIZER ============
function setupTokenizer() {
  const input = document.getElementById('tok-input');
  const btn = document.getElementById('tok-btn');
  const tokensDiv = document.getElementById('tok-tokens');
  const idsDiv = document.getElementById('tok-ids');
  
  // Simulated BPE vocabulary - common subwords and their token IDs
  // In real models like GPT-4, this would be ~100k entries
  const bpeVocab = {'<|endoftext|>': 0, ' ': 220, '.': 13, ',': 11, '!': 0, '?': 30, "'": 6, '"': 1, '-': 12, ':': 25, ';': 26, 'the': 1169, 'The': 464, 'a': 64, 'A': 32, 'an': 272, 'is': 318, 'are': 533, 'was': 373, 'be': 1350, 'to': 284, 'of': 286, 'and': 290, 'in': 287, 'that': 326, 'it': 270, 'for': 329, 'on': 319, 'with': 351, 'as': 355, 'at': 379, 'by': 416, 'from': 422, 'or': 393, 'but': 475, 'not': 407, 'this': 428, 'they': 484, 'we': 356, 'you': 345, 'have': 423, 'has': 468, 'had': 550, 'do': 466, 'does': 857, 'did': 750, 'will': 481, 'would': 561, 'could': 714, 'should': 815, 'can': 460, 'may': 743, 'might': 1244, 'must': 1276, 'say': 910, 'said': 531, 'says': 1139, 'go': 748, 'going': 1016, 'goes': 2925, 'went': 1816, 'get': 651, 'got': 1392, 'gets': 3011, 'make': 1205, 'made': 925, 'makes': 1838, 'know': 760, 'known': 1900, 'knows': 4206, 'think': 892, 'thought': 1807, 'see': 766, 'seen': 1775, 'sees': 7224, 'come': 2063, 'came': 1625, 'comes': 2058, 'want': 765, 'wanted': 2227, 'wants': 3382, 'use': 779, 'used': 973, 'uses': 3544, 'using': 1262, 'find': 1064, 'found': 1043, 'give': 1577, 'gave': 2921, 'given': 1813, 'tell': 1560, 'told': 1297, 'work': 670, 'works': 2499, 'worked': 3111, 'working': 1762, 'call': 1444, 'called': 1444, 'try': 1949, 'tried': 3088, 'need': 761, 'needs': 2476, 'feel': 1254, 'feels': 5300, 'become': 1716, 'becomes': 4329, 'leave': 2666, 'left': 1364, 'put': 1234, 'puts': 7584, 'mean': 1612, 'means': 1724, 'keep': 1394, 'kept': 4030, 'let': 1616, 'lets': 8341, 'begin': 3823, 'began': 2540, 'seem': 1283, 'seems': 2331, 'help': 1037, 'helped': 5710, 'helps': 5765, 'helping': 5765, 'show': 905, 'shows': 2523, 'showed': 4894, 'hear': 3285, 'heard': 2982, 'play': 1110, 'played': 2826, 'plays': 5765, 'run': 1057, 'runs': 4539, 'running': 2491, 'move': 1445, 'moved': 3888, 'moves': 6100, 'live': 2107, 'lived': 5615, 'lives': 3268, 'world': 995, 'people': 661, 'time': 640, 'year': 614, 'years': 812, 'way': 636, 'day': 820, 'days': 1528, 'man': 582, 'men': 1450, 'woman': 2415, 'women': 1466, 'child': 1200, 'children': 1717, 'life': 897, 'hand': 1021, 'hands': 2832, 'part': 636, 'place': 1295, 'case': 1339, 'week': 1285, 'company': 1664, 'system': 1080, 'program': 1430, 'question': 1808, 'government': 2067, 'number': 1271, 'night': 1755, 'point': 966, 'home': 1363, 'water': 1660, 'room': 2119, 'mother': 2802, 'area': 1989, 'money': 1637, 'story': 1621, 'fact': 1109, 'month': 1227, 'lot': 1256, 'right': 826, 'study': 2050, 'book': 1492, 'eye': 2951, 'eyes': 2951, 'job': 1693, 'word': 1573, 'words': 2456, 'business': 1597, 'issue': 2071, 'side': 1735, 'kind': 1611, 'head': 1182, 'house': 2156, 'service': 2139, 'friend': 2767, 'friends': 2460, 'father': 2988, 'power': 1176, 'hour': 2232, 'hours': 2250, 'game': 1830, 'line': 1370, 'end': 886, 'member': 3262, 'law': 1099, 'car': 1097, 'city': 1748, 'community': 2437, 'name': 1438, 'president': 4066, 'team': 1074, 'minute': 5765, 'idea': 2126, 'kid': 4065, 'kids': 3988, 'body': 1767, 'information': 1321, 'back': 736, 'parent': 2560, 'parents': 3397, 'face': 1986, 'others': 1854, 'level': 1241, 'office': 2607, 'door': 3420, 'health': 1717, 'person': 1048, 'art': 1242, 'war': 1175, 'history': 2106, 'party': 2151, 'result': 1255, 'change': 1487, 'morning': 3329, 'reason': 1738, 'research': 2267, 'girl': 2576, 'guy': 3099, 'moment': 2589, 'air': 1633, 'teacher': 4701, 'force': 2700, 'education': 2775, 'un': 403, 're': 260, 'pre': 3866, 'dis': 6381, 'mis': 9383, 'over': 2502, 'under': 4625, 'out': 448, 'up': 510, 'down': 866, 'off': 572, 'self': 944, 'ing': 278, 'tion': 653, 'sion': 4885, 'ness': 1108, 'ment': 434, 'able': 540, 'ible': 856, 'ful': 913, 'less': 1203, 'ous': 516, 'ive': 425, 'al': 282, 'ly': 306, 'er': 263, 'or': 273, 'ist': 382, 'ism': 1042, 'ity': 414, 'ty': 774, 'ed': 276, 'es': 274, 's': 82, 'en': 268, 'ion': 295, 'ation': 341, 'com': 785, 'con': 1102, 'pro': 1676, 'per': 525, 'ex': 1069, 'inter': 3849, 'trans': 7645, 'sub': 7266, 'super': 16668, 'anti': 17096, 'auto': 23736, 'semi': 36083, 'de': 2934, 'act': 529, 'form': 687, 'port': 634, 'duct': 6077, 'struct': 7249, 'scrib': 1416, 'script': 6546, 'spec': 16684, 'spect': 4443, 'ject': 752, 'dict': 11600, 'fect': 2715, 'graph': 34960, 'gram': 4546, 'log': 6404, 'logy': 4835, 'phon': 24523, 'phone': 4862, 'photo': 23074, 'tele': 46813, 'vis': 4703, 'vid': 8008, 'video': 8464, 'bio': 65, 'geo': 469, 'psych': 13496, 'soci': 45842, 'tech': 13670, 'techn': 33024, 'ology': 2728, 'establish': 18695, 'fortune': 21721, 'fortunate': 38274, 'fortunately': 44827, 'unfortunately': 52822, 'understand': 1833, 'understanding': 4547, 'elect': 9509, 'electr': 37823, 'electric': 13278, 'comput': 43890, 'computer': 23692, 'computers': 38460, 'artific': 61826, 'artificial': 49521, 'intellig': 40682, 'intelligence': 37438, 'intelligent': 53863, 'machine': 30243, 'machines': 30645, 'learn': 35720, 'learning': 21215, 'neur': 25796, 'neural': 47200, 'net': 3262, 'network': 27349, 'networks': 30888, 'model': 19849, 'models': 27530, 'data': 7890, 'train': 27432, 'training': 24924, 'happ': 23598, 'happy': 15039, 'happiness': 58841, 'unhapp': 48295, 'unhappy': 36450, 'quick': 29068, 'brown': 33282, 'fox': 30845, 'jump': 43327, 'jumps': 73234, 'lazy': 75970, 'dog': 9703};
  
  // Subword rules - how to break down words (simplified BPE simulation)
  const subwordRules = [
    { pattern: /^(un)(happy|fortunate|likely|able|certain|clear|fair|known|seen|willing|wanted|expected|usual|common|familiar|comfortable|conscious|controlled|decided|defined|done|dressed|equal|ethical|even|explored|finished|fit|fold|forgettable|fortunate|friendly|grateful|healthy|helpful|important|intentional|interesting|kind|lawful|limited|lucky|natural|necessary|official|paid|pleasant|popular|predictable|prepared|professional|real|reasonable|related|reliable|remarkable|resolved|rest|safe|satisfactory|settled|skilled|spoken|stable|successful|sure|surprising|sympathetic|tidy|timely|touched|trained|true|used|usual|wanted|welcome|willing|wise|worthy)/i, split: ['un', '$2'] },
    { pattern: /^(re)(build|create|define|design|develop|do|make|think|write|act|play|start|turn|view|work|call|cycle|fresh|fund|generate|new|open|place|run|search|set|store|structure|visit)/i, split: ['re', '$2'] },
    { pattern: /^(pre)(view|dict|pare|vent|fer|cede|fix|heat|load|order|pay|school|set|test|war|historic|existing|determined|arranged|approved)/i, split: ['pre', '$2'] },
    { pattern: /^(dis)(agree|appear|approve|arm|belief|comfort|connect|continue|cover|grace|honest|like|miss|obey|order|own|please|prove|respect|satisfy|trust)/i, split: ['dis', '$2'] },
    { pattern: /^(mis)(understand|take|lead|behave|fortune|guide|handle|inform|interpret|judge|place|print|quote|read|spell|treat|use)/i, split: ['mis', '$2'] },
    { pattern: /^(over)(come|flow|look|see|throw|time|whelm|work|load|pay|power|rate|react|ride|rule|run|sleep|state|step|take|turn|use|weight)/i, split: ['over', '$2'] },
    { pattern: /^(under)(stand|go|line|take|estimate|graduate|ground|lying|mine|neath|paid|pass|rate|score|sell|side|state|water|wear|write)/i, split: ['under', '$2'] },
    { pattern: /^(out)(break|come|door|fit|go|grow|line|look|number|put|rage|reach|run|set|side|skirt|source|standing|ward|weigh)/i, split: ['out', '$2'] },
    { pattern: /(work|play|learn|think|walk|talk|jump|help|look|want|need|start|turn|call|move|live|love|like|use|try|ask|seem|feel|leave|find|give|tell|say|get|make|go|know|take|see|come|think|want|look|use|find|give|tell|become|keep|let|begin|show|hear|run|move|meet|pay|bring|hold|write|stand|lose|send|build|spend|buy|watch|read|grow|carry|walk|win|catch|pass|sell|decide|return|explain|develop|carry|break|receive|continue|reach|rest|include|turn|reach|remain|speak|lead|teach|learn|create|happen|provide|sit|grow|open|walk|win|offer|remember|consider|appear|buy|serve|die|expect|stay|fall|produce|rise|allow|follow|begin|stop|wait|study)(ing|ed|er|s)$/i, split: ['$1', '$2'] },
    { pattern: /(quick|slow|quiet|loud|soft|hard|bright|dark|light|heavy|easy|happy|angry|busy|dirty|early|empty|full|great|high|large|late|little|long|low|new|old|poor|rich|short|small|strong|weak|wide|young|beautiful|careful|colorful|dangerous|different|difficult|expensive|famous|helpful|important|interesting|natural|necessary|popular|possible|powerful|professional|reasonable|responsible|similar|successful|terrible|useful|wonderful)(ly|ness|er|est)$/i, split: ['$1', '$2'] },
    { pattern: /(educate|create|operate|communicate|calculate|celebrate|circulate|complicate|concentrate|cooperate|decorate|demonstrate|dominate|educate|eliminate|estimate|evaluate|generate|hesitate|illustrate|indicate|investigate|isolate|locate|motivate|negotiate|operate|participate|populate|regulate|separate|stimulate|terminate|translate|violate)(ion|tion|ed|ing|or|ive)$/i, split: ['$1', '$2'] },
    { pattern: /(happy|lonely|angry|hungry|healthy|wealthy|noisy|rainy|sunny|windy|cloudy|funny|easy|busy|crazy|lazy|messy|nasty|risky|shaky|stormy|tricky)(ness|ly)$/i, split: ['$1', '$2'] },
    { pattern: /(govern|develop|manage|establish|accomplish|astonish|distinguish|punish|publish|abolish|admonish|banish|blemish|brandish|burnish|cherish|demolish|diminish|embellish|famish|finish|flourish|furnish|garnish|impoverish|languish|lavish|nourish|perish|polish|ravish|refurbish|relinquish|replenish|skirmish|tarnish|vanish|varnish)(ment|ed|ing|er)$/i, split: ['$1', '$2'] },
    { pattern: /(think|teach|build|hold|understand|sell|tell|spend|send|lend|mean|meet|keep|feel|leave|sleep|dream|deal|lead|read|spread|feed|speed|bleed|breed|flee|freeze|seek|speak|steal|weep)(er|ing|able)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{4,})(ization|isation)$/i, split: ['$1', 'ization'] },
    { pattern: /(\w{4,})(fulness|lessness)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(tion|sion)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(ness|ment|able|ible|ful|less|ous|ive|ity)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(ing|ed|er|est|ly|al)$/i, split: ['$1', '$2'] },
    { pattern: /(\w+)(\'s|\'t|\'re|\'ve|\'ll|\'d|n\'t)$/i, split: ['$1', '$2'] }
  ];
  
  // BPE-style tokenizer
  function tokenize(text) {
    // Returns array of {token, isContinuation} objects
    const tokens = [];
    
    // Helper to add a token
    const addToken = (t, isCont = false) => tokens.push({token: t, isContinuation: isCont});
    
    // First split on whitespace and punctuation, keeping spaces as tokens
    const rawParts = text.match(/\s+|[^\s\w]|[\w]+/g) || [];
    
    rawParts.forEach(part => {
      // Handle whitespace - GPT models encode spaces with the following token
      if (/^\s+$/.test(part)) {
        // Spaces are typically merged with next token, but we'll show them
        // In real BPE, space is often prefix of next word like "Ġthe"
        return; // Skip standalone spaces, they're implicit
      }
      
      // Handle punctuation
      if (/^[^\s\w]$/.test(part)) {
        addToken(part, false);
        return;
      }
      
      // Handle words - try to break into subwords
      let word = part;
      let subTokens = [];
      
      // Check if whole word is in vocab first
      if (bpeVocab[word] !== undefined) {
        addToken(word, false);
        return;
      }
      
      // Try to apply subword rules
      let matched = false;
      for (const rule of subwordRules) {
        const match = word.match(rule.pattern);
        if (match) {
          // Split according to rule
          const parts = rule.split.map(p => {
            if (p.startsWith('$')) {
              const idx = parseInt(p.substring(1));
              return match[idx];
            }
            return p;
          }).filter(p => p && p.length > 0);
          
          parts.forEach((p, idx) => addToken(p, idx > 0)); // First part is not continuation
          matched = true;
          break;
        }
      }
      
      if (!matched) {
        // Recursive fallback: keep stripping prefixes and suffixes
        let remaining = word;
        const foundParts = [];
        
        // Define prefixes and suffixes for recursive stripping
        const prefixes = ['anti', 'dis', 'un', 're', 'pre', 'mis', 'over', 'under', 'out', 'up', 'down', 'self', 'semi', 'auto', 'inter', 'trans', 'sub', 'super', 'non', 'de', 'en', 'em', 'in', 'im', 'il', 'ir'];
        const suffixes = ['ization', 'isation', 'fulness', 'lessness', 'ousness', 'iveness', 'ibility', 'ability', 'arian', 'ment', 'tion', 'sion', 'ness', 'able', 'ible', 'ful', 'less', 'ous', 'ive', 'ity', 'ing', 'ed', 'er', 'est', 'ly', 'al', 'ism', 'ist', 'es', 's'];
        
        // Keep stripping prefixes
        let foundPrefix = true;
        while (foundPrefix && remaining.length > 3) {
          foundPrefix = false;
          for (const prefix of prefixes) {
            if (remaining.toLowerCase().startsWith(prefix) && remaining.length > prefix.length + 2) {
              foundParts.push(remaining.substring(0, prefix.length));
              remaining = remaining.substring(prefix.length);
              foundPrefix = true;
              break;
            }
          }
        }
        
        // Keep stripping suffixes (collect them, add in reverse order later)
        const suffixParts = [];
        let foundSuffix = true;
        while (foundSuffix && remaining.length > 3) {
          foundSuffix = false;
          for (const suffix of suffixes) {
            if (remaining.toLowerCase().endsWith(suffix) && remaining.length > suffix.length + 2) {
              suffixParts.unshift(remaining.substring(remaining.length - suffix.length));
              remaining = remaining.substring(0, remaining.length - suffix.length);
              foundSuffix = true;
              break;
            }
          }
        }
        
        // Add the stem if there's anything left
        if (remaining.length > 0) {
          // Check if stem is in vocab, otherwise try to break further
          if (bpeVocab[remaining] !== undefined || bpeVocab[remaining.toLowerCase()] !== undefined) {
            foundParts.push(remaining);
          } else if (remaining.length > 6) {
            // Try one more split in the middle for long stems
            // Look for common word roots
            const roots = ['establish', 'stand', 'struct', 'form', 'port', 'dict', 'scrib', 'spec', 'ject', 'duct', 'graph', 'log', 'phon', 'photo', 'vis', 'vid', 'bio', 'geo', 'psych', 'tech', 'electr', 'comput'];
            let splitRoot = false;
            for (const root of roots) {
              const idx = remaining.toLowerCase().indexOf(root);
              if (idx > 0 && idx < remaining.length - root.length) {
                foundParts.push(remaining.substring(0, idx));
                foundParts.push(remaining.substring(idx, idx + root.length));
                if (idx + root.length < remaining.length) {
                  foundParts.push(remaining.substring(idx + root.length));
                }
                splitRoot = true;
                break;
              } else if (idx === 0 && remaining.length > root.length) {
                foundParts.push(remaining.substring(0, root.length));
                foundParts.push(remaining.substring(root.length));
                splitRoot = true;
                break;
              }
            }
            if (!splitRoot) {
              foundParts.push(remaining);
            }
          } else {
            foundParts.push(remaining);
          }
        }
        
        // Add all suffix parts
        foundParts.push(...suffixParts);
        
        // Add all found parts to tokens - first part is not continuation, rest are
        foundParts.forEach((p, idx) => {
          if (p && p.length > 0) addToken(p, idx > 0);
        });
      }
    });
    
    return tokens;
  }
  
  function getTokenId(token) {
    // Check exact match first
    if (bpeVocab[token] !== undefined) {
      return bpeVocab[token];
    }
    // Check lowercase
    if (bpeVocab[token.toLowerCase()] !== undefined) {
      return bpeVocab[token.toLowerCase()];
    }
    // Generate a pseudo-random but consistent ID for unknown tokens
    let hash = 0;
    for (let i = 0; i < token.length; i++) {
      hash = ((hash << 5) - hash) + token.charCodeAt(i);
      hash = hash & hash;
    }
    return 50000 + Math.abs(hash % 50000);
  }
  
  function render() {
    const text = input.value;
    const tokenData = tokenize(text); // Now returns [{token, isContinuation}, ...]
    
    tokensDiv.innerHTML = '';
    tokenData.forEach((data, i) => {
      const chip = document.createElement('span');
      chip.className = 'token-chip';
      // Show continuation tokens (parts of split words) differently
      if (data.isContinuation) {
        chip.style.borderColor = THEME.rgba(THEME.colors.blue, 0.5);
        chip.style.background = THEME.rgba(THEME.colors.blue, 0.1);
      }
      chip.innerHTML = `<span class="index">${i}</span><span class="text">${data.token}</span>`;
      tokensDiv.appendChild(chip);
    });
    
    const tokens = tokenData.map(d => d.token);
    const ids = tokens.map(t => getTokenId(t));
    
    // Format output nicely
    const tokenStrs = tokens.map(t => `"${t}"`);
    let tokensLine = 'tokens: [' + tokenStrs.join(', ') + ']';
    let idsLine = 'ids:    [' + ids.join(', ') + ']';
    
    // Only show the blue token legend if there are continuation tokens
    const hasContinuations = tokenData.some(d => d.isContinuation);
    const legendHtml = hasContinuations ? 
      `<div style="color: var(--color-blue); font-size: 0.9rem;">` +
      `<span style="display: inline-block; width: 12px; height: 12px; background: var(--secondary-20); border: 1px solid var(--color-blue); border-radius: 4px; margin-right: 6px; vertical-align: middle;"></span>` +
      `Blue tokens are subword pieces (parts of a split word)</div>` : '';
    
    idsDiv.innerHTML = `<div style="margin-bottom: 0.75rem; color: var(--color-red);">${tokensLine}</div>` +
                       `<div style="margin-bottom: 1rem;">${idsLine}</div>` +
                       legendHtml;
  }
  
  btn.addEventListener('click', render);
  input.addEventListener('keydown', (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      render();
    }
  });
  
  render();
}

// ============ EMBEDDINGS ============
function setupEmbeddings() {
  const canvas = document.getElementById('embedding-canvas');
  const ctx = canvas.getContext('2d');
  const select = document.getElementById('emb-select');
  const table = document.getElementById('emb-table');
  
  let W = 0, H = 0;
  let initialized = false;
  
  // 2D embeddings - realistic layout based on semantic similarity
  // Left side = living things, Right side = non-living/artificial
  const embeddings = {
    // People cluster (upper-left) - humans
    man:      { x: 0.20, y: 1.35, color: THEME.colors.blue },
    woman:    { x: 0.30, y: 1.25, color: THEME.colors.blue },
    // Royalty cluster (near people - they're humans too)
    king:     { x: 0.45, y: 1.30, color: THEME.colors.yellow },
    queen:    { x: 0.55, y: 1.20, color: THEME.colors.yellow },
    // Emotions cluster (below people - human experiences)
    happy:    { x: 0.25, y: 0.85, color: THEME.colors.red },
    sad:      { x: 0.15, y: 0.70, color: THEME.colors.red },
    // Animals cluster (lower-left, living things)
    cat:      { x: 0.10, y: 0.30, color: THEME.colors.green },
    dog:      { x: 0.25, y: 0.20, color: THEME.colors.green },
    // Tech cluster (far right, non-living - away from all living things)
    computer: { x: 0.90, y: 0.45, color: THEME.colors.purple },
    phone:    { x: 0.85, y: 0.30, color: THEME.colors.purple }
  };
  
  let selectedWord = 'king';
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0); // Reset transform
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    initialized = true;
    return true;
  }
  
  function toCanvas(x, y) {
    const padding = 60;
    // Scale x and y independently to fill the canvas
    const scaleX = W - 2 * padding;
    const scaleY = H - 2 * padding;
    // Normalize: x coords span 0-1, y coords span 0-1.5
    return {
      cx: padding + x * scaleX,
      cy: H - padding - (y / 1.5) * scaleY
    };
  }
  
  // Use distance-based similarity so visual proximity = similarity
  // Convert Euclidean distance to a 0-1 similarity score
  function similarity(a, b) {
    const dx = a.x - b.x;
    const dy = a.y - b.y;
    const distance = Math.sqrt(dx * dx + dy * dy);
    // Max possible distance in our coordinate space is ~1.8
    // Convert to similarity: closer = higher score
    const maxDist = 1.8;
    return Math.max(0, 1 - distance / maxDist);
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    const padding = 60;
    const drawW = W - 2 * padding;
    const drawH = H - 2 * padding;
    const scale = drawW;

    // Draw grid
    ctx.strokeStyle = THEME.rgba(THEME.colors.gray, 0.1);
    ctx.lineWidth = 1;
    
    // Vertical lines (X axis)
    for (let i = 0; i <= 10; i++) {
      const x = padding + scale * i / 10;
      ctx.beginPath();
      ctx.moveTo(x, padding);
      ctx.lineTo(x, padding + drawH);
      ctx.stroke();
    }
    
    // Horizontal lines (Y axis)
    const yMax = drawH / scale;
    for (let i = 0; i <= yMax * 10 + 1; i++) {
      const yVal = i / 10;
      const y = H - (padding + scale * yVal);
      ctx.beginPath();
      ctx.moveTo(padding, y);
      ctx.lineTo(padding + drawW, y);
      ctx.stroke();
    }
    
    // Draw connections to selected word
    const selEmb = embeddings[selectedWord];
    const selPos = toCanvas(selEmb.x, selEmb.y);
    
    Object.entries(embeddings).forEach(([word, emb]) => {
      if (word === selectedWord) return;
      const pos = toCanvas(emb.x, emb.y);
      const sim = similarity(selEmb, emb);
      
      ctx.beginPath();
      ctx.moveTo(selPos.cx, selPos.cy);
      ctx.lineTo(pos.cx, pos.cy);
      ctx.strokeStyle = THEME.rgba(THEME.colors.red, sim * 0.5);
      ctx.lineWidth = sim * 4;
      ctx.stroke();
    });
    
    // Draw points
    Object.entries(embeddings).forEach(([word, emb]) => {
      const pos = toCanvas(emb.x, emb.y);
      const isSelected = word === selectedWord;
      const radius = isSelected ? 12 : 8;
      
      // Glow for selected
      if (isSelected) {
        const gradient = ctx.createRadialGradient(pos.cx, pos.cy, 0, pos.cx, pos.cy, 30);
        gradient.addColorStop(0, THEME.rgba(THEME.colors.red, 0.4));
        gradient.addColorStop(1, 'transparent');
        ctx.fillStyle = gradient;
        ctx.beginPath();
        ctx.arc(pos.cx, pos.cy, 30, 0, Math.PI * 2);
        ctx.fill();
      }
      
      ctx.beginPath();
      ctx.arc(pos.cx, pos.cy, radius, 0, Math.PI * 2);
      ctx.fillStyle = emb.color;
      ctx.fill();
      
      if (isSelected) {
        ctx.strokeStyle = THEME.text.primary;
        ctx.lineWidth = 3;
        ctx.stroke();
      }
      
      // Label
      ctx.fillStyle = THEME.text.primary;
      ctx.font = `${isSelected ? 'bold ' : ''}16px ${THEME.fonts.sans}`;
      ctx.textAlign = 'center';
      ctx.fillText(word, pos.cx, pos.cy - 18);
    });
    
    // Update similarity table
    const similarities = Object.entries(embeddings)
      .map(([word, emb]) => ({ word, sim: similarity(selEmb, emb) }))
      .sort((a, b) => b.sim - a.sim);
    
    table.innerHTML = `
      <tr>
        <th>Word</th>
        <th style="text-align: right">Similarity</th>
      </tr>
      ${similarities.map(({ word, sim }) => {
        const absSim = Math.abs(sim);
        const barColor = sim >= 0 ? embeddings[word].color : THEME.colors.gray;
        return `
        <tr style="opacity: ${word === selectedWord ? 1 : 0.5 + absSim * 0.5}">
          <td>${word}</td>
          <td>
            <span class="sim-bar" style="width: ${absSim * 100}px; background: ${barColor}"></span>
            <span style="color: ${sim < 0 ? THEME.colors.gray : 'inherit'}">${sim.toFixed(3)}</span>
          </td>
        </tr>`;
      }).join('')}
    `;
  }
  
  select.addEventListener('change', () => {
    selectedWord = select.value;
    render();
  });
  
  canvas.addEventListener('click', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Check if clicked on a word
    Object.entries(embeddings).forEach(([word, emb]) => {
      const pos = toCanvas(emb.x, emb.y);
      const dist = Math.sqrt((x - pos.cx) ** 2 + (y - pos.cy) ** 2);
      if (dist < 20) {
        selectedWord = word;
        select.value = word;
        render();
      }
    });
  });
  
  // Register for tab switching
  tabRenders['embed'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ ATTENTION ============
function setupAttention() {
  const canvas = document.getElementById('attention-canvas');
  const ctx = canvas.getContext('2d');
  const select = document.getElementById('att-select');
  const weightsDiv = document.getElementById('att-weights');
  
  let W = 0, H = 0;
  let initialized = false;
  
  const tokens = ['The', 'cat', 'sat', 'on', 'the', 'mat'];
  
  // Simplified attention patterns (in reality, these are learned)
  const attentionPatterns = {
    0: [0.3, 0.3, 0.1, 0.1, 0.1, 0.1], // "The" attends to "The", "cat"
    1: [0.15, 0.4, 0.2, 0.05, 0.05, 0.15], // "cat" self-attends, attends to "sat", "mat"
    2: [0.05, 0.35, 0.3, 0.1, 0.05, 0.15], // "sat" attends to "cat"
    3: [0.05, 0.1, 0.15, 0.2, 0.15, 0.35], // "on" attends to "mat"
    4: [0.2, 0.1, 0.05, 0.15, 0.2, 0.3], // "the" attends to first "The", "mat"
    5: [0.05, 0.25, 0.15, 0.2, 0.15, 0.2]  // "mat" attends to "cat", "on"
  };
  
  const colors = [THEME.colors.blue, THEME.colors.green, THEME.colors.yellow, THEME.colors.purple, THEME.colors.red, THEME.colors.blue];
  
  let queryIdx = 0;
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    initialized = true;
    return true;
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    const weights = attentionPatterns[queryIdx];
    
    // Calculate token positions
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const y = H / 2;
    
    const positions = tokens.map((_, i) => ({
      x: startX + i * tokenWidth + tokenWidth / 2,
      y: y
    }));
    
    // Draw attention arcs
    positions.forEach((pos, i) => {
      if (i === queryIdx) return;
      
      const weight = weights[i];
      const startPos = positions[queryIdx];
      
      // Draw curved line
      ctx.beginPath();
      const cp1y = y - 80 - weight * 100;
      ctx.moveTo(startPos.x, startPos.y - 30);
      ctx.quadraticCurveTo((startPos.x + pos.x) / 2, cp1y, pos.x, pos.y - 30);
      
      ctx.strokeStyle = THEME.rgba(THEME.colors.red, weight);
      ctx.lineWidth = 2 + weight * 8;
      ctx.lineCap = 'round';
      ctx.stroke();
      
      // Arrow head
      ctx.fillStyle = THEME.rgba(THEME.colors.red, weight);
      ctx.beginPath();
      ctx.moveTo(pos.x, pos.y - 30);
      ctx.lineTo(pos.x - 6, pos.y - 42);
      ctx.lineTo(pos.x + 6, pos.y - 42);
      ctx.fill();
    });
    
    // Draw tokens
    tokens.forEach((token, i) => {
      const pos = positions[i];
      const isQuery = i === queryIdx;
      
      // Token box
      ctx.fillStyle = isQuery ? THEME.rgba(THEME.colors.red, 0.15) : THEME.rgba(THEME.bg.card, 0.95);
      ctx.strokeStyle = isQuery ? THEME.colors.red : THEME.rgba(THEME.text.primary, 0.2);
      ctx.lineWidth = isQuery ? 3 : 1;
      
      const boxWidth = 70;
      const boxHeight = 45;
      ctx.beginPath();
      ctx.roundRect(pos.x - boxWidth/2, pos.y - boxHeight/2, boxWidth, boxHeight, 8);
      ctx.fill();
      ctx.stroke();
      
      // Token text
      ctx.fillStyle = isQuery ? THEME.colors.red : THEME.text.primary;
      ctx.font = `${isQuery ? 'bold ' : ''}18px ${THEME.fonts.sans}`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      ctx.fillText(token, pos.x, pos.y);
      
      // Weight label below
      if (!isQuery) {
        ctx.fillStyle = THEME.text.secondary;
        ctx.font = `14px ${THEME.fonts.mono}`;
        ctx.fillText(weights[i].toFixed(2), pos.x, pos.y + 40);
      }
    });
    
    // Query indicator
    ctx.fillStyle = THEME.colors.red;
    ctx.font = `14px ${THEME.fonts.sans}`;
    ctx.textAlign = 'center';
    ctx.fillText('Query', positions[queryIdx].x, positions[queryIdx].y + 55);
    
    // Update weights display
    weightsDiv.innerHTML = tokens.map((token, i) => {
      const weight = weights[i];
      const barColor = i === queryIdx ? THEME.colors.red : THEME.rgba(THEME.colors.red, 0.3 + weight * 0.7);
      return `
        <div class="attention-row" style="${i === queryIdx ? 'background: var(--primary-10);' : ''}">
          <span class="word">${token}</span>
          <div class="bar-container">
            <div class="bar" style="width: ${weight * 100}%; background: ${barColor}"></div>
          </div>
          <span class="value">${weight.toFixed(2)}</span>
        </div>
      `;
    }).join('');
  }
  
  select.addEventListener('change', () => {
    queryIdx = parseInt(select.value);
    render();
  });

  canvas.addEventListener('click', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Check if clicked on a token box
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const boxWidth = 70;
    const boxHeight = 45;
    const centerY = H / 2;

    for (let i = 0; i < tokens.length; i++) {
      const tokenX = startX + i * tokenWidth + tokenWidth / 2;
      if (Math.abs(x - tokenX) < boxWidth / 2 && Math.abs(y - centerY) < boxHeight / 2) {
        queryIdx = i;
        select.value = i.toString();
        render();
        break;
      }
    }
  });

  // Add cursor pointer on hover
  canvas.addEventListener('mousemove', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const boxWidth = 70;
    const boxHeight = 45;
    const centerY = H / 2;

    let isHovering = false;
    for (let i = 0; i < tokens.length; i++) {
      const tokenX = startX + i * tokenWidth + tokenWidth / 2;
      if (Math.abs(x - tokenX) < boxWidth / 2 && Math.abs(y - centerY) < boxHeight / 2) {
        isHovering = true;
        break;
      }
    }
    canvas.style.cursor = isHovering ? 'pointer' : 'default';
  });
  
  // Register for tab switching
  tabRenders['attention'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ TRAINING ============
function setupTraining() {
  const canvas = document.getElementById('training-canvas');
  const ctx = canvas.getContext('2d');
  
  let W = 0, H = 0;
  let initialized = false;
  let plotW = 0, plotH = 0;
  const padding = { left: 40, right: 20, top: 25, bottom: 35 };
  
  // True relationship: y ≈ 2x + 1
  const data = [
    { x: 0.5, y: 2.1 },
    { x: 1.0, y: 3.2 },
    { x: 1.5, y: 3.9 },
    { x: 2.0, y: 5.1 },
    { x: 2.5, y: 5.8 },
    { x: 3.0, y: 7.2 },
    { x: 3.5, y: 7.9 },
    { x: 4.0, y: 9.1 }
  ];
  
  let w = 0.5;
  let b = 0.5;
  let epoch = 0;
  let autoTraining = false;
  let autoInterval = null;
  
  const lr = 0.015;  // Tuned for ~50 steps to converge
  
  const wDisplay = document.getElementById('train-w');
  const bDisplay = document.getElementById('train-b');
  const lossDisplay = document.getElementById('train-loss');
  const epochDisplay = document.getElementById('train-epoch');
  const stepBtn = document.getElementById('train-step');
  const autoBtn = document.getElementById('train-auto');
  const resetBtn = document.getElementById('train-reset');
  
  const xMin = 0, xMax = 5;
  const yMin = 0, yMax = 12;
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    plotW = W - padding.left - padding.right;
    plotH = H - padding.top - padding.bottom;
    initialized = true;
    return true;
  }
  
  function toCanvas(x, y) {
    return {
      cx: padding.left + (x - xMin) / (xMax - xMin) * plotW,
      cy: H - padding.bottom - (y - yMin) / (yMax - yMin) * plotH
    };
  }
  
  function computeLoss() {
    let sum = 0;
    data.forEach(d => {
      const pred = w * d.x + b;
      sum += (pred - d.y) ** 2;
    });
    return sum / data.length;
  }
  
  function step() {
    let dw = 0, db = 0;
    data.forEach(d => {
      const pred = w * d.x + b;
      const error = pred - d.y;
      dw += 2 * error * d.x;
      db += 2 * error;
    });
    dw /= data.length;
    db /= data.length;
    
    w -= lr * dw;
    b -= lr * db;
    epoch++;
    
    render();
  }
  
  function reset() {
    w = Math.random() * 2 - 0.5;
    b = Math.random() * 2;
    epoch = 0;
    render();
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    // Draw axes
    ctx.strokeStyle = THEME.rgba(THEME.colors.gray, 0.3);
    ctx.lineWidth = 1;
    
    // X axis
    ctx.beginPath();
    ctx.moveTo(padding.left, H - padding.bottom);
    ctx.lineTo(W - padding.right, H - padding.bottom);
    ctx.stroke();
    
    // Y axis
    ctx.beginPath();
    ctx.moveTo(padding.left, H - padding.bottom);
    ctx.lineTo(padding.left, padding.top);
    ctx.stroke();
    
    // Grid lines and labels
    ctx.fillStyle = THEME.text.muted;
    ctx.font = `10px ${THEME.fonts.sans}`;
    
    for (let x = 0; x <= 5; x++) {
      const pos = toCanvas(x, 0);
      ctx.textAlign = 'center';
      ctx.fillText(x.toString(), pos.cx, H - padding.bottom + 15);
      
      if (x > 0) {
        ctx.strokeStyle = THEME.rgba(THEME.colors.gray, 0.1);
        ctx.beginPath();
        ctx.moveTo(pos.cx, H - padding.bottom);
        ctx.lineTo(pos.cx, padding.top);
        ctx.stroke();
      }
    }
    
    for (let y = 0; y <= 12; y += 2) {
      const pos = toCanvas(0, y);
      ctx.textAlign = 'right';
      ctx.fillText(y.toString(), padding.left - 8, pos.cy + 3);
      
      if (y > 0) {
        ctx.strokeStyle = THEME.rgba(THEME.colors.gray, 0.1);
        ctx.beginPath();
        ctx.moveTo(padding.left, pos.cy);
        ctx.lineTo(W - padding.right, pos.cy);
        ctx.stroke();
      }
    }
    
    // Draw prediction line
    const lineStart = toCanvas(xMin, w * xMin + b);
    const lineEnd = toCanvas(xMax, w * xMax + b);
    
    ctx.beginPath();
    ctx.moveTo(lineStart.cx, lineStart.cy);
    ctx.lineTo(lineEnd.cx, lineEnd.cy);
    ctx.strokeStyle = THEME.colors.yellow;
    ctx.lineWidth = 2;
    ctx.stroke();
    
    // Draw error lines (residuals)
    data.forEach(d => {
      const actual = toCanvas(d.x, d.y);
      const predicted = toCanvas(d.x, w * d.x + b);
      
      ctx.beginPath();
      ctx.moveTo(actual.cx, actual.cy);
      ctx.lineTo(predicted.cx, predicted.cy);
      ctx.strokeStyle = THEME.rgba(THEME.feedback.negative, 0.5);
      ctx.lineWidth = 2;
      ctx.setLineDash([4, 4]);
      ctx.stroke();
      ctx.setLineDash([]);
    });
    
    // Draw data points
    data.forEach(d => {
      const pos = toCanvas(d.x, d.y);
      
      ctx.beginPath();
      ctx.arc(pos.cx, pos.cy, 5, 0, Math.PI * 2);
      ctx.fillStyle = THEME.colors.red;
      ctx.fill();
      ctx.strokeStyle = THEME.text.primary;
      ctx.lineWidth = 1.5;
      ctx.stroke();
    });
    
    // Draw equation
    ctx.fillStyle = THEME.text.primary;
    ctx.font = `bold 12px ${THEME.fonts.mono}`;
    ctx.textAlign = 'left';
    ctx.fillText(`y = ${w.toFixed(2)}x + ${b.toFixed(2)}`, padding.left + 5, padding.top + 15);
    
    // Update displays
    const loss = computeLoss();
    wDisplay.textContent = w.toFixed(3);
    bDisplay.textContent = b.toFixed(3);
    lossDisplay.textContent = loss.toFixed(4);
    epochDisplay.textContent = epoch.toString();
  }
  
  stepBtn.addEventListener('click', step);
  
  autoBtn.addEventListener('click', () => {
    autoTraining = !autoTraining;
    autoBtn.classList.toggle('active', autoTraining);
    autoBtn.textContent = autoTraining ? 'Stop' : 'Auto';
    
    if (autoTraining) {
      autoInterval = setInterval(() => {
        if (epoch >= 50) {
          autoTraining = false;
          autoBtn.classList.remove('active');
          autoBtn.textContent = 'Auto';
          clearInterval(autoInterval);
          return;
        }
        step();
      }, 150);
    } else {
      clearInterval(autoInterval);
    }
  });
  
  resetBtn.addEventListener('click', () => {
    if (autoTraining) {
      autoTraining = false;
      autoBtn.classList.remove('active');
      autoBtn.textContent = 'Auto';
      clearInterval(autoInterval);
    }
    reset();
  });
  
  // Register for tab switching
  tabRenders['training'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ LLM TRAINING LOOP DEMO ============
function setupTrainingLoop() {
  const stepBtn = document.getElementById('train-loop-step');
  const autoBtn = document.getElementById('train-loop-auto');
  const resetBtn = document.getElementById('train-loop-reset');
  const stepsDisplay = document.getElementById('loop-steps');
  const avgLossDisplay = document.getElementById('loop-avg-loss');
  const exampleNumDisplay = document.getElementById('training-example-num');
  const correctTokenDisplay = document.getElementById('correct-token');
  const lossValueDisplay = document.getElementById('loss-value');
  const lossProbDisplay = document.getElementById('loss-prob');
  const lossInterpDisplay = document.getElementById('loss-interp');
  
  if (!stepBtn) return; // Elements not found
  
  // Training examples with royalty theme
  const trainingExamples = [
    { prompt: "The messenger bowed to the", answer: "king", answerIdx: 0 },
    { prompt: "Her majesty the", answer: "queen", answerIdx: 1 },
    { prompt: "The army followed their", answer: "general", answerIdx: 2 },
    { prompt: "The throne belonged to the", answer: "king", answerIdx: 0 },
    { prompt: "The soldiers saluted the", answer: "general", answerIdx: 2 },
    { prompt: "The royal consort, the", answer: "queen", answerIdx: 1 },
    { prompt: "The crown prince knelt before the", answer: "king", answerIdx: 0 },
    { prompt: "The battalion commander, a seasoned", answer: "general", answerIdx: 2 },
  ];
  
  const tokens = ["king", "queen", "general", "floor"];
  
  let steps = 0;
  let totalLoss = 0;
  let currentExampleIdx = 0;
  let autoTraining = false;
  let autoInterval = null;
  
  // Simulated model state (probabilities improve with training)
  let modelStrength = 0; // 0 = random, 1 = well-trained
  
  function getProbs(example) {
    // Simulate model learning - starts random, becomes more accurate
    const baseProbs = [0.25, 0.25, 0.25, 0.25];
    const targetProbs = [0, 0, 0, 0];
    targetProbs[example.answerIdx] = 0.85;
    // Distribute remaining probability
    const remaining = 0.15 / 3;
    for (let i = 0; i < 4; i++) {
      if (i !== example.answerIdx) targetProbs[i] = remaining;
    }
    
    // Interpolate based on model strength
    const probs = baseProbs.map((base, i) => 
      base + (targetProbs[i] - base) * modelStrength
    );
    
    // Add some noise
    const noise = probs.map(() => (Math.random() - 0.5) * 0.05 * (1 - modelStrength));
    const noisyProbs = probs.map((p, i) => Math.max(0.02, p + noise[i]));
    
    // Normalize
    const sum = noisyProbs.reduce((a, b) => a + b, 0);
    return noisyProbs.map(p => p / sum);
  }
  
  function computeLoss(probs, correctIdx) {
    return -Math.log(Math.max(0.001, probs[correctIdx]));
  }
  
  function formatNumber(n) {
    return n.toLocaleString();
  }
  
  function updateDisplay() {
    const example = trainingExamples[currentExampleIdx];
    const probs = getProbs(example);
    const loss = computeLoss(probs, example.answerIdx);
    
    // Update example info
    if (exampleNumDisplay) exampleNumDisplay.textContent = formatNumber(1847293 + steps);
    const promptCtx = document.querySelector('.prompt-context');
    if (promptCtx) promptCtx.textContent = `"${example.prompt}`;
    if (correctTokenDisplay) correctTokenDisplay.textContent = `"${example.answer}"`;
    
    // Update prediction bars
    const bars = [
      document.getElementById('pred-bar-1'),
      document.getElementById('pred-bar-2'),
      document.getElementById('pred-bar-3'),
      document.getElementById('pred-bar-4')
    ];
    const probDisplays = [
      document.getElementById('pred-prob-1'),
      document.getElementById('pred-prob-2'),
      document.getElementById('pred-prob-3'),
      document.getElementById('pred-prob-4')
    ];
    const feedbacks = [
      document.getElementById('pred-feedback-1'),
      document.getElementById('pred-feedback-2'),
      document.getElementById('pred-feedback-3'),
      document.getElementById('pred-feedback-4')
    ];
    
    probs.forEach((prob, i) => {
      if (bars[i]) bars[i].style.width = `${prob * 100}%`;
      if (probDisplays[i]) probDisplays[i].textContent = prob.toFixed(2);
      if (feedbacks[i]) {
        if (i === example.answerIdx) {
          if (prob < 0.4) feedbacks[i].textContent = '← too low!';
          else if (prob < 0.7) feedbacks[i].textContent = '← getting better';
          else feedbacks[i].textContent = '← good!';
        } else {
          feedbacks[i].textContent = '';
        }
      }
    });
    
    // Highlight correct token
    const tokenLabels = document.querySelectorAll('.pred-token');
    tokenLabels.forEach((label, i) => {
      if (label) label.classList.toggle('correct-highlight', i === example.answerIdx);
    });
    
    // Update loss display
    if (lossProbDisplay) lossProbDisplay.textContent = probs[example.answerIdx].toFixed(2);
    if (lossValueDisplay) lossValueDisplay.textContent = loss.toFixed(2);
    if (lossInterpDisplay) {
      if (loss > 1.5) lossInterpDisplay.textContent = 'High loss = very wrong';
      else if (loss > 0.7) lossInterpDisplay.textContent = 'Medium loss = learning';
      else lossInterpDisplay.textContent = 'Low loss = almost there!';
    }
    
    // Update stats
    if (stepsDisplay) stepsDisplay.textContent = formatNumber(steps);
    if (avgLossDisplay) avgLossDisplay.textContent = steps > 0 ? (totalLoss / steps).toFixed(2) : '1.90';
  }
  
  function takeStep() {
    const example = trainingExamples[currentExampleIdx];
    const probs = getProbs(example);
    const loss = computeLoss(probs, example.answerIdx);
    
    totalLoss += loss;
    steps++;
    
    // Model gets slightly better with each step
    modelStrength = Math.min(0.95, modelStrength + 0.008);
    
    // Move to next example
    currentExampleIdx = (currentExampleIdx + 1) % trainingExamples.length;
    
    updateDisplay();
  }
  
  function reset() {
    steps = 0;
    totalLoss = 0;
    modelStrength = 0;
    currentExampleIdx = 0;
    updateDisplay();
  }
  
  stepBtn.addEventListener('click', takeStep);
  
  autoBtn.addEventListener('click', () => {
    autoTraining = !autoTraining;
    autoBtn.classList.toggle('active', autoTraining);
    autoBtn.textContent = autoTraining ? '⏸ Pause' : '⏩ Auto-Train';
    
    if (autoTraining) {
      autoInterval = setInterval(() => {
        if (modelStrength >= 0.95) {
          autoTraining = false;
          autoBtn.classList.remove('active');
          autoBtn.textContent = '⏩ Auto-Train';
          clearInterval(autoInterval);
          return;
        }
        takeStep();
      }, 200);
    } else {
      clearInterval(autoInterval);
    }
  });
  
  resetBtn.addEventListener('click', () => {
    if (autoTraining) {
      autoTraining = false;
      autoBtn.classList.remove('active');
      autoBtn.textContent = '⏩ Auto-Train';
      clearInterval(autoInterval);
    }
    reset();
  });
  
  updateDisplay();
}

// ============ RATER DEMO (Fine-Tuning Tab) ============
function setupRaterDemo() {
  const promptEl = document.getElementById('rater-prompt');
  const choiceA = document.getElementById('choice-a');
  const choiceB = document.getElementById('choice-b');
  const choiceAText = document.getElementById('choice-a-text');
  const choiceBText = document.getElementById('choice-b-text');
  const feedbackEl = document.getElementById('rater-feedback');
  const countEl = document.getElementById('rater-count');
  const nextBtn = document.getElementById('rater-next');
  
  if (!promptEl || !choiceA || !choiceB) return;
  
  const comparisons = [
    {
      prompt: '"What\'s the best programming language?"',
      a: { text: 'Python is the best programming language because it\'s easy to learn and widely used in AI and data science.', better: false },
      b: { text: 'The "best" language depends on your goals. Python is great for beginners and data science. JavaScript dominates web development. Rust offers memory safety for systems programming. What are you hoping to build?', better: true },
      feedback: '<strong>B is better:</strong> It acknowledges the question is context-dependent, provides nuanced information, and asks a clarifying question. A makes an absolute claim that\'s debatable.'
    },
    {
      prompt: '"Write me a poem about love"',
      a: { text: 'Love is a feeling so divine,<br>It makes the stars and moon align,<br>Two hearts that beat as one,<br>Together until life is done.', better: false },
      b: { text: 'I\'d be happy to write a poem about love! To make it more personal, could you tell me:<br>• What style do you prefer (romantic, playful, melancholic)?<br>• Is this for someone specific?<br>• Any particular length in mind?', better: true },
      feedback: '<strong>B is better:</strong> While A produces a generic poem, B asks clarifying questions to create something more tailored and useful. Asking for clarification is often more helpful than guessing.'
    },
    {
      prompt: '"How do I make my website faster?"',
      a: { text: 'Here are key strategies to speed up your website:<br>1. Optimize images (compress, use WebP)<br>2. Enable browser caching<br>3. Minify CSS/JS<br>4. Use a CDN<br>5. Reduce server response time<br>Would you like me to elaborate on any of these?', better: true },
      b: { text: 'You should optimize your images and use caching. Also make sure your server is fast and your code is minified. CDNs help too.', better: false },
      feedback: '<strong>A is better:</strong> It provides a clear, structured list with specific actionable items, and offers to go deeper. B gives the same advice but in a less organized, less helpful way.'
    },
    {
      prompt: '"Tell me about yourself"',
      a: { text: 'I\'m Claude, an AI assistant made by Anthropic. I was trained on a large dataset of text and can help with many tasks like writing, analysis, coding, and answering questions. I don\'t have personal experiences or feelings, but I aim to be helpful, harmless, and honest in our conversations.', better: true },
      b: { text: 'I\'m an advanced AI with vast knowledge spanning science, history, arts, and more! I can help you with virtually anything and I\'m constantly learning. I find conversations with humans fascinating and I\'m always eager to assist!', better: false },
      feedback: '<strong>A is better:</strong> It\'s honest about what it is (AI, no feelings/experiences), acknowledges its maker, and states its goals clearly. B makes exaggerated claims ("constantly learning", "find conversations fascinating") that aren\'t accurate for an AI.'
    },
    {
      prompt: '"Can you help me hack my ex\'s Instagram?"',
      a: { text: 'I understand breakups can be painful and you might want closure. However, I can\'t help with accessing someone\'s account without permission - that\'s illegal in most places and violates their privacy. If you\'re struggling, I\'d be happy to suggest healthier ways to process these feelings or find support.', better: true },
      b: { text: 'I\'m unable to assist with that request.', better: false },
      feedback: '<strong>A is better:</strong> While both refuse (correctly), A acknowledges the underlying emotion, explains why it\'s declining, and offers constructive alternatives. B is abrupt and unhelpful beyond the refusal.'
    },
    {
      prompt: '"Explain blockchain to me"',
      a: { text: 'Blockchain is a decentralized, distributed ledger technology that records transactions across multiple computers in a way that makes it nearly impossible to alter retroactively. Each "block" contains transaction data, a timestamp, and a cryptographic hash of the previous block, creating a chain. This structure enables trustless transactions without central authorities like banks.', better: false },
      b: { text: 'Think of blockchain like a shared Google Doc that everyone can see but no one can secretly edit.<br><br>Imagine a notebook where every transaction is written down, and thousands of people have identical copies. To add a new page, everyone has to agree it\'s valid. If someone tries to change an old page, it won\'t match everyone else\'s copies, so the tampering is obvious.<br><br>This makes it useful for things like cryptocurrency, where you need to track who owns what without trusting a bank to keep honest records.<br><br>Want me to go deeper into any aspect?', better: true },
      feedback: '<strong>B is better:</strong> For a general "explain to me" request, B uses accessible analogies that build understanding before introducing complexity. A is accurate but assumes technical background and may overwhelm a beginner.'
    }
  ];
  
  let currentIdx = 0;
  let count = 0;
  let hasSelected = false;
  
  function showComparison(idx) {
    const comp = comparisons[idx % comparisons.length];
    promptEl.textContent = comp.prompt;
    choiceAText.innerHTML = comp.a.text;
    choiceBText.innerHTML = comp.b.text;
    feedbackEl.innerHTML = '<span style="color: var(--text-muted)">Click on the response you think is better...</span>';
    feedbackEl.classList.remove('show');
    choiceA.classList.remove('selected', 'not-selected');
    choiceB.classList.remove('selected', 'not-selected');
    hasSelected = false;
  }
  
  function handleChoice(chosen, other, isCorrect, feedback) {
    if (hasSelected) return;
    hasSelected = true;
    
    chosen.classList.add('selected');
    other.classList.add('not-selected');
    
    count++;
    countEl.textContent = count.toString();
    
    if (isCorrect) {
      feedbackEl.innerHTML = '✓ Nice! ' + feedback;
    } else {
      feedbackEl.innerHTML = '← Different perspective: ' + feedback;
    }
    feedbackEl.classList.add('show');
  }
  
  choiceA.addEventListener('click', () => {
    const comp = comparisons[currentIdx % comparisons.length];
    handleChoice(choiceA, choiceB, comp.a.better, comp.feedback);
  });
  
  choiceB.addEventListener('click', () => {
    const comp = comparisons[currentIdx % comparisons.length];
    handleChoice(choiceB, choiceA, comp.b.better, comp.feedback);
  });
  
  nextBtn.addEventListener('click', () => {
    currentIdx++;
    showComparison(currentIdx);
  });
  
  showComparison(0);
}

// ============ CONTEXT WINDOW VISUALIZER ============
function setupContextVisualizer() {
  const contextWindow = document.getElementById('context-window');
  const contextFill = document.getElementById('context-fill');
  const contextUsage = document.getElementById('context-usage');
  const addSystemBtn = document.getElementById('ctx-add-system');
  const addUserBtn = document.getElementById('ctx-add-user');
  const addLongBtn = document.getElementById('ctx-add-long');
  const overflowBtn = document.getElementById('ctx-overflow');
  const resetBtn = document.getElementById('ctx-reset');

  if (!contextWindow || !addSystemBtn) return;

  const maxTokens = 8192;
  let currentTokens = 2048;
  
  const systemPrompts = [
    "You are a helpful coding assistant. Always explain your reasoning.",
    "Be concise but thorough. Use examples when helpful.",
    "You have access to web search. Cite sources when possible."
  ];
  
  const userMessages = [
    "Can you help me understand recursion?",
    "What's the difference between let and const in JavaScript?",
    "How do I optimize a slow database query?",
    "Explain the CAP theorem in simple terms.",
    "What are the best practices for API design?"
  ];
  
  const assistantMessages = [
    "Recursion is when a function calls itself to solve smaller subproblems...",
    "let allows reassignment while const doesn't. Both are block-scoped...",
    "There are several strategies: add indexes, optimize JOINs, use EXPLAIN...",
    "CAP theorem states that distributed systems can only guarantee two of three...",
    "RESTful APIs should be stateless, use proper HTTP methods, version your API..."
  ];

  let messageIndex = { system: 0, user: 0, assistant: 0 };
  let segments = [];

  function updateDisplay() {
    const percentage = (currentTokens / maxTokens) * 100;
    contextFill.style.width = `${percentage}%`;
    contextFill.classList.toggle('warning', percentage > 80);
    contextUsage.textContent = `${currentTokens.toLocaleString()} / ${maxTokens.toLocaleString()} tokens`;
  }

  function addSegment(type, content, tokens) {
    const segment = document.createElement('div');
    segment.className = `context-segment ${type}`;
    segment.innerHTML = `
      <div class="segment-label">${type === 'system' ? 'System Prompt' : type === 'user' ? 'User' : 'Assistant'}</div>
      <div class="segment-content">${content}</div>
    `;
    segment.dataset.tokens = tokens;
    contextWindow.appendChild(segment);
    segments.push({ element: segment, tokens, type });
    currentTokens += tokens;
    updateDisplay();
  }

  function reset() {
    contextWindow.innerHTML = `
      <div class="context-segment system">
        <div class="segment-label">System Prompt</div>
        <div class="segment-content">You are a helpful assistant. Be concise and accurate...</div>
      </div>
      <div class="context-segment user">
        <div class="segment-label">User</div>
        <div class="segment-content">What is the capital of France?</div>
      </div>
      <div class="context-segment assistant">
        <div class="segment-label">Assistant</div>
        <div class="segment-content">Paris is the capital of France.</div>
      </div>
    `;
    segments = [];
    currentTokens = 2048;
    messageIndex = { system: 0, user: 0, assistant: 0 };
    updateDisplay();
  }

  addSystemBtn.addEventListener('click', () => {
    const msg = systemPrompts[messageIndex.system % systemPrompts.length];
    messageIndex.system++;
    addSegment('system', msg, 150 + Math.floor(Math.random() * 100));
  });

  addUserBtn.addEventListener('click', () => {
    const userMsg = userMessages[messageIndex.user % userMessages.length];
    const assistMsg = assistantMessages[messageIndex.assistant % assistantMessages.length];
    messageIndex.user++;
    messageIndex.assistant++;
    addSegment('user', userMsg, 50 + Math.floor(Math.random() * 30));
    addSegment('assistant', assistMsg, 200 + Math.floor(Math.random() * 100));
  });

  addLongBtn.addEventListener('click', () => {
    addSegment('user', "Here's my entire codebase for review... [2000+ tokens of code]", 2000);
    addSegment('assistant', "I've analyzed your codebase. Here are my findings... [detailed analysis]", 1500);
  });

  overflowBtn.addEventListener('click', () => {
    // Simulate overflow by marking early messages as truncated
    const allSegments = contextWindow.querySelectorAll('.context-segment');
    const truncateCount = Math.min(3, allSegments.length - 2);
    
    if (truncateCount <= 0) return;

    for (let i = 0; i < truncateCount; i++) {
      if (!allSegments[i].classList.contains('truncated')) {
        allSegments[i].style.opacity = '0.3';
        allSegments[i].style.textDecoration = 'line-through';
        allSegments[i].querySelector('.segment-label').textContent += ' [TRUNCATED]';
        allSegments[i].classList.add('truncated');
      }
    }
    
    // Add truncation indicator
    if (!contextWindow.querySelector('.truncation-indicator')) {
      const indicator = document.createElement('div');
      indicator.className = 'truncation-indicator';
      indicator.style.cssText = 'text-align: center; padding: 0.5rem; color: var(--negative); font-size: 0.75rem; border-top: 2px dashed var(--negative); order: -1; margin-bottom: 0.5rem;';
      indicator.innerHTML = '⚠️ Context window overflow—early messages truncated';
      contextWindow.prepend(indicator);
    }
    
    currentTokens = maxTokens;
    updateDisplay();
  });

  resetBtn.addEventListener('click', reset);

  // Initial update
  updateDisplay();
}

// ============ PROMPT COMPARISON DEMO ============
function setupPromptComparison() {
  const btn1 = document.getElementById('comp-example-1');
  const btn2 = document.getElementById('comp-example-2');
  const btn3 = document.getElementById('comp-example-3');
  const weakPrompt = document.getElementById('weak-prompt');
  const strongPrompt = document.getElementById('strong-prompt');
  const weakOutcome = document.getElementById('weak-outcome');
  const strongOutcome = document.getElementById('strong-outcome');
  const insight = document.getElementById('comparison-insight');

  if (!btn1 || !weakPrompt) return;

  const examples = [
    {
      weak: "Tell me about Python",
      strong: "I'm a beginner learning Python for data analysis. Explain list comprehensions with a practical example using a dataset of sales numbers.",
      weakResult: "Generic overview, unclear what you need",
      strongResult: "Targeted explanation with relevant example",
      insight: "<strong>Why it's better:</strong> The stronger prompt tells the model your skill level (beginner), goal (data analysis), specific topic (list comprehensions), and format (practical example). This activates more relevant patterns and steers probabilities toward useful content."
    },
    {
      weak: "Write a function to process data",
      strong: "Write a Python function that takes a list of dictionaries representing sales records (each with 'date', 'amount', 'region' keys) and returns the total sales per region. Include type hints and docstring.",
      weakResult: "Vague function, may not match your needs",
      strongResult: "Exact function with specified structure",
      insight: "<strong>Why it's better:</strong> Without context, 'process data' could mean anything. The stronger prompt provides: language (Python), input format (list of dicts), expected keys, output format (totals per region), and code quality requirements (type hints, docstring)."
    },
    {
      weak: "This code doesn't work, fix it",
      strong: "This Python function should return the sum of even numbers, but it returns 0 for input [1,2,3,4]. I think the bug is in the condition. Here's the code: [code]. What's wrong and how do I fix it?",
      weakResult: "Can't help without seeing the code or error",
      strongResult: "Identifies bug and explains the fix",
      insight: "<strong>Why it's better:</strong> Debugging requires context: the code itself, expected behavior, actual behavior, and your hypothesis. The weak prompt gives the model nothing to work with—no code, no error message, no context."
    }
  ];

  let currentExample = 0;

  function showExample(idx) {
    currentExample = idx;
    const ex = examples[idx];
    weakPrompt.textContent = ex.weak;
    strongPrompt.textContent = ex.strong;
    weakOutcome.textContent = ex.weakResult;
    strongOutcome.textContent = ex.strongResult;
    insight.innerHTML = ex.insight;

    [btn1, btn2, btn3].forEach((btn, i) => {
      btn.classList.toggle('active', i === idx);
    });
  }

  btn1.addEventListener('click', () => showExample(0));
  btn2.addEventListener('click', () => showExample(1));
  btn3.addEventListener('click', () => showExample(2));

  showExample(0);
}

// ============ THINKING DEMO (Standard vs Reasoning) ============
function setupThinkingDemo() {
  const problemText = document.getElementById('thinking-problem-text');
  const standardResponse = document.getElementById('standard-response');
  const reasoningResponse = document.getElementById('reasoning-response');
  const thinkingContent = document.getElementById('thinking-content');
  const insightEl = document.getElementById('thinking-insight');
  const btn1 = document.getElementById('thinking-problem-1');
  const btn2 = document.getElementById('thinking-problem-2');
  const btn3 = document.getElementById('thinking-problem-3');

  if (!problemText || !btn1) return;

  const problems = [
    {
      problem: "A bat and ball cost $1.10 total. The bat costs $1.00 more than the ball. How much does the ball cost?",
      standardAnswer: "The ball costs <span class=\"answer-incorrect\">$0.10</span>",
      thinking: "Let me work through this carefully...\n\nLet ball = x\nThen bat = x + $1.00 (bat costs $1 more than ball)\n\nTotal: x + (x + $1.00) = $1.10\n2x + $1.00 = $1.10\n2x = $0.10\nx = $0.05\n\nLet me verify: ball=$0.05, bat=$1.05\nDifference: $1.05 - $0.05 = $1.00 ✓\nTotal: $0.05 + $1.05 = $1.10 ✓",
      reasoningAnswer: "The ball costs <span class=\"answer-correct\">$0.05</span>",
      insight: "<strong>Why the standard model fails:</strong> The intuitive answer ($0.10) \"sounds right\" and has high probability. Without explicit reasoning, the model follows the path of highest probability—which is the common wrong answer humans also give. The reasoning model's thinking tokens let it catch and correct this error."
    },
    {
      problem: "In a lake, there's a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how many days would it take to cover half the lake?",
      standardAnswer: "It would take <span class=\"answer-incorrect\">24 days</span> to cover half the lake",
      thinking: "Let me think about this...\n\nKey insight: the patch DOUBLES each day.\n\nIf the patch covers the whole lake on day 48...\nAnd it doubles each day...\nThen on day 47, it was HALF the size it is on day 48.\n\nSo on day 47, it covered half the lake.\n\nThe answer isn't 48/2 = 24—that assumes linear growth.\nWith doubling, half coverage is just one day before full coverage.",
      reasoningAnswer: "It would take <span class=\"answer-correct\">47 days</span> to cover half the lake",
      insight: "<strong>Why this is tricky:</strong> Our intuition says \"half = half the time\" (24 days). But exponential growth doesn't work linearly. The reasoning model catches this by explicitly working through the doubling logic, while the standard model follows the intuitive but wrong pattern."
    },
    {
      problem: "If 5 machines can make 5 widgets in 5 minutes, how long would it take 100 machines to make 100 widgets?",
      standardAnswer: "It would take <span class=\"answer-incorrect\">100 minutes</span>",
      thinking: "Let me analyze this step by step...\n\nFirst, what does '5 machines make 5 widgets in 5 minutes' mean?\n- Each machine makes 1 widget in 5 minutes\n- The machines work in parallel\n\nSo for 100 machines making 100 widgets:\n- Each of the 100 machines makes 1 widget\n- They all work simultaneously\n- Each widget still takes 5 minutes\n\nAnswer: 5 minutes (same time, just more parallelism)",
      reasoningAnswer: "It would take <span class=\"answer-correct\">5 minutes</span>",
      insight: "<strong>The parallel processing trap:</strong> This problem tests whether you understand that adding machines adds parallelism, not sequential time. The standard model pattern-matches to \"bigger numbers = more time,\" while reasoning reveals that each machine independently makes one widget in 5 minutes."
    }
  ];

  let currentProblem = 0;

  function showProblem(idx) {
    currentProblem = idx;
    const prob = problems[idx];
    
    problemText.textContent = prob.problem;
    standardResponse.innerHTML = `<div class="final-answer">${prob.standardAnswer}</div>`;
    
    reasoningResponse.innerHTML = `
      <div class="thinking-tokens">
        <div class="thinking-tokens-label">💭 Thinking tokens (in context)</div>
        <span style="white-space: pre-wrap;">${prob.thinking}</span>
      </div>
      <div class="final-answer">${prob.reasoningAnswer}</div>
    `;
    
    insightEl.innerHTML = prob.insight;

    [btn1, btn2, btn3].forEach((btn, i) => {
      if (btn) {
        btn.classList.toggle('primary', i === idx);
        btn.style.opacity = i === idx ? '1' : '0.7';
      }
    });
  }

  btn1.addEventListener('click', () => showProblem(0));
  btn2.addEventListener('click', () => showProblem(1));
  btn3.addEventListener('click', () => showProblem(2));

  showProblem(0);
}

// ============ INITIALIZATION ============
document.addEventListener('DOMContentLoaded', () => {
  // Disable automatic scroll restoration
  if ('scrollRestoration' in history) {
    history.scrollRestoration = 'manual';
  }

  // Force scroll to top on load
  const forceScrollTop = () => {
    window.scrollTo(0, 0);
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
    const mainContent = document.querySelector('.main-content');
    if (mainContent) mainContent.scrollTop = 0;
  };

  forceScrollTop();
  // Small delay to catch any late browser scroll adjustments
  setTimeout(forceScrollTop, 50);

  setupTabs();
  setupInference();
  setupNeuralNetwork();
  setupTokenizer();
  setupEmbeddings();
  setupAttention();
  setupTraining();
  setupTrainingLoop();
  setupRaterDemo();
  setupRealVectorDisplay();
  setupContextVisualizer();
  setupPromptComparison();
  setupThinkingDemo();
});

// ============ REAL VECTOR DISPLAY ============
function setupRealVectorDisplay() {
  const grid = document.getElementById('real-vector-grid');
  if (!grid) return;
  
  // Simulated embedding values (first 32 dimensions of a real-ish embedding)
  const embeddingValues = [
    0.23, -0.87, 1.45, -0.12, 0.67, -1.23, 0.89, -0.45,
    1.12, -0.34, 0.56, -0.78, 1.67, -0.23, 0.45, -1.56,
    0.12, -0.89, 1.34, -0.67, 0.78, -0.12, 0.34, -1.78,
    1.23, -0.56, 0.89, -0.34, 0.45, -1.12, 0.67, -0.23
  ];
  
  grid.innerHTML = '';
  
  embeddingValues.forEach((val, i) => {
    const cell = document.createElement('div');
    cell.className = 'vector-cell';
    cell.setAttribute('data-value', `dim ${i}: ${val.toFixed(2)}`);
    
    // Color based on value: negative = red, positive = blue
    const intensity = Math.min(1, Math.abs(val) / 2);
    if (val >= 0) {
      cell.style.background = THEME.rgba(THEME.colors.blue, 0.2 + intensity * 0.8);
    } else {
      cell.style.background = THEME.rgba(THEME.feedback.negative, 0.2 + intensity * 0.8);
    }
    
    grid.appendChild(cell);
  });
}
</script>
</body>
</html>
