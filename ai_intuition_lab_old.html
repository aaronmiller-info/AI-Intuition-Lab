<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Intuition Lab</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=DM+Sans:opsz,wght@9..40,400;9..40,500;9..40,600;9..40,700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-deep: #050508;
      --bg-panel: #0d0d14;
      --bg-card: #14141d;
      --bg-elevated: #1c1c28;
      --bg-well: #08080c;
      --accent-primary: #00d4aa;
      --accent-secondary: #7c3aed;
      --accent-warm: #f59e0b;
      --accent-cool: #3b82f6;
      --accent-pink: #ec4899;
      --text-primary: #f8fafc;
      --text-secondary: #94a3b8;
      --text-muted: #64748b;
      --border-subtle: rgba(148, 163, 184, 0.1);
      --border-accent: rgba(0, 212, 170, 0.3);
      --glow-accent: rgba(0, 212, 170, 0.2);
      --positive: #22c55e;
      --negative: #ef4444;
      --radius: 12px;
      --radius-sm: 6px;
      --shadow-crisp: 0 1px 3px rgba(0, 0, 0, 0.4);
    }

    /* Utilities */
    .mt-1 { margin-top: 1rem; }
    .mt-15 { margin-top: 1.5rem; }
    .mt-2 { margin-top: 2rem; }
    .mb-05 { margin-bottom: 0.5rem; }
    .mb-1 { margin-bottom: 1rem; }
    .mb-15 { margin-bottom: 1.5rem; }
    .mb-2 { margin-bottom: 2rem; }
    .mb-0 { margin-bottom: 0; }
    .p-075 { padding: 0.75rem; }
    .p-1 { padding: 1rem; }
    .p-125 { padding: 1.25rem; }
    .p-15 { padding: 1.5rem; }
    .flex { display: flex; }
    .flex-col { flex-direction: column; }
    .items-center { align-items: center; }
    .justify-center { justify-content: center; }
    .gap-05 { gap: 0.5rem; }
    .gap-075 { gap: 0.75rem; }
    .gap-1 { gap: 1rem; }
    .w-full { width: 100%; }
    .h-full { height: 100%; }
    .flex-1 { flex: 1; }
    .mono { font-family: 'JetBrains Mono', monospace; }
    .text-sm { font-size: 0.8rem; }
    .text-xs { font-size: 0.7rem; }
    .text-muted { color: var(--text-muted); }
    .text-secondary { color: var(--text-secondary); }
    .text-accent { color: var(--accent-primary); }
    .text-warm { color: var(--accent-warm); }
    .text-cool { color: var(--accent-cool); }
    .text-pink { color: var(--accent-pink); }
    .text-positive { color: var(--positive); }
    .text-negative { color: var(--negative); }
    .bold { font-weight: 700; }
    .uppercase { text-transform: uppercase; letter-spacing: 0.05em; }
    .h-900 { height: 900px; }
    .max-w-600 { max-width: 600px; }
    .mt-125 { margin-top: 1.25rem; }
    .mb-125 { margin-bottom: 1.25rem; }
    .overflow-y-auto { overflow-y: auto; }
    .hidden { display: none; }
    .card-sm { background: var(--bg-elevated); padding: 0.75rem; border-radius: var(--radius-sm); }
    .grid { display: grid; }
    .grid-2-col { grid-template-columns: 1fr 1fr; }
    .text-center { text-align: center; }
    .bg-dark { background: rgba(0,0,0,0.2); }
    .border-none { border: none; }
    .bg-transparent { background: transparent; }
    .border-collapse { border-collapse: collapse; }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    html {
      font-size: 18px;
    }

    body {
      font-family: 'DM Sans', system-ui, sans-serif;
      background: var(--bg-deep);
      color: var(--text-primary);
      min-height: 100vh;
      line-height: 1.5;
      overflow-x: hidden;
    }

    /* Ambient background */
    body::before {
      content: '';
      position: fixed;
      top: -50%;
      left: -50%;
      width: 200%;
      height: 200%;
      background: 
        radial-gradient(ellipse at 20% 20%, rgba(0, 212, 170, 0.03) 0%, transparent 50%),
        radial-gradient(ellipse at 80% 80%, rgba(124, 58, 237, 0.03) 0%, transparent 50%),
        radial-gradient(ellipse at 50% 50%, rgba(59, 130, 246, 0.02) 0%, transparent 70%);
      pointer-events: none;
      z-index: -1;
    }

    /* Layout: Sidebar + Content */
    .app-layout {
      display: flex;
      min-height: 100vh;
    }

    /* Sidebar */
    .sidebar {
      width: 220px;
      flex-shrink: 0;
      background: var(--bg-panel);
      border-right: 1px solid var(--border-subtle);
      position: sticky;
      top: 0;
      height: 100vh;
      overflow-y: auto;
      padding: 1.25rem 0;
    }

    .sidebar-header {
      padding: 0 1rem 1rem;
      border-bottom: 1px solid var(--border-subtle);
      margin-bottom: 0.75rem;
    }

    .sidebar-header h1 {
      font-size: 1.1rem;
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 0.2rem;
      background: linear-gradient(135deg, var(--text-primary) 0%, var(--accent-primary) 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }

    .sidebar-header p {
      font-size: 0.75rem;
      color: var(--text-muted);
      line-height: 1.4;
    }

    /* Navigation Tabs */
    .tab-nav {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
      padding: 0 0.5rem;
    }

    .tab-group {
      margin-bottom: 0.5rem;
    }

    .tab-group-label {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      font-size: 0.6rem;
      font-weight: 700;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      padding: 0.4rem 0.5rem 0.25rem;
    }

    .tab-group-label .group-num {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      width: 16px;
      height: 16px;
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-radius: 50%;
      font-size: 0.55rem;
      font-weight: 700;
    }

    .tab-group-buttons {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .tab-divider {
      display: none;
    }

    .tab-btn {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.5rem 0.6rem;
      background: rgba(255, 255, 255, 0.03);
      border: 1px solid transparent;
      border-radius: var(--radius-sm);
      color: var(--text-secondary);
      font-family: inherit;
      font-size: 0.75rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
      text-align: left;
      width: 100%;
    }

    .tab-btn:hover {
      background: rgba(255, 255, 255, 0.08);
      border-color: var(--border-subtle);
      color: var(--text-primary);
      transform: translateX(2px);
    }

    .tab-btn.active {
      background: var(--bg-elevated);
      color: var(--accent-primary);
      border-color: var(--border-accent);
      box-shadow: var(--shadow-crisp);
    }

    .tab-btn .icon {
      font-size: 0.9rem;
      width: 1.1rem;
      text-align: center;
      opacity: 0.7;
    }

    .tab-btn.active .icon {
      opacity: 1;
    }

    /* Main Content */
    .main-content {
      flex: 1;
      padding: 1.5rem 2.5rem;
      width: 100%;
      min-width: 0;
      overflow-y: auto;
    }

    /* Sidebar scrollbar */
    .sidebar::-webkit-scrollbar {
      width: 4px;
    }

    .sidebar::-webkit-scrollbar-track {
      background: transparent;
    }

    .sidebar::-webkit-scrollbar-thumb {
      background: var(--border-subtle);
      border-radius: 2px;
    }

    /* Responsive: Collapse sidebar on small screens */
    @media (max-width: 900px) {
      .app-layout {
        flex-direction: column;
      }
      
      .sidebar {
        width: 100%;
        height: auto;
        position: relative;
        border-right: none;
        border-bottom: 1px solid var(--border-subtle);
        padding: 0.75rem 0;
      }
      
      .sidebar-header {
        display: flex;
        align-items: center;
        gap: 1rem;
        padding: 0 1rem 0.75rem;
      }
      
      .sidebar-header p {
        display: none;
      }
      
      .tab-nav {
        flex-direction: row;
        flex-wrap: wrap;
        gap: 0.25rem;
        padding: 0 0.75rem;
        justify-content: center;
      }
      
      .tab-group {
        display: flex;
        align-items: center;
        gap: 0.25rem;
        margin-bottom: 0;
      }
      
      .tab-group-label {
        padding: 0.2rem 0.3rem;
      }
      
      .tab-group-buttons {
        flex-direction: row;
        gap: 0.25rem;
      }
      
      .tab-btn {
        padding: 0.35rem 0.5rem;
        font-size: 0.7rem;
      }
      
      .tab-btn span:not(.icon) {
        display: none;
      }
      
      .tab-btn .icon {
        margin: 0;
      }
      
      .tab-btn.active {
        box-shadow: 0 0 8px rgba(0, 212, 170, 0.3);
      }
      
      .main-content {
        padding: 1rem;
      }
    }

    /* Tab Sections */
    .tab-section {
      display: none;
      animation: fadeIn 0.4s ease;
    }

    .tab-section.active {
      display: block;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* Section Header */
    .section-header {
      text-align: center;
      margin-bottom: 2rem;
    }

    .section-header h2 {
      font-size: 2.2rem;
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 0.5rem;
    }

    .section-header p {
      font-size: 1.15rem;
      color: var(--text-secondary);
      max-width: 800px;
      margin: 0 auto;
    }

    /* Sub-panel for controls inside a workbench */
    .control-panel-well {
      background: rgba(0, 0, 0, 0.25);
      border-radius: var(--radius-sm);
      padding: 1.25rem;
      margin: 0;
      border: 1px solid var(--border-subtle);
    }

    /* Cards */
    .card {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
      box-shadow: var(--shadow-crisp);
    }

    /* Interactive Well */
    .interactive-well {
      background: var(--bg-well);
      border: 1px solid var(--border-subtle);
      border-left: 4px solid var(--accent-primary);
      border-radius: var(--radius-sm);
      padding: 1.5rem;
      margin: 1.5rem 0;
      box-shadow: inset 0 2px 8px rgba(0,0,0,0.5);
      position: relative;
    }

    .interactive-well::before {
      content: 'DEMO / WORKBENCH';
      position: absolute;
      top: -10px;
      left: 1rem;
      background: var(--accent-primary);
      color: var(--bg-deep);
      font-size: 0.6rem;
      font-weight: 800;
      padding: 2px 8px;
      border-radius: 4px;
      letter-spacing: 0.05em;
    }

    /* Informational Cards */
    .concept-card {
      background: rgba(124, 58, 237, 0.03);
      border: 1px solid rgba(124, 58, 237, 0.1);
      border-radius: var(--radius-sm);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .concept-card h4 {
      color: var(--accent-secondary);
      font-size: 1rem;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .concept-card h4::before {
      content: 'ðŸ“–';
      font-size: 0.9rem;
    }

    .card-header h3 {
      font-size: 1.3rem;
      font-weight: 600;
    }

    .card-header .badge {
      padding: 0.35rem 0.75rem;
      background: var(--bg-elevated);
      border-radius: 100px;
      font-size: 0.85rem;
      color: var(--accent-primary);
      font-weight: 500;
    }

    /* Layout helpers */
    .grid-2 {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
    }

    .grid-3 {
      display: grid;
      grid-template-columns: 1fr 1fr 1fr;
      gap: 1.5rem;
    }

    @media (max-width: 1200px) {
      .grid-2, .grid-3 {
        grid-template-columns: 1fr;
      }
    }

    /* Neural Network Intro */
    .nn-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .nn-intro-flow {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 1rem;
      flex-wrap: wrap;
      margin-bottom: 1rem;
    }

    .nn-intro-box {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem 1rem;
      text-align: center;
      min-width: 160px;
    }

    .nn-intro-box.input-box {
      border: 1px solid var(--accent-cool);
    }

    .nn-intro-box.network-box {
      border: 1px solid var(--accent-secondary);
      background: linear-gradient(135deg, rgba(124, 58, 237, 0.1), rgba(124, 58, 237, 0.05));
    }

    .nn-intro-box.output-box {
      border: 1px solid var(--accent-primary);
    }

    .intro-box-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.25rem;
    }

    .intro-box-content {
      font-size: 0.85rem;
      color: var(--text-primary);
    }

    .intro-box-content strong {
      display: block;
      margin-bottom: 0.15rem;
    }

    .intro-example {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .nn-intro-arrow {
      font-size: 1.25rem;
      color: var(--text-muted);
    }

    .nn-intro-note {
      font-size: 0.85rem;
      color: var(--text-secondary);
      text-align: center;
      margin: 0;
    }

    /* Neural Network Visualization Canvas */
    .nn-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    .nn-canvas-wrapper {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      border: 1px solid var(--border-subtle);
    }

    .controls-note {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 1rem;
    }

    .nn-output-display {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
    }

    .nn-output-display .output-row {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      padding: 0.3rem 0;
    }

    .nn-output-display .output-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      min-width: 50px;
    }

    .output-bar-container {
      flex: 1;
      height: 6px;
      background: var(--bg-elevated);
      border-radius: 3px;
      overflow: hidden;
    }

    .output-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 3px;
      transition: width 0.2s ease;
      width: 0%;
    }

    .nn-output-display .output-value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      min-width: 35px;
      text-align: right;
    }

    .nn-try-this {
      margin-top: 0.75rem;
      padding: 0.5rem 0.6rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.75rem;
      color: var(--text-secondary);
      border-left: 3px solid var(--accent-primary);
      line-height: 1.4;
    }

    .nn-try-this strong {
      color: var(--accent-primary);
    }

    .legend-circle {
      width: 16px;
      height: 16px;
      border-radius: 50%;
      background: var(--accent-primary);
      box-shadow: 0 0 8px var(--accent-primary);
    }

    .legend-circle.active {
      background: var(--accent-primary);
    }

    #nn-canvas {
      width: 100%;
      height: 380px;
      display: block;
    }

    .nn-legend {
      display: flex;
      justify-content: center;
      gap: 2rem;
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid var(--border-subtle);
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.95rem;
      color: var(--text-secondary);
    }

    .legend-line {
      width: 30px;
      height: 4px;
      border-radius: 2px;
    }

    .legend-line.positive { background: var(--positive); }
    .legend-line.negative { background: var(--negative); }
    .legend-line.thick { height: 8px; }
    .legend-line.thin { height: 2px; }

    /* Controls Panel */
    .controls-panel {
      background: var(--bg-panel);
      border-radius: var(--radius);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .controls-panel h3 {
      font-size: 1rem;
      font-weight: 600;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .control-group {
      margin-bottom: 1rem;
    }

    .control-group:last-child {
      margin-bottom: 0;
    }

    .control-group-title {
      font-size: 0.75rem;
      font-weight: 600;
      color: var(--accent-primary);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.5rem;
    }

    .slider-row {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .slider-row label {
      flex: 0 0 60px;
      font-size: 0.85rem;
      color: var(--text-secondary);
      font-weight: 500;
    }

    .slider-row input[type="range"] {
      flex: 1;
      height: 6px;
      -webkit-appearance: none;
      appearance: none;
      background: var(--bg-elevated);
      border-radius: 4px;
      outline: none;
      min-width: 80px;
    }

    .slider-row input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 16px;
      height: 16px;
      background: var(--accent-primary);
      border-radius: 50%;
      cursor: pointer;
      box-shadow: 0 0 8px var(--glow-accent);
    }

    .slider-value {
      flex: 0 0 45px;
      text-align: right;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      font-weight: 600;
      color: var(--text-primary);
      background: var(--bg-elevated);
      padding: 0.35rem 0.6rem;
      border-radius: var(--radius-sm);
    }

    /* Output Display */
    .output-display {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-top: 1.5rem;
      border: 2px solid var(--border-accent);
    }

    .output-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0.75rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .output-row:last-child {
      border-bottom: none;
      padding-bottom: 0;
    }

    .output-row:first-child {
      padding-top: 0;
    }

    .output-label {
      font-size: 1rem;
      color: var(--text-secondary);
    }

    .output-value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.3rem;
      font-weight: 600;
    }

    .output-value.highlight {
      color: var(--accent-primary);
      font-size: 1.6rem;
    }

    /* Tokenizer Section */
    .tokenizer-container {
      width: 100%;
      margin: 0;
    }

    .input-area {
      margin-bottom: 1.5rem;
    }

    .input-area textarea {
      width: 100%;
      min-height: 120px;
      padding: 1.25rem;
      font-family: inherit;
      font-size: 1.2rem;
      background: var(--bg-card);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius);
      color: var(--text-primary);
      resize: vertical;
      transition: border-color 0.2s ease;
    }

    .input-area textarea:focus {
      outline: none;
      border-color: var(--accent-primary);
    }

    .input-area textarea::placeholder {
      color: var(--text-muted);
    }

    .action-btn {
      display: inline-flex;
      align-items: center;
      gap: 0.6rem;
      padding: 0.8rem 1.6rem;
      background: var(--accent-primary);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 700;
      cursor: pointer;
      transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
      border-bottom: 3px solid rgba(0, 0, 0, 0.2);
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .action-btn:hover {
      transform: translateY(-2px);
      filter: brightness(1.1);
      box-shadow: 0 4px 12px rgba(0, 212, 170, 0.2);
    }

    .action-btn:active {
      transform: translateY(1px);
      border-bottom-width: 1px;
    }

    /* Slider refinement */
    .slider-row input[type="range"] {
      flex: 1;
      height: 4px;
      -webkit-appearance: none;
      appearance: none;
      background: var(--bg-deep);
      border-radius: 2px;
      outline: none;
      min-width: 80px;
    }

    .slider-row input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 18px;
      height: 18px;
      background: var(--accent-primary);
      border: 2px solid var(--bg-panel);
      border-radius: 50%;
      cursor: pointer;
      transition: transform 0.1s ease;
    }

    .slider-row input[type="range"]:hover::-webkit-slider-thumb {
      transform: scale(1.1);
    }

    /* Canvas refinement */
    canvas {
      background-image: 
        linear-gradient(rgba(255, 255, 255, 0.02) 1px, transparent 1px),
        linear-gradient(90deg, rgba(255, 255, 255, 0.02) 1px, transparent 1px);
      background-size: 20px 20px;
      border: 1px solid var(--border-subtle) !important;
    }

    .tokens-display {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 2rem;
      margin-top: 1.5rem;
      border: 1px solid var(--border-subtle);
    }

    .tokens-display h4 {
      font-size: 1.1rem;
      color: var(--text-secondary);
      margin-bottom: 1rem;
      font-weight: 500;
    }

    .tokens-grid {
      display: flex;
      flex-wrap: wrap;
      gap: 0.75rem;
    }

    .token-chip {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.4rem 0.8rem;
      background: var(--bg-deep);
      border: 1px solid var(--border-subtle);
      border-left: 3px solid var(--accent-secondary);
      border-radius: var(--radius-sm);
      font-size: 1rem;
      transition: all 0.2s ease;
    }

    .token-chip:hover {
      border-color: var(--accent-secondary);
      background: var(--bg-elevated);
    }

    .token-chip .index {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      color: var(--accent-primary);
      font-weight: 600;
    }

    .token-chip .text {
      color: var(--text-primary);
      font-weight: 500;
    }

    .ids-display {
      margin-top: 1.5rem;
      padding: 1.25rem;
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      font-family: 'JetBrains Mono', monospace;
      font-size: 1rem;
      color: var(--text-secondary);
      line-height: 1.8;
      overflow-x: auto;
    }

    /* Embeddings Section */
    .embeddings-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    #embedding-canvas {
      width: 100%;
      height: 450px;
      background: var(--bg-card);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
      cursor: crosshair;
    }

    .word-selector {
      margin-bottom: 1.5rem;
    }

    .word-selector label {
      display: block;
      font-size: 1rem;
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    .word-selector select {
      width: 100%;
      padding: 1rem;
      font-family: inherit;
      font-size: 1.1rem;
      background: var(--bg-card);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      cursor: pointer;
    }

    .word-selector select:focus {
      outline: none;
      border-color: var(--accent-primary);
    }

    .similarity-table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 1rem;
    }

    .similarity-table th,
    .similarity-table td {
      padding: 0.9rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border-subtle);
    }

    .similarity-table th {
      font-size: 0.9rem;
      font-weight: 600;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .similarity-table td {
      font-size: 1.05rem;
    }

    .similarity-table td:first-child {
      font-weight: 600;
      color: var(--text-primary);
    }

    .similarity-table td:last-child {
      font-family: 'JetBrains Mono', monospace;
      text-align: right;
    }

    .sim-bar {
      display: inline-block;
      height: 8px;
      border-radius: 4px;
      margin-right: 0.75rem;
      vertical-align: middle;
    }

    /* Attention Section */
    .attention-container {
      width: 100%;
      margin-bottom: 2rem;
    }

    #attention-canvas {
      width: 100%;
      height: 400px;
      background: var(--bg-card);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .attention-weights {
      margin-top: 1.5rem;
    }

    .attention-row {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      margin-bottom: 0.75rem;
    }

    .attention-row .word {
      flex: 0 0 100px;
      font-weight: 600;
      font-size: 1.1rem;
    }

    .attention-row .bar-container {
      flex: 1;
      height: 24px;
      background: var(--bg-elevated);
      border-radius: 12px;
      overflow: hidden;
    }

    .attention-row .bar {
      height: 100%;
      border-radius: 12px;
      transition: width 0.4s ease;
    }

    .attention-row .value {
      flex: 0 0 60px;
      text-align: right;
      font-family: 'JetBrains Mono', monospace;
      font-size: 1rem;
      font-weight: 600;
    }

    /* Pre-Training Section */
    .pretrain-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .pretrain-mindblown {
      display: flex;
      gap: 1.25rem;
      align-items: flex-start;
      margin-bottom: 1.5rem;
    }

    .mindblown-icon {
      font-size: 2.5rem;
      flex-shrink: 0;
    }

    .mindblown-content h4 {
      margin: 0 0 0.5rem 0;
      color: var(--accent-primary);
      font-size: 1.1rem;
    }

    .mindblown-content p {
      margin: 0 0 0.75rem 0;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    .mindblown-content p:last-child {
      margin-bottom: 0;
    }

    .pretrain-timeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 1rem;
      flex-wrap: wrap;
    }

    .timeline-stage {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem 1rem;
      text-align: center;
      min-width: 120px;
    }

    .timeline-stage.highlight {
      border-color: var(--accent-primary);
      background: rgba(0, 212, 170, 0.1);
    }

    .timeline-stage .stage-icon {
      font-size: 1.5rem;
      margin-bottom: 0.25rem;
    }

    .timeline-stage .stage-label {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.1rem;
    }

    .timeline-stage .stage-desc {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .timeline-arrow {
      font-size: 1.25rem;
      color: var(--text-muted);
    }

    /* Training Data Section */
    .training-data-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .training-data-section h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .training-data-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .training-examples {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .training-example {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem 1rem;
      border-left: 3px solid var(--accent-cool);
    }

    .example-source {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .example-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
    }

    .masked-word {
      background: var(--accent-primary);
      color: var(--bg-deep);
      padding: 0.1rem 0.4rem;
      border-radius: 4px;
      font-weight: 600;
    }

    .data-scale-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--text-secondary);
    }

    /* Training Loop Section */
    .training-loop-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .training-loop-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .training-loop-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .training-loop-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .loop-step-container {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-bottom: 1rem;
    }

    .loop-example-card,
    .loop-predictions-card,
    .loop-loss-card,
    .loop-adjust-card {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .loop-step-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.5rem;
    }

    .loop-prompt {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .prompt-blank {
      background: var(--accent-warm);
      color: var(--bg-deep);
      padding: 0.1rem 0.5rem;
      border-radius: 4px;
    }

    .loop-answer {
      display: flex;
      flex-direction: column;
      gap: 0.1rem;
    }

    .answer-label {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .answer-token {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-weight: 600;
    }

    .prediction-bars {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
    }

    .pred-row {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.75rem;
    }

    .pred-token {
      font-family: 'JetBrains Mono', monospace;
      width: 55px;
      flex-shrink: 0;
    }

    .pred-token.correct-highlight {
      color: var(--accent-primary);
    }

    .pred-bar-container {
      flex: 1;
      height: 8px;
      background: var(--bg-card);
      border-radius: 4px;
      overflow: hidden;
    }

    .pred-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 4px;
      transition: width 0.3s ease;
    }

    .pred-prob {
      font-family: 'JetBrains Mono', monospace;
      width: 35px;
      text-align: right;
    }

    .pred-feedback {
      font-size: 0.65rem;
      color: var(--accent-warm);
      width: 60px;
    }

    .loss-display {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .loss-formula {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .loss-value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--accent-warm);
    }

    .loss-interpretation {
      font-size: 0.7rem;
      color: var(--text-muted);
      width: 100%;
    }

    .adjust-explanation {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .adjust-explanation p {
      margin: 0 0 0.25rem 0;
    }

    .adjust-visual {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
      margin-top: 0.5rem;
    }

    .weight-change {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.65rem;
      color: var(--accent-primary);
    }

    .loop-controls {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
    }

    .train-loop-btn {
      padding: 0.5rem 1rem;
      background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .train-loop-btn:hover {
      transform: translateY(-1px);
    }

    .train-loop-btn.auto {
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      color: var(--text-primary);
    }

    .train-loop-btn.auto.active {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .train-loop-btn.reset {
      background: transparent;
      border: 1px solid var(--text-muted);
      color: var(--text-secondary);
    }

    .loop-stats {
      margin-left: auto;
      font-size: 0.8rem;
      color: var(--text-secondary);
      display: flex;
      gap: 1rem;
    }

    .loop-stats strong {
      color: var(--accent-primary);
      font-family: 'JetBrains Mono', monospace;
    }

    /* Mini Training Demo (in deep dive) */
    .mini-training-demo {
      display: grid;
      grid-template-columns: 1.5fr 1fr;
      gap: 1rem;
      margin: 1rem 0;
    }

    @media (max-width: 700px) {
      .mini-training-demo {
        grid-template-columns: 1fr;
      }
    }

    .mini-canvas-container {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
      overflow: hidden;
    }

    #training-canvas {
      width: 100%;
      height: 200px;
      display: block;
    }

    .mini-training-controls {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .mini-metrics {
      display: flex;
      gap: 0.5rem;
    }

    .mini-metric {
      flex: 1;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      text-align: center;
    }

    .mini-metric .label {
      font-size: 0.65rem;
      color: var(--text-muted);
      display: block;
    }

    .mini-metric .value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
      font-weight: 600;
      color: var(--accent-primary);
    }

    .mini-metric.loss .value {
      color: var(--accent-warm);
    }

    .mini-buttons {
      display: flex;
      gap: 0.5rem;
    }

    .mini-btn {
      flex: 1;
      padding: 0.4rem 0.5rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.75rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .mini-btn:hover {
      border-color: var(--accent-primary);
    }

    .mini-btn.active {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .mini-epoch {
      font-size: 0.75rem;
      color: var(--text-secondary);
      text-align: center;
    }

    .mini-demo-note {
      font-size: 0.8rem;
      color: var(--text-muted);
      text-align: center;
      margin-top: 0.5rem;
    }

    /* Deep Dive: What Emerges */
    .emerges-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 0.75rem;
      margin: 1rem 0;
    }

    @media (max-width: 600px) {
      .emerges-grid {
        grid-template-columns: 1fr;
      }
    }

    .emerges-item {
      display: flex;
      gap: 0.75rem;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .emerges-icon {
      font-size: 1.25rem;
      flex-shrink: 0;
    }

    .emerges-item strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.2rem;
    }

    .emerges-item p {
      font-size: 0.75rem;
      color: var(--text-secondary);
      margin: 0;
    }

    .emerges-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Backpropagation Section */
    .backprop-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .backprop-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .backprop-section > p {
      color: var(--text-secondary);
      margin-bottom: 1.25rem;
    }

    .backprop-visual {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .backprop-network {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 1rem;
    }

    .backprop-stage {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .stage-title {
      font-weight: 600;
      font-size: 0.85rem;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .stage-desc {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
    }

    .network-mini {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.25rem;
      padding: 0.5rem 0;
    }

    .layer-col {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      align-items: center;
    }

    .connection-col {
      width: 40px;
      height: 60px;
    }

    .conn-svg {
      width: 100%;
      height: 100%;
    }

    .mini-node {
      width: 28px;
      height: 28px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.55rem;
      font-family: 'JetBrains Mono', monospace;
      position: relative;
    }

    .mini-node.input-node {
      background: rgba(59, 130, 246, 0.3);
      border: 2px solid #3b82f6;
    }

    .mini-node.hidden-node {
      background: rgba(107, 114, 128, 0.3);
      border: 2px solid #6b7280;
    }

    .mini-node.output-node {
      background: rgba(0, 212, 170, 0.3);
      border: 2px solid #00d4aa;
    }

    .mini-node .node-label {
      color: var(--text-primary);
      font-weight: 500;
    }

    .mini-node.blamed {
      box-shadow: 0 0 8px rgba(245, 158, 11, 0.5);
    }

    .mini-node .blame-amount {
      position: absolute;
      top: -16px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 0.55rem;
      color: #f59e0b;
      white-space: nowrap;
    }

    .stage-result {
      font-size: 0.7rem;
      color: var(--text-secondary);
      text-align: center;
      margin-top: 0.5rem;
      padding-top: 0.5rem;
      border-top: 1px solid var(--border-subtle);
    }

    .loss-calc-visual {
      display: flex;
      flex-direction: column;
      gap: 0.4rem;
      padding: 0.5rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .loss-target,
    .loss-actual {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .loss-result {
      font-size: 0.8rem;
      color: var(--accent-warm);
      padding-top: 0.4rem;
      border-top: 1px dashed var(--border-subtle);
    }

    .weight-updates {
      display: flex;
      flex-direction: column;
      gap: 0.3rem;
    }

    .weight-update-row {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.65rem;
      padding: 0.25rem 0.4rem;
      background: var(--bg-card);
      border-radius: 4px;
    }

    .weight-update-row.ellipsis {
      justify-content: center;
      color: var(--text-muted);
      font-style: italic;
    }

    .weight-name {
      color: var(--text-secondary);
      flex: 1;
    }

    .weight-old {
      color: var(--text-muted);
    }

    .weight-arrow {
      color: var(--accent-primary);
    }

    .weight-new {
      color: var(--accent-primary);
    }

    .backprop-key-insight {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--text-secondary);
      border-left: 3px solid var(--accent-warm);
    }

    .backprop-key-insight strong {
      color: var(--accent-warm);
    }

    /* Math Intuition */
    .math-intuition {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin: 1rem 0;
    }

    .math-block {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .math-question {
      font-size: 0.85rem;
      color: var(--text-primary);
      font-weight: 500;
    }

    .math-answer {
      font-size: 0.8rem;
      color: var(--text-secondary);
      padding-left: 1rem;
      border-left: 2px solid var(--accent-primary);
    }

    /* Training Changes Visual */
    .training-changes {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .change-item {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
    }

    .change-before,
    .change-after {
      flex: 1;
      min-width: 150px;
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
    }

    .change-before {
      background: rgba(239, 68, 68, 0.1);
      border: 1px solid rgba(239, 68, 68, 0.3);
    }

    .change-after {
      background: rgba(0, 212, 170, 0.1);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .change-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      text-transform: uppercase;
      display: block;
    }

    .change-desc {
      font-size: 0.8rem;
    }

    .change-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Does/Doesn't Section */
    .does-doesnt {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin: 1rem 0;
    }

    @media (max-width: 600px) {
      .does-doesnt {
        grid-template-columns: 1fr;
      }
    }

    .does,
    .doesnt {
      padding: 0.75rem;
      border-radius: var(--radius-sm);
    }

    .does {
      background: rgba(0, 212, 170, 0.1);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .doesnt {
      background: rgba(239, 68, 68, 0.1);
      border: 1px solid rgba(239, 68, 68, 0.3);
    }

    .does-header,
    .doesnt-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .does-header {
      color: var(--accent-primary);
    }

    .doesnt-header {
      color: var(--negative);
    }

    .does ul,
    .doesnt ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.8rem;
    }

    .does li,
    .doesnt li {
      margin-bottom: 0.25rem;
    }

    /* Fine-Tuning Section */
    .ft-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-gap-visual {
      display: flex;
      align-items: stretch;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }

    .gap-side {
      flex: 1;
      min-width: 200px;
      max-width: 280px;
      padding: 1rem;
      border-radius: var(--radius);
      text-align: center;
    }

    .gap-side.pretrained {
      background: rgba(107, 114, 128, 0.15);
      border: 1px solid rgba(107, 114, 128, 0.3);
    }

    .gap-side.finetuned {
      background: rgba(0, 212, 170, 0.1);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .gap-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
    }

    .gap-icon {
      font-size: 2rem;
      margin-bottom: 0.5rem;
    }

    .gap-desc {
      font-size: 0.8rem;
      color: var(--text-secondary);
      margin-bottom: 0.75rem;
    }

    .gap-list {
      list-style: none;
      padding: 0;
      margin: 0;
      text-align: left;
      font-size: 0.75rem;
    }

    .gap-list li {
      padding: 0.25rem 0;
      padding-left: 1.25rem;
      position: relative;
    }

    .gap-side.pretrained .gap-list li::before {
      content: 'â—‹';
      position: absolute;
      left: 0;
      color: var(--text-muted);
    }

    .gap-side.finetuned .gap-list li::before {
      content: 'â—';
      position: absolute;
      left: 0;
      color: var(--accent-primary);
    }

    .gap-arrow {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 0 0.5rem;
    }

    .gap-arrow span {
      font-size: 0.7rem;
      color: var(--accent-primary);
      font-weight: 600;
      margin-bottom: 0.25rem;
    }

    .arrow-line {
      width: 60px;
      height: 3px;
      background: var(--accent-primary);
      position: relative;
    }

    .arrow-line::after {
      content: '';
      position: absolute;
      right: -4px;
      top: -4px;
      border: 5px solid transparent;
      border-left-color: var(--accent-primary);
    }

    /* Before/After Example */
    .ft-example-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-example-section h3 {
      margin: 0 0 1rem 0;
      font-size: 1.1rem;
    }

    .ft-example-container {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .ft-prompt {
      background: var(--bg-card);
      padding: 0.75rem 1rem;
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-cool);
    }

    .prompt-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .prompt-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
    }

    .ft-responses {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1rem;
    }

    .ft-response {
      padding: 1rem;
      border-radius: var(--radius-sm);
    }

    .ft-response.before {
      background: rgba(239, 68, 68, 0.08);
      border: 1px solid rgba(239, 68, 68, 0.2);
    }

    .ft-response.after {
      background: rgba(0, 212, 170, 0.08);
      border: 1px solid rgba(0, 212, 170, 0.2);
    }

    .response-header {
      margin-bottom: 0.5rem;
    }

    .response-badge {
      display: inline-block;
      padding: 0.2rem 0.5rem;
      border-radius: 4px;
      font-size: 0.7rem;
      font-weight: 600;
    }

    .response-badge.bad {
      background: rgba(239, 68, 68, 0.2);
      color: #ef4444;
    }

    .response-badge.good {
      background: rgba(0, 212, 170, 0.2);
      color: #00d4aa;
    }

    .response-text {
      font-size: 0.85rem;
      line-height: 1.5;
      margin-bottom: 0.5rem;
    }

    .response-note {
      font-size: 0.7rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* What Fine-Tuning Teaches */
    .ft-teaches-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .ft-teaches-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .ft-teaches-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .teaches-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 0.75rem;
    }

    @media (max-width: 1000px) {
      .teaches-grid {
        grid-template-columns: repeat(2, 1fr);
      }
    }

    @media (max-width: 600px) {
      .teaches-grid {
        grid-template-columns: 1fr;
      }
    }

    .teaches-card {
      display: flex;
      gap: 0.75rem;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
    }

    .teaches-icon {
      font-size: 1.5rem;
      flex-shrink: 0;
    }

    .teaches-content h4 {
      margin: 0 0 0.25rem 0;
      font-size: 0.85rem;
    }

    .teaches-content p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* RLHF Section */
    .rlhf-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .rlhf-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .rlhf-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .rlhf-loop {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 1rem;
    }

    .rlhf-step {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .rlhf-step .step-number {
      width: 28px;
      height: 28px;
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.9rem;
      margin-bottom: 0.5rem;
    }

    .rlhf-step .step-content h4 {
      margin: 0 0 0.25rem 0;
      font-size: 0.9rem;
    }

    .rlhf-step .step-content > p {
      margin: 0 0 0.5rem 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .step-example {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      font-size: 0.7rem;
    }

    .example-prompt {
      font-family: 'JetBrains Mono', monospace;
      color: var(--text-primary);
      margin-bottom: 0.4rem;
    }

    .example-responses {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .resp-a, .resp-b {
      padding: 0.25rem 0.4rem;
      border-radius: 4px;
    }

    .resp-a {
      background: rgba(239, 68, 68, 0.1);
      color: var(--text-secondary);
    }

    .resp-b {
      background: rgba(0, 212, 170, 0.1);
      color: var(--text-secondary);
    }

    .human-choice {
      display: flex;
      gap: 0.5rem;
      align-items: center;
    }

    .choice-label {
      color: var(--text-muted);
    }

    .choice-winner {
      color: var(--accent-primary);
      font-weight: 600;
    }

    .choice-reason {
      color: var(--text-muted);
      font-style: italic;
      margin-top: 0.25rem;
    }

    .reward-model {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .reward-insight {
      color: var(--accent-primary);
      font-style: italic;
    }

    .weight-update-note {
      color: var(--text-muted);
      font-style: italic;
    }

    .rlhf-repeat {
      text-align: center;
      margin-top: 1rem;
      padding: 0.5rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      color: var(--accent-primary);
    }

    /* Rater Demo */
    .rater-demo-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .rater-demo-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .rater-demo-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .rater-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .rater-prompt {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      margin-bottom: 1rem;
    }

    .rater-prompt-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .rater-prompt-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
    }

    .rater-choices {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1rem;
      margin-bottom: 1rem;
    }

    .rater-choice {
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      cursor: pointer;
      transition: all 0.2s ease;
      text-align: left;
      font-family: inherit;
    }

    .rater-choice:hover {
      border-color: var(--accent-primary);
    }

    .rater-choice.selected {
      border-color: var(--accent-primary);
      background: rgba(0, 212, 170, 0.1);
    }

    .rater-choice.not-selected {
      opacity: 0.5;
    }

    .choice-header {
      font-weight: 600;
      font-size: 0.85rem;
      margin-bottom: 0.5rem;
      color: var(--text-primary);
    }

    .choice-text {
      font-size: 0.8rem;
      color: var(--text-secondary);
      line-height: 1.5;
    }

    .rater-feedback {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin-bottom: 1rem;
      min-height: 60px;
      font-size: 0.85rem;
    }

    .rater-feedback.show {
      border-left: 3px solid var(--accent-primary);
    }

    .rater-stats {
      display: flex;
      align-items: center;
      justify-content: space-between;
      font-size: 0.85rem;
    }

    .rater-next-btn {
      padding: 0.5rem 1rem;
      background: var(--accent-primary);
      border: none;
      border-radius: var(--radius-sm);
      color: var(--bg-deep);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .rater-next-btn:hover {
      transform: translateY(-1px);
    }

    .rater-next-btn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
      transform: none;
    }

    /* Deep Dive: Training Stages */
    .training-stages {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin: 1rem 0;
    }

    .stage-block {
      display: flex;
      gap: 0.5rem;
      padding: 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
      min-width: 160px;
    }

    .stage-num {
      width: 24px;
      height: 24px;
      background: var(--accent-secondary);
      color: white;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.8rem;
      flex-shrink: 0;
    }

    .stage-info h5 {
      margin: 0 0 0.2rem 0;
      font-size: 0.8rem;
    }

    .stage-info p {
      margin: 0;
      font-size: 0.7rem;
      color: var(--text-secondary);
    }

    .stage-data {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-top: 0.25rem;
    }

    .stage-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Approaches Grid */
    .approaches-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .approach-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 1px solid var(--border-subtle);
    }

    .approach-name {
      font-family: 'JetBrains Mono', monospace;
      font-weight: 700;
      color: var(--accent-primary);
      font-size: 0.9rem;
    }

    .approach-full {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.4rem;
    }

    .approach-desc {
      font-size: 0.75rem;
      color: var(--text-secondary);
      margin-bottom: 0.4rem;
    }

    .approach-used {
      font-size: 0.65rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* Reward Model Visual */
    .reward-model-visual {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin: 1rem 0;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .rm-input, .rm-model, .rm-output {
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
      text-align: center;
    }

    .rm-input {
      background: rgba(59, 130, 246, 0.15);
      border: 1px solid rgba(59, 130, 246, 0.3);
    }

    .rm-model {
      background: rgba(168, 85, 247, 0.15);
      border: 1px solid rgba(168, 85, 247, 0.3);
    }

    .rm-output {
      background: rgba(0, 212, 170, 0.15);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .rm-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.2rem;
    }

    .rm-content {
      font-size: 0.8rem;
      font-weight: 500;
    }

    .rm-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Challenges List */
    .challenges-list {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      margin: 1rem 0;
    }

    .challenge-item {
      padding: 0.5rem 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-warm);
    }

    .challenge-item strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.2rem;
    }

    .challenge-item p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Tradeoff Visual */
    .tradeoff-visual {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      margin: 1rem 0;
    }

    .tradeoff-item {
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }

    .tradeoff-label {
      width: 100px;
      font-size: 0.75rem;
      flex-shrink: 0;
    }

    .tradeoff-bar {
      flex: 1;
      height: 12px;
      background: var(--bg-card);
      border-radius: 6px;
      overflow: hidden;
    }

    .bar-fill {
      height: 100%;
      border-radius: 6px;
    }

    .bar-fill.pretrain {
      background: var(--text-muted);
    }

    .bar-fill.finetune {
      background: var(--accent-secondary);
    }

    .bar-fill.helpful {
      background: var(--accent-primary);
    }

    .bar-fill.safe {
      background: var(--accent-cool);
    }

    .tradeoff-note {
      font-size: 0.65rem;
      color: var(--text-muted);
      width: 150px;
    }

    /* Complete Pipeline */
    .complete-pipeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.25rem;
      flex-wrap: wrap;
      margin: 1rem 0;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .pipeline-stage {
      text-align: center;
      padding: 0.5rem;
      min-width: 70px;
    }

    .pipeline-stage.highlight {
      background: rgba(0, 212, 170, 0.15);
      border-radius: var(--radius-sm);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .pipe-icon {
      font-size: 1.25rem;
      margin-bottom: 0.25rem;
    }

    .pipe-name {
      font-size: 0.7rem;
      font-weight: 600;
      margin-bottom: 0.1rem;
    }

    .pipe-desc {
      font-size: 0.6rem;
      color: var(--text-muted);
    }

    .pipe-arrow {
      color: var(--text-muted);
      font-size: 0.9rem;
    }

    /* Legacy Training Section (keeping for reference) */
    .training-container {
      display: grid;
      grid-template-columns: 1.2fr 1fr;
      gap: 2rem;
    }

    @media (max-width: 1000px) {
      .training-container {
        grid-template-columns: 1fr;
      }
    }

    .training-controls {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .metric-card {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem 1.5rem;
      border: 1px solid var(--border-subtle);
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .metric-card .label {
      font-size: 1rem;
      color: var(--text-secondary);
    }

    .metric-card .value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.5rem;
      font-weight: 600;
      color: var(--accent-primary);
    }

    .metric-card.loss .value {
      color: var(--accent-warm);
    }

    .step-btn {
      padding: 1.25rem 2rem;
      background: linear-gradient(135deg, var(--accent-warm) 0%, var(--accent-pink) 100%);
      border: none;
      border-radius: var(--radius);
      color: white;
      font-family: inherit;
      font-size: 1.2rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
      margin-top: 0.5rem;
    }

    .step-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 10px 30px rgba(245, 158, 11, 0.3);
    }

    .auto-train-btn {
      padding: 1rem 1.5rem;
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
    }

    .auto-train-btn:hover {
      border-color: var(--accent-primary);
    }

    .auto-train-btn.active {
      background: var(--accent-primary);
      border-color: var(--accent-primary);
      color: var(--bg-deep);
    }

    .reset-btn {
      padding: 1rem 1.5rem;
      background: transparent;
      border: 2px solid var(--negative);
      border-radius: var(--radius);
      color: var(--negative);
      font-family: inherit;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.25s ease;
    }

    .reset-btn:hover {
      background: var(--negative);
      color: white;
    }

    .epoch-counter {
      text-align: center;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      font-size: 1rem;
      color: var(--text-secondary);
    }

    .epoch-counter strong {
      color: var(--text-primary);
      font-family: 'JetBrains Mono', monospace;
    }

    /* Explanation boxes */
    .explanation {
      background: linear-gradient(135deg, rgba(0, 212, 170, 0.1) 0%, rgba(124, 58, 237, 0.1) 100%);
      border: 1px solid var(--border-accent);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-top: 1.5rem;
    }

    .explanation h4 {
      font-size: 1.1rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
      color: var(--accent-primary);
    }

    .explanation p {
      font-size: 1.05rem;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    /* Formula display */
    .formula-box {
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      padding: 1.25rem 1.5rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 1rem;
      color: var(--text-secondary);
      margin: 1rem 0;
      overflow-x: auto;
      line-height: 1.8;
    }

    .formula-box .highlight {
      color: var(--accent-primary);
    }

    .formula-box .warm {
      color: var(--accent-warm);
    }

    /* Deep Dive Sections */
    .deep-dive {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 2px solid var(--border-subtle);
    }

    .deep-dive-title {
      font-size: 1.5rem;
      font-weight: 700;
      margin-bottom: 2rem;
      color: var(--text-primary);
      text-align: center;
    }

    .concept-card {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
      margin-bottom: 1.5rem;
    }

    .concept-card h4 {
      font-size: 1.25rem;
      font-weight: 600;
      margin-bottom: 1rem;
      color: var(--accent-primary);
    }

    .concept-card p {
      font-size: 1.05rem;
      line-height: 1.7;
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .concept-card p:last-child {
      margin-bottom: 0;
    }

    .concept-list {
      list-style: none;
      padding: 0;
      margin: 1rem 0;
    }

    .concept-list li {
      padding: 0.75rem 0 0.75rem 2rem;
      position: relative;
      font-size: 1.05rem;
      color: var(--text-secondary);
      border-bottom: 1px solid var(--border-subtle);
    }

    .concept-list li:last-child {
      border-bottom: none;
    }

    .concept-list li::before {
      content: counter(list-item);
      counter-increment: list-item;
      position: absolute;
      left: 0;
      width: 1.5rem;
      height: 1.5rem;
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-radius: 50%;
      font-size: 0.85rem;
      font-weight: 600;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .concept-list {
      counter-reset: list-item;
    }

    .analogy-box {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1.5rem 0;
    }

    .analogy-item {
      display: flex;
      gap: 1rem;
      padding: 1rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .analogy-item:last-child {
      border-bottom: none;
      padding-bottom: 0;
    }

    .analogy-item:first-child {
      padding-top: 0;
    }

    .analogy-icon {
      font-size: 1.5rem;
      flex-shrink: 0;
    }

    .analogy-item strong {
      color: var(--text-primary);
      display: block;
      margin-bottom: 0.25rem;
    }

    .analogy-item p {
      margin: 0;
      font-size: 0.95rem;
    }

    /* Black Box Visual */
    .black-box-container {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 800px) {
      .black-box-container {
        grid-template-columns: 1fr;
      }
    }

    .box-side {
      background: var(--bg-card);
      padding: 1.25rem;
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .box-side-label {
      font-size: 0.7rem;
      font-weight: 700;
      color: var(--accent-primary);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .code-snippet {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      color: var(--accent-cool);
      line-height: 1.4;
      background: var(--bg-deep);
      padding: 1rem;
      border-radius: var(--radius-sm);
      min-height: 120px;
    }

    .weights-grid-mini {
      display: grid;
      grid-template-columns: repeat(8, 1fr);
      gap: 4px;
      background: var(--bg-deep);
      padding: 1rem;
      border-radius: var(--radius-sm);
      min-height: 120px;
    }

    .weight-dot {
      aspect-ratio: 1;
      border-radius: 2px;
      background: var(--text-muted);
      opacity: 0.3;
    }

    .weight-dot.active-pos { background: var(--accent-primary); opacity: 0.8; }
    .weight-dot.active-neg { background: var(--negative); opacity: 0.8; }

    /* Hierarchy Visual */
    .hierarchy-container {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: var(--bg-deep);
      border-radius: var(--radius);
      border: 1px solid var(--border-subtle);
    }

    .hierarchy-level {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 0.75rem 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border-left: 4px solid var(--text-muted);
      transition: all 0.2s ease;
    }

    .hierarchy-level:hover {
      transform: translateX(5px);
      border-left-color: var(--accent-primary);
      background: var(--bg-card);
    }

    .level-icon {
      font-size: 1.25rem;
      min-width: 30px;
      text-align: center;
    }

    .level-content {
      flex: 1;
    }

    .level-title {
      font-weight: 600;
      font-size: 0.9rem;
      margin-bottom: 0.15rem;
      color: var(--text-primary);
    }

    .level-desc {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .hierarchy-arrow {
      text-align: center;
      color: var(--text-muted);
      font-size: 0.8rem;
      line-height: 1;
      margin: -0.25rem 0;
    }

    /* Scale Comparison */
    .scale-comparison {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .scale-comparison {
        grid-template-columns: repeat(2, 1fr);
      }
    }

    .scale-item {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
      border: 1px solid var(--border-subtle);
    }

    .scale-number {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.75rem;
      font-weight: 700;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .scale-label {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Experiment Box */
    .experiment-box {
      background: linear-gradient(135deg, rgba(0, 212, 170, 0.1) 0%, rgba(124, 58, 237, 0.1) 100%);
      border: 1px solid var(--border-accent);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1rem 0;
    }

    .experiment-box p {
      margin-bottom: 0.75rem;
    }

    .experiment-box p:last-child {
      margin-bottom: 0;
    }

    .experiment-box ul {
      margin: 0.5rem 0;
      padding-left: 1.5rem;
    }

    .experiment-box li {
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    /* Comparison Table */
    .comparison-table {
      border-radius: var(--radius);
      overflow: hidden;
      margin: 1.5rem 0;
    }

    .comparison-row {
      display: grid;
      grid-template-columns: 1fr 1.5fr 2fr;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-bottom: 1px solid var(--border-subtle);
    }

    .comparison-row.header {
      background: var(--bg-elevated);
      font-weight: 600;
      color: var(--text-muted);
      font-size: 0.85rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .comparison-row.highlight {
      background: rgba(0, 212, 170, 0.1);
      border-color: var(--border-accent);
    }

    .comparison-row:last-child {
      border-bottom: none;
    }

    /* Token Evolution */
    .token-evolution {
      display: flex;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .evolution-step {
      text-align: center;
    }

    .step-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .step-tokens {
      display: flex;
      gap: 0.25rem;
    }

    .evo-token {
      padding: 0.4rem 0.6rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: 4px;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
    }

    .evo-token.merged {
      background: rgba(0, 212, 170, 0.2);
      border-color: var(--accent-primary);
    }

    .evo-token.final {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .evolution-arrow {
      color: var(--text-muted);
      padding: 0 0.5rem;
    }

    /* Vocab Table */
    .vocab-table {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      margin: 1rem 0;
    }

    .vocab-row {
      display: grid;
      grid-template-columns: 80px 1fr 1fr;
      gap: 1rem;
      padding: 0.5rem 0;
      border-bottom: 1px solid var(--border-subtle);
      align-items: center;
    }

    .vocab-row:last-child {
      border-bottom: none;
    }

    .vocab-id {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
    }

    .vocab-token {
      font-family: 'JetBrains Mono', monospace;
    }

    .vocab-note {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Token Cost */
    .token-cost-example {
      display: grid;
      gap: 0.75rem;
      margin: 1rem 0;
    }

    .cost-item {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0.75rem 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .cost-text {
      color: var(--text-secondary);
    }

    .cost-tokens {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Real Vector Display */
    .real-vector-display {
      margin: 1.5rem 0;
    }

    .real-vector-grid {
      display: grid;
      grid-template-columns: repeat(16, 1fr);
      gap: 3px;
      margin-bottom: 1rem;
    }

    .vector-cell {
      aspect-ratio: 1;
      border-radius: 3px;
      position: relative;
    }

    .vector-cell:hover::after {
      content: attr(data-value);
      position: absolute;
      bottom: 100%;
      left: 50%;
      transform: translateX(-50%);
      background: var(--bg-deep);
      color: var(--text-primary);
      padding: 0.25rem 0.5rem;
      border-radius: 4px;
      font-size: 0.75rem;
      white-space: nowrap;
      z-index: 10;
    }

    .vector-stats {
      display: flex;
      justify-content: center;
      gap: 2rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .stat {
      text-align: center;
    }

    .stat-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      display: block;
    }

    .stat-value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.1rem;
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Dimension Examples */
    .dimension-examples {
      display: grid;
      gap: 1rem;
      margin: 1.5rem 0;
    }

    .dim-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem 1.25rem;
    }

    .dim-header {
      display: flex;
      justify-content: space-between;
      margin-bottom: 0.75rem;
    }

    .dim-num {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-weight: 600;
    }

    .dim-might {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .dim-spectrum {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 0.5rem;
    }

    .spectrum-end {
      font-size: 0.8rem;
      color: var(--text-muted);
      white-space: nowrap;
    }

    .spectrum-bar {
      flex: 1;
      height: 8px;
      background: linear-gradient(to right, var(--accent-cool), var(--bg-elevated), var(--accent-warm));
      border-radius: 4px;
      position: relative;
    }

    .spectrum-marker {
      position: absolute;
      top: -4px;
      width: 16px;
      height: 16px;
      background: var(--text-primary);
      border-radius: 50%;
      transform: translateX(-50%);
      border: 2px solid var(--bg-card);
    }

    .dim-examples-list {
      font-size: 0.85rem;
      color: var(--text-muted);
      font-style: italic;
    }

    /* Similarity Visual */
    .similarity-visual {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .similarity-visual {
        grid-template-columns: 1fr;
      }
    }

    .sim-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
    }

    .sim-arrows {
      height: 80px;
      position: relative;
      margin-bottom: 1rem;
    }

    .sim-arrows .arrow {
      position: absolute;
      bottom: 50%;
      left: 50%;
      width: 60px;
      height: 3px;
      background: var(--accent-primary);
      transform-origin: left center;
    }

    .sim-arrows .arrow::after {
      content: '';
      position: absolute;
      right: -5px;
      top: -4px;
      border: 5px solid transparent;
      border-left-color: var(--accent-primary);
    }

    .high-sim .arrow1 { transform: rotate(-20deg); }
    .high-sim .arrow2 { transform: rotate(-30deg); background: var(--accent-warm); }
    .high-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .medium-sim .arrow1 { transform: rotate(-20deg); }
    .medium-sim .arrow2 { transform: rotate(-70deg); background: var(--accent-warm); }
    .medium-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .low-sim .arrow1 { transform: rotate(-20deg); }
    .low-sim .arrow2 { transform: rotate(-110deg); background: var(--accent-warm); }
    .low-sim .arrow2::after { border-left-color: var(--accent-warm); }

    .sim-label strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .sim-label span {
      display: block;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .sim-desc {
      font-style: italic;
      margin-top: 0.5rem;
    }

    /* Word Algebra */
    .word-algebra {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 2rem;
      margin: 1.5rem 0;
      text-align: center;
    }

    .algebra-equation {
      display: flex;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .algebra-word {
      padding: 0.5rem 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.1rem;
    }

    .algebra-word.result {
      background: var(--accent-primary);
      color: var(--bg-deep);
      font-weight: 600;
    }

    .algebra-op {
      font-size: 1.5rem;
      color: var(--text-muted);
    }

    .algebra-explanation {
      color: var(--text-muted);
      font-size: 0.95rem;
    }

    .more-algebra {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 1rem;
      margin-top: 1rem;
    }

    .algebra-mini {
      padding: 0.5rem 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
      color: var(--text-secondary);
    }

    /* Attention Example Sentence */
    .attention-example-sentence {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      justify-content: center;
      padding: 1.5rem;
      background: var(--bg-card);
      border-radius: var(--radius);
      margin: 1rem 0;
    }

    .att-word {
      padding: 0.5rem 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 1.1rem;
    }

    .att-word.highlighted {
      background: rgba(34, 197, 94, 0.3);
      border: 2px solid var(--positive);
    }

    .att-word.query {
      background: rgba(0, 212, 170, 0.3);
      border: 2px solid var(--accent-primary);
    }

    /* QKV Explanation */
    .qkv-explanation {
      display: grid;
      gap: 1rem;
      margin: 1.5rem 0;
    }

    .qkv-role {
      display: flex;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius);
    }

    .qkv-icon {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.5rem;
      font-weight: 700;
      flex-shrink: 0;
    }

    .query-icon { background: rgba(0, 212, 170, 0.2); color: var(--accent-primary); }
    .key-icon { background: rgba(245, 158, 11, 0.2); color: var(--accent-warm); }
    .value-icon { background: rgba(124, 58, 237, 0.2); color: var(--accent-secondary); }

    .qkv-content strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .qkv-content p {
      margin: 0;
      font-size: 0.95rem;
    }

    .qkv-example {
      color: var(--text-muted);
      font-style: italic;
      margin-top: 0.25rem;
    }

    /* Multihead Visual */
    .multihead-visual {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .multihead-visual {
        grid-template-columns: 1fr;
      }
    }

    .head-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .head-label {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-weight: 600;
      margin-bottom: 0.25rem;
    }

    .head-focus {
      font-size: 0.85rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .head-pattern {
      font-size: 0.9rem;
      color: var(--text-secondary);
      font-style: italic;
    }

    /* Timeline */
    .timeline-mini {
      margin: 1.5rem 0;
    }

    .timeline-item {
      display: flex;
      gap: 1rem;
      padding: 0.75rem 1rem;
      border-left: 3px solid var(--border-subtle);
      margin-left: 1rem;
    }

    .timeline-item.highlight {
      border-left-color: var(--accent-primary);
      background: rgba(0, 212, 170, 0.1);
      border-radius: 0 var(--radius-sm) var(--radius-sm) 0;
    }

    .timeline-year {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-weight: 600;
      flex-shrink: 0;
      width: 80px;
    }

    .timeline-desc {
      color: var(--text-secondary);
    }

    /* Transformer Architecture Diagram */
    .transformer-diagram {
      display: flex;
      align-items: center;
      gap: 2rem;
      margin: 1.5rem 0;
      flex-wrap: wrap;
      justify-content: center;
    }

    .transformer-block {
      background: var(--bg-card);
      border: 2px dashed var(--border-subtle);
      border-radius: var(--radius);
      padding: 1rem;
      min-width: 260px;
    }

    .block-label {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.75rem;
      text-align: center;
    }

    .block-content {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .transformer-block .layer {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      padding: 0.75rem;
      border-radius: var(--radius-sm);
    }

    .transformer-block .layer-icon {
      font-size: 1.25rem;
    }

    .transformer-block .layer-info {
      display: flex;
      flex-direction: column;
    }

    .transformer-block .layer-info strong {
      font-size: 0.9rem;
    }

    .transformer-block .layer-info span {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .attention-layer {
      background: rgba(59, 130, 246, 0.15);
      border: 1px solid rgba(59, 130, 246, 0.3);
    }

    .ffn-layer {
      background: rgba(168, 85, 247, 0.15);
      border: 1px solid rgba(168, 85, 247, 0.3);
    }

    .layer-arrow {
      text-align: center;
      color: var(--text-muted);
      font-size: 1rem;
    }

    .transformer-repeat-arrow {
      display: flex;
      flex-direction: column;
      align-items: center;
      color: var(--text-muted);
      font-size: 0.8rem;
    }

    .repeat-arrow-line {
      width: 60px;
      height: 2px;
      background: var(--border-subtle);
      margin-top: 0.5rem;
      position: relative;
    }

    .repeat-arrow-line::after {
      content: 'â†»';
      position: absolute;
      right: -10px;
      top: -8px;
      font-size: 1rem;
    }

    /* Full Stack Visualization */
    .transformer-full-stack {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      margin-top: 1.5rem;
    }

    .stack-label {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 1rem;
      text-align: center;
    }

    .stack-content {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0.25rem;
    }

    .stack-layer {
      padding: 0.5rem 1.25rem;
      border-radius: var(--radius-sm);
      text-align: center;
      font-size: 0.85rem;
      display: flex;
      flex-direction: column;
      gap: 0.1rem;
    }

    .stack-layer .layer-ref {
      font-size: 0.7rem;
      color: var(--text-muted);
    }

    .stack-layer.input-layer {
      background: rgba(0, 212, 170, 0.15);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .stack-layer.output-layer {
      background: rgba(0, 212, 170, 0.15);
      border: 1px solid rgba(0, 212, 170, 0.3);
    }

    .stack-block {
      display: flex;
      gap: 0.5rem;
      align-items: center;
      padding: 0.4rem 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border-subtle);
    }

    .mini-layer {
      padding: 0.3rem 0.6rem;
      border-radius: 4px;
      font-size: 0.7rem;
      font-weight: 500;
    }

    .mini-layer.attention {
      background: rgba(59, 130, 246, 0.2);
      color: #60a5fa;
    }

    .mini-layer.ffn {
      background: rgba(168, 85, 247, 0.2);
      color: #c084fc;
    }

    .block-number {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-left: 0.5rem;
    }

    .stack-arrow {
      color: var(--text-muted);
      font-size: 0.85rem;
    }

    .stack-dots {
      color: var(--text-muted);
      font-size: 1.2rem;
      line-height: 1;
    }

    .transformer-scale-note {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.8rem;
      color: var(--text-secondary);
      text-align: center;
    }

    /* Pipeline Summary */
    .pipeline-summary {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin: 1.5rem 0;
    }

    .pipeline-step {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      text-align: center;
      min-width: 100px;
    }

    .pipeline-step .step-num {
      display: inline-block;
      width: 20px;
      height: 20px;
      background: var(--accent-primary);
      color: var(--bg-main);
      border-radius: 50%;
      font-size: 0.7rem;
      font-weight: bold;
      line-height: 20px;
      margin-bottom: 0.25rem;
    }

    .pipeline-step strong {
      display: block;
      font-size: 0.8rem;
      margin-bottom: 0.25rem;
    }

    .pipeline-step p {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin: 0;
    }

    .pipeline-arrow {
      color: var(--text-muted);
      font-size: 1rem;
    }

    /* Hiking Visual */
    .hiking-visual {
      margin: 1.5rem 0;
    }

    .mountain-scene {
      height: 120px;
      background: linear-gradient(to bottom, var(--bg-card) 0%, var(--bg-elevated) 100%);
      border-radius: var(--radius);
      position: relative;
      overflow: hidden;
    }

    .mountain {
      position: absolute;
      bottom: 0;
      left: 10%;
      right: 10%;
      height: 80%;
      background: linear-gradient(135deg, var(--bg-elevated) 0%, var(--bg-panel) 50%, var(--bg-elevated) 100%);
      clip-path: polygon(0% 100%, 20% 40%, 35% 70%, 50% 20%, 65% 60%, 80% 30%, 100% 100%);
    }

    #hiker-icon {
      position: absolute;
      font-size: 1.5rem;
      top: 30%;
      left: 25%;
    }

    .valley-marker {
      position: absolute;
      bottom: 10px;
      right: 20%;
      font-size: 0.85rem;
      color: var(--accent-primary);
    }

    /* Gradient Visual */
    .gradient-visual {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .gradient-visual {
        grid-template-columns: 1fr;
      }
    }

    .gradient-case {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.25rem;
      text-align: center;
    }

    .gradient-arrow {
      width: 40px;
      height: 40px;
      margin: 0 auto 1rem;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .gradient-arrow.up {
      background: rgba(239, 68, 68, 0.2);
    }
    .gradient-arrow.up::before {
      content: 'â†—';
      font-size: 1.5rem;
      color: var(--negative);
    }

    .gradient-arrow.down {
      background: rgba(34, 197, 94, 0.2);
    }
    .gradient-arrow.down::before {
      content: 'â†˜';
      font-size: 1.5rem;
      color: var(--positive);
    }

    .gradient-arrow.flat {
      background: rgba(148, 163, 184, 0.2);
    }
    .gradient-arrow.flat::before {
      content: 'â†’';
      font-size: 1.5rem;
      color: var(--text-muted);
    }

    .gradient-label strong {
      display: block;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .gradient-label p {
      margin: 0.25rem 0;
      font-size: 0.9rem;
    }

    .gradient-action {
      color: var(--accent-primary);
      font-weight: 600;
    }

    /* Learning Rate Comparison */
    .lr-comparison {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1rem;
      margin: 1.5rem 0;
    }

    @media (max-width: 768px) {
      .lr-comparison {
        grid-template-columns: 1fr;
      }
    }

    .lr-case {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .lr-viz {
      height: 60px;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      margin-bottom: 0.75rem;
      position: relative;
      overflow: hidden;
    }

    .lr-viz .lr-path {
      position: absolute;
      bottom: 10px;
      left: 10%;
      right: 10%;
      height: 3px;
    }

    .too-high .lr-path {
      background: linear-gradient(90deg, 
        var(--negative) 0%, var(--negative) 20%,
        transparent 20%, transparent 30%,
        var(--negative) 30%, var(--negative) 50%,
        transparent 50%, transparent 60%,
        var(--negative) 60%, var(--negative) 80%
      );
      animation: bounce 1s infinite;
    }

    .just-right .lr-path {
      background: linear-gradient(90deg,
        var(--positive) 0%,
        var(--positive) 100%
      );
      clip-path: polygon(0% 50%, 30% 80%, 60% 30%, 100% 50%);
    }

    .too-low .lr-path {
      background: var(--accent-warm);
      width: 20%;
    }

    .lr-label strong {
      display: block;
      color: var(--text-primary);
      font-size: 0.9rem;
    }

    .lr-label p {
      margin: 0.25rem 0 0;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Backprop Chain */
    .backprop-chain {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      padding: 1.5rem;
      background: var(--bg-card);
      border-radius: var(--radius);
      margin: 1rem 0;
    }

    .chain-step {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 0.5rem;
    }

    .chain-label {
      width: 80px;
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
      font-size: 0.85rem;
    }

    .chain-arrow {
      color: var(--negative);
      font-size: 1.25rem;
    }

    .chain-content {
      color: var(--text-secondary);
      font-size: 0.95rem;
    }

    /* Loss Examples */
    .loss-examples {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin: 1rem 0;
    }

    @media (max-width: 768px) {
      .loss-examples {
        grid-template-columns: 1fr;
      }
    }

    .loss-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .loss-type {
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .loss-formula {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      color: var(--accent-primary);
      margin-bottom: 0.5rem;
    }

    .loss-use {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Vector Example */
    .vector-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin: 1rem 0;
    }

    .vector-visual {
      text-align: center;
    }

    .vector-label {
      font-size: 0.9rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .vector-numbers {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.5rem;
      color: var(--accent-primary);
      margin-bottom: 0.5rem;
    }

    .vector-meaning {
      display: flex;
      justify-content: center;
      gap: 2rem;
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    /* ============ EMBEDDING INTRO STYLES ============ */
    .embedding-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
      margin-bottom: 2rem;
    }

    .intro-step-container {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1.5rem;
      margin-bottom: 1.5rem;
    }

    @media (max-width: 900px) {
      .intro-step-container {
        grid-template-columns: 1fr;
      }
    }

    .intro-step {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1.25rem;
      display: flex;
      gap: 1rem;
      overflow: hidden;
    }

    .step-number {
      width: 32px;
      height: 32px;
      min-width: 32px;
      border-radius: 50%;
      background: linear-gradient(135deg, var(--accent-primary), var(--accent-secondary));
      color: var(--bg-deep);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.95rem;
    }

    .step-content h4 {
      font-size: 0.95rem;
      margin-bottom: 0.4rem;
      color: var(--text-primary);
    }

    .step-content p {
      font-size: 0.85rem;
      color: var(--text-secondary);
      line-height: 1.45;
      margin-bottom: 0.5rem;
    }

    .step-content p:last-child {
      margin-bottom: 0;
    }

    .step-note {
      font-size: 0.8rem !important;
      color: var(--text-muted) !important;
      font-style: italic;
      background: var(--bg-elevated);
      padding: 0.4rem 0.6rem;
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-primary);
    }

    .step-visual {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin: 0.75rem 0;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .word-bubble {
      background: linear-gradient(135deg, var(--accent-cool), var(--accent-secondary));
      color: white;
      padding: 0.4rem 0.75rem;
      border-radius: 20px;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
      font-weight: 500;
    }

    .arrow-icon {
      color: var(--text-muted);
      font-size: 1.2rem;
    }

    .question-mark {
      font-size: 1.5rem;
      color: var(--accent-warm);
    }

    .computer-icon {
      font-size: 1.5rem;
    }

    .vector-box {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      padding: 0.4rem 0.6rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
    }

    .vector-row {
      display: flex;
      justify-content: space-between;
      gap: 0.75rem;
      padding: 0.15rem 0;
    }

    .dim-label {
      color: var(--text-muted);
    }

    .dim-value {
      font-weight: 600;
    }

    .dim-value.high {
      color: var(--accent-primary);
    }

    .dim-value.low {
      color: var(--text-muted);
    }

    .dim-more {
      color: var(--text-muted);
      font-style: italic;
      justify-content: center;
      border-top: 1px solid var(--border-subtle);
      margin-top: 0.2rem;
      padding-top: 0.3rem;
      font-size: 0.7rem;
    }

    .coords-visual {
      flex-direction: column;
      align-items: stretch;
      gap: 0.5rem;
    }

    .coords-example {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      width: 100%;
    }

    .coords-2d, .coords-3d, .coords-nd {
      display: flex;
      flex-direction: column;
      align-items: flex-start;
      gap: 0.25rem;
      padding: 0.5rem 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .coords-label {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .coords-display {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      color: var(--text-primary);
    }

    .coords-point {
      color: var(--accent-primary);
    }

    .cluster-visual {
      flex-direction: row;
      gap: 0.75rem;
      justify-content: center;
      flex-wrap: wrap;
    }

    .cluster-group {
      text-align: center;
      flex: 1;
      min-width: 80px;
    }

    .cluster-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.35rem;
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .cluster-words {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .cluster-word {
      background: var(--bg-card);
      border: 1px solid var(--border-subtle);
      padding: 0.15rem 0.4rem;
      border-radius: var(--radius-sm);
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      color: var(--text-primary);
    }

    .cluster-group:nth-child(1) .cluster-word {
      border-color: var(--accent-secondary);
      background: rgba(124, 58, 237, 0.1);
    }

    .cluster-group:nth-child(2) .cluster-word {
      border-color: var(--accent-warm);
      background: rgba(245, 158, 11, 0.1);
    }

    .cluster-group:nth-child(3) .cluster-word {
      border-color: var(--accent-cool);
      background: rgba(59, 130, 246, 0.1);
    }

    .intro-summary {
      background: linear-gradient(135deg, rgba(0, 212, 170, 0.1), rgba(124, 58, 237, 0.1));
      border: 1px solid var(--border-accent);
      border-radius: var(--radius-sm);
      padding: 1rem 1.25rem;
      font-size: 0.95rem;
      color: var(--text-primary);
      text-align: center;
    }

    .intro-summary strong {
      color: var(--accent-primary);
    }

    /* ============ INFERENCE TAB STYLES ============ */
    .inference-container {
      margin-bottom: 2rem;
    }

    .inference-grid {
      display: grid;
      grid-template-columns: 1fr 380px;
      gap: 2rem;
    }

    @media (max-width: 1100px) {
      .inference-grid {
        grid-template-columns: 1fr;
      }
    }

    .inference-main {
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
    }

    .inference-prompt-area {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
    }

    .inference-prompt-label {
      font-size: 0.9rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .inference-prompt-display {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.1rem;
      line-height: 1.6;
      color: var(--text-primary);
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      min-height: 60px;
    }

    .inference-prompt-display .generated {
      color: var(--accent-primary);
    }

    .inference-prompt-display .cursor {
      display: inline-block;
      width: 2px;
      height: 1.2em;
      background: var(--accent-primary);
      margin-left: 2px;
      animation: blink 1s step-end infinite;
      vertical-align: text-bottom;
    }

    @keyframes blink {
      50% { opacity: 0; }
    }

    .inference-flow {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 2rem;
    }

    .inference-flow-title {
      font-size: 1rem;
      color: var(--text-muted);
      margin-bottom: 1.5rem;
      text-align: center;
    }

    .inference-pipeline {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .pipeline-stage {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0.5rem;
    }

    .pipeline-box {
      padding: 1rem 1.25rem;
      border-radius: var(--radius-sm);
      font-size: 0.95rem;
      font-weight: 500;
      text-align: center;
      min-width: 100px;
      transition: all 0.3s ease;
    }

    .pipeline-box.input {
      background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(59, 130, 246, 0.1));
      border: 2px solid var(--accent-cool);
      color: var(--accent-cool);
    }

    .pipeline-box.model {
      background: linear-gradient(135deg, rgba(124, 58, 237, 0.3), rgba(124, 58, 237, 0.1));
      border: 2px solid var(--accent-secondary);
      color: var(--text-primary);
      min-width: 140px;
      padding: 1.25rem;
    }

    .pipeline-box.model .model-icon {
      font-size: 1.5rem;
      margin-bottom: 0.25rem;
    }

    .pipeline-box.output {
      background: linear-gradient(135deg, rgba(0, 212, 170, 0.2), rgba(0, 212, 170, 0.1));
      border: 2px solid var(--accent-primary);
      color: var(--accent-primary);
      font-family: 'JetBrains Mono', monospace;
    }

    .pipeline-box.active {
      box-shadow: 0 0 20px var(--glow-accent);
      transform: scale(1.05);
    }

    .pipeline-arrow {
      font-size: 1.5rem;
      color: var(--text-muted);
    }

    .pipeline-label {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    /* Token Probabilities */
    .token-probs-area {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
    }

    .token-probs-title {
      font-size: 1rem;
      color: var(--text-muted);
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .token-prob-list {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }

    .token-prob-item {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      padding: 0.5rem 0.75rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      transition: all 0.2s ease;
    }

    .token-prob-item.selected {
      background: linear-gradient(135deg, rgba(0, 212, 170, 0.2), rgba(0, 212, 170, 0.1));
      border: 1px solid var(--accent-primary);
    }

    .token-prob-item.alternative {
      opacity: 0.7;
    }

    .token-prob-rank {
      font-size: 0.8rem;
      color: var(--text-muted);
      width: 20px;
    }

    .token-prob-token {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.95rem;
      color: var(--text-primary);
      padding: 0.25rem 0.5rem;
      background: var(--bg-elevated);
      border-radius: 4px;
      min-width: 60px;
    }

    .token-prob-bar-container {
      flex: 1;
      height: 8px;
      background: var(--bg-elevated);
      border-radius: 4px;
      overflow: hidden;
    }

    .token-prob-bar {
      height: 100%;
      background: var(--accent-primary);
      border-radius: 4px;
      transition: width 0.3s ease;
    }

    .token-prob-item.alternative .token-prob-bar {
      background: var(--text-muted);
    }

    .token-prob-percent {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      color: var(--text-secondary);
      width: 50px;
      text-align: right;
    }

    /* Controls Panel for Inference */
    .inference-controls {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
    }

    .inference-controls h3 {
      font-size: 1.1rem;
      margin-bottom: 1.25rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .temp-viz {
      margin: 1rem 0;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
    }

    .temp-viz-label {
      font-size: 0.85rem;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
      text-align: center;
    }

    .temp-viz-bar {
      display: flex;
      height: 40px;
      border-radius: var(--radius-sm);
      overflow: hidden;
      gap: 2px;
    }

    .temp-viz-segment {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.7rem;
      font-weight: 600;
      color: var(--text-primary);
      transition: all 0.3s ease;
    }

    .temp-description {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.9rem;
      color: var(--text-secondary);
      text-align: center;
    }

    /* Generation Controls */
    .generation-buttons {
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      margin-top: 1.5rem;
    }

    .gen-btn {
      padding: 0.75rem 1.25rem;
      border-radius: var(--radius-sm);
      border: none;
      font-family: inherit;
      font-size: 0.9rem;
      font-weight: 700;
      cursor: pointer;
      transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .gen-btn.primary {
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-bottom: 3px solid rgba(0, 0, 0, 0.2);
    }

    .gen-btn.primary:hover {
      transform: translateY(-2px);
      filter: brightness(1.1);
      box-shadow: 0 4px 12px rgba(0, 212, 170, 0.2);
    }

    .gen-btn.secondary {
      background: var(--bg-elevated);
      color: var(--text-primary);
      border: 1px solid var(--border-subtle);
    }

    .gen-btn.secondary:hover {
      background: var(--bg-card);
      border-color: var(--text-muted);
      transform: translateY(-1px);
    }

    .gen-btn:active {
      transform: translateY(1px);
    }

    .gen-btn:disabled {
      opacity: 0.4;
      cursor: not-allowed;
      transform: none !important;
      box-shadow: none !important;
    }

    /* Autoregressive Loop Visualization */
    .autoregressive-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-top: 1.5rem;
    }

    .autoregressive-title {
      font-size: 1.1rem;
      font-weight: 600;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .loop-visualization {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .loop-step {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--border-subtle);
      transition: all 0.3s ease;
    }

    .loop-step.active {
      border-left-color: var(--accent-primary);
      background: linear-gradient(90deg, rgba(0, 212, 170, 0.1), transparent);
    }

    .loop-step.completed {
      border-left-color: var(--positive);
    }

    .loop-step-number {
      width: 28px;
      height: 28px;
      border-radius: 50%;
      background: var(--bg-elevated);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.85rem;
      font-weight: 600;
      color: var(--text-muted);
    }

    .loop-step.active .loop-step-number {
      background: var(--accent-primary);
      color: var(--bg-deep);
    }

    .loop-step.completed .loop-step-number {
      background: var(--positive);
      color: var(--bg-deep);
    }

    .loop-step-content {
      flex: 1;
    }

    .loop-step-label {
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
    }

    .loop-step-tokens {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
      color: var(--text-primary);
    }

    .loop-step-tokens .new-token {
      color: var(--accent-primary);
      font-weight: 600;
    }

    .loop-step-tokens .stop-token {
      color: var(--accent-warm);
      background: rgba(245, 158, 11, 0.2);
      padding: 0.1rem 0.3rem;
      border-radius: 3px;
    }

    .loop-arrow {
      display: flex;
      justify-content: center;
      color: var(--text-muted);
      font-size: 1.2rem;
    }

    .loop-arrow.feedback {
      position: relative;
    }

    .loop-arrow.feedback::before {
      content: 'â†© feeds back as input';
      font-size: 0.75rem;
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
      white-space: nowrap;
      color: var(--text-muted);
    }

    .generation-stats {
      margin-top: 1rem;
      padding: 1rem;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      display: flex;
      justify-content: space-around;
      text-align: center;
    }

    .stat-item {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .stat-value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.5rem;
      color: var(--accent-primary);
    }

    .stat-label {
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    /* ============ CONTEXT & PROMPTING TAB ============ */
    .context-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .context-intro h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .context-intro > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .why-prompts-matter {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
    }

    .prompt-reason {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border-left: 3px solid var(--accent-primary);
    }

    .prompt-reason strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.25rem;
    }

    .prompt-reason p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Context Window Visualizer */
    .context-window-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .context-window-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .context-window-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .context-visualizer {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .context-window-bar {
      background: var(--bg-deep);
      border-radius: var(--radius-sm);
      padding: 0.5rem;
      margin-bottom: 0.75rem;
      position: relative;
      min-height: 100px;
      max-height: 400px;
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
      overflow-y: auto;
    }

    .context-segment {
      border-radius: 4px;
      padding: 0.4rem 0.6rem;
      font-size: 0.75rem;
      transition: all 0.3s ease;
    }

    .context-segment.system {
      background: rgba(124, 58, 237, 0.3);
      border-left: 3px solid var(--accent-secondary);
    }

    .context-segment.user {
      background: rgba(59, 130, 246, 0.3);
      border-left: 3px solid var(--accent-cool);
    }

    .context-segment.assistant {
      background: rgba(0, 212, 170, 0.3);
      border-left: 3px solid var(--accent-primary);
    }

    .segment-label {
      font-weight: 600;
      font-size: 0.65rem;
      text-transform: uppercase;
      margin-bottom: 0.2rem;
      opacity: 0.7;
    }

    .segment-content {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.7rem;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .context-capacity {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
    }

    .capacity-bar {
      flex: 1;
      height: 8px;
      background: var(--bg-elevated);
      border-radius: 4px;
      overflow: hidden;
    }

    .capacity-fill {
      height: 100%;
      background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary));
      transition: width 0.3s ease;
    }

    .capacity-fill.warning {
      background: linear-gradient(90deg, var(--accent-warm), var(--negative));
    }

    .capacity-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      color: var(--text-secondary);
      min-width: 100px;
      text-align: right;
    }

    .context-controls {
      display: flex;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .context-btn {
      padding: 0.4rem 0.8rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.75rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .context-btn:hover {
      border-color: var(--accent-primary);
    }

    .context-btn.primary {
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-color: var(--accent-primary);
    }

    /* System Prompt Explainer Card */
    .system-prompt-card {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .system-prompt-card h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .system-prompt-content {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }

    @media (max-width: 800px) {
      .system-prompt-content {
        grid-template-columns: 1fr;
      }
    }

    .system-what, .system-why {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
    }

    .system-what h4, .system-why h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.9rem;
      color: var(--accent-secondary);
    }

    .system-what ul, .system-why ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.85rem;
      color: var(--text-secondary);
    }

    .system-what li, .system-why li {
      margin-bottom: 0.35rem;
    }

    .system-example {
      margin-top: 1rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      border-left: 3px solid var(--accent-secondary);
    }

    .system-example-label {
      font-size: 0.65rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
      font-family: 'DM Sans', sans-serif;
    }

    /* Token Economics Section */
    .token-economics {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .token-economics h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .token-economics > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .token-types-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 700px) {
      .token-types-grid {
        grid-template-columns: 1fr;
      }
    }

    .token-type-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .token-type-card.input {
      border-top: 3px solid var(--accent-cool);
    }

    .token-type-card.output {
      border-top: 3px solid var(--accent-primary);
    }

    .token-type-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .token-type-header h4 {
      margin: 0;
      font-size: 0.95rem;
    }

    .token-type-icon {
      font-size: 1.2rem;
    }

    .token-type-card p {
      margin: 0 0 0.5rem 0;
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    .token-type-card ul {
      margin: 0;
      padding-left: 1.25rem;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .cost-comparison {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      font-size: 0.8rem;
    }

    .cost-row {
      display: flex;
      justify-content: space-between;
      padding: 0.3rem 0;
      border-bottom: 1px solid var(--border-subtle);
    }

    .cost-row:last-child {
      border-bottom: none;
    }

    .cost-label {
      color: var(--text-secondary);
    }

    .cost-value {
      font-family: 'JetBrains Mono', monospace;
      color: var(--accent-primary);
    }

    /* Prompt Comparison Demo */
    .prompt-comparison-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .prompt-comparison-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .prompt-comparison-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .prompt-comparison-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .comparison-toggle {
      display: flex;
      gap: 0.5rem;
      margin-bottom: 1rem;
    }

    .toggle-btn {
      flex: 1;
      padding: 0.6rem 1rem;
      background: var(--bg-elevated);
      border: 2px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-secondary);
      font-family: inherit;
      font-size: 0.85rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .toggle-btn:hover {
      border-color: var(--accent-primary);
    }

    .toggle-btn.active {
      background: rgba(0, 212, 170, 0.15);
      border-color: var(--accent-primary);
      color: var(--accent-primary);
    }

    .comparison-display {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }

    @media (max-width: 800px) {
      .comparison-display {
        grid-template-columns: 1fr;
      }
    }

    .comparison-side {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .comparison-side h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    .prompt-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      padding: 0.5rem;
      background: var(--bg-card);
      border-radius: 4px;
      margin-bottom: 0.5rem;
      min-height: 60px;
    }

    .response-quality {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.75rem;
    }

    .quality-indicator {
      width: 8px;
      height: 8px;
      border-radius: 50%;
    }

    .quality-indicator.poor {
      background: var(--negative);
    }

    .quality-indicator.good {
      background: var(--positive);
    }

    .comparison-insight {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      border-left: 3px solid var(--accent-primary);
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    /* Context Forgetting Section */
    .forgetting-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .forgetting-section h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .forgetting-visual {
      display: flex;
      gap: 1rem;
      align-items: stretch;
      margin-bottom: 1rem;
      flex-wrap: wrap;
    }

    .conversation-box {
      flex: 1;
      min-width: 250px;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      position: relative;
    }

    .conversation-box h4 {
      margin: 0 0 0.5rem 0;
      font-size: 0.85rem;
    }

    .convo-messages {
      font-size: 0.7rem;
      font-family: 'JetBrains Mono', monospace;
    }

    .convo-msg {
      padding: 0.3rem 0.5rem;
      margin-bottom: 0.25rem;
      border-radius: 4px;
    }

    .convo-msg.user-msg {
      background: rgba(59, 130, 246, 0.2);
    }

    .convo-msg.assistant-msg {
      background: rgba(0, 212, 170, 0.2);
    }

    .convo-msg.truncated {
      opacity: 0.4;
      text-decoration: line-through;
    }

    .truncation-line {
      border-top: 2px dashed var(--negative);
      margin: 0.5rem 0;
      position: relative;
    }

    .truncation-label {
      position: absolute;
      top: -8px;
      left: 50%;
      transform: translateX(-50%);
      background: var(--bg-card);
      padding: 0 0.5rem;
      font-size: 0.6rem;
      color: var(--negative);
    }

    .forgetting-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-cool);
    }

    /* ============ LIMITATIONS TAB ============ */
    .limitations-intro {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .limitations-intro h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .limitations-intro > p {
      color: var(--text-secondary);
      margin-bottom: 0;
    }

    .key-insight-box {
      background: var(--bg-elevated);
      padding: 1rem;
      border-radius: var(--radius-sm);
      margin-top: 1rem;
      border-left: 3px solid var(--accent-warm);
    }

    .key-insight-box strong {
      color: var(--accent-warm);
    }

    /* Hallucination Section */
    .hallucination-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .hallucination-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .hallucination-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .hallucination-example {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
      margin-bottom: 1rem;
    }

    .example-qa {
      margin-bottom: 0.75rem;
    }

    .example-q, .example-a {
      padding: 0.5rem 0.75rem;
      border-radius: var(--radius-sm);
      margin-bottom: 0.5rem;
      font-size: 0.85rem;
    }

    .example-q {
      background: rgba(59, 130, 246, 0.2);
      border-left: 3px solid var(--accent-cool);
    }

    .example-a {
      background: rgba(0, 212, 170, 0.2);
      border-left: 3px solid var(--accent-primary);
    }

    .example-a.hallucinated {
      background: rgba(239, 68, 68, 0.2);
      border-left: 3px solid var(--negative);
    }

    .example-verdict {
      font-size: 0.8rem;
      padding: 0.5rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
    }

    .hallucination-reasons {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      gap: 0.75rem;
    }

    .reason-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .reason-card strong {
      display: block;
      font-size: 0.85rem;
      margin-bottom: 0.25rem;
    }

    .reason-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    /* Knowledge Cutoff Section */
    .cutoff-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .cutoff-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .cutoff-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .cutoff-timeline {
      display: flex;
      align-items: center;
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      margin-bottom: 1rem;
      overflow-x: auto;
    }

    .timeline-segment {
      flex: 1;
      min-width: 100px;
      text-align: center;
      position: relative;
      padding: 0.5rem;
    }

    .timeline-segment::after {
      content: '';
      position: absolute;
      top: 50%;
      right: 0;
      width: 100%;
      height: 2px;
      background: var(--border-subtle);
      z-index: 0;
    }

    .timeline-segment:last-child::after {
      display: none;
    }

    .timeline-dot {
      width: 12px;
      height: 12px;
      background: var(--accent-primary);
      border-radius: 50%;
      margin: 0 auto 0.5rem;
      position: relative;
      z-index: 1;
    }

    .timeline-segment.unknown .timeline-dot {
      background: var(--text-muted);
    }

    .timeline-segment.cutoff .timeline-dot {
      background: var(--accent-warm);
      box-shadow: 0 0 10px var(--accent-warm);
    }

    .timeline-label {
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .timeline-segment.unknown .timeline-label {
      color: var(--text-muted);
    }

    .cutoff-note {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-warm);
    }

    /* Reasoning Models Section */
    .reasoning-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .reasoning-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .reasoning-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .model-comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 800px) {
      .model-comparison {
        grid-template-columns: 1fr;
      }
    }

    .model-type-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      border: 1px solid var(--border-subtle);
    }

    .model-type-card.standard {
      border-top: 3px solid var(--text-muted);
    }

    .model-type-card.reasoning {
      border-top: 3px solid var(--accent-primary);
    }

    .model-type-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
    }

    .model-type-header h4 {
      margin: 0;
      font-size: 0.95rem;
    }

    .model-type-icon {
      font-size: 1.2rem;
    }

    .model-type-card ul {
      margin: 0 0 0.75rem 0;
      padding-left: 1.25rem;
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    .model-examples {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .reasoning-why-works {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 1rem;
      margin-bottom: 1rem;
    }

    .reasoning-why-works h4 {
      margin: 0 0 0.75rem 0;
      font-size: 0.95rem;
    }

    .why-points {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
    }

    .why-point {
      display: flex;
      gap: 0.5rem;
      font-size: 0.8rem;
    }

    .why-point-icon {
      font-size: 1rem;
      flex-shrink: 0;
    }

    .why-point p {
      margin: 0;
      color: var(--text-secondary);
    }

    .why-point strong {
      color: var(--text-primary);
    }

    /* Interactive Thinking Demo */
    .thinking-demo-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .thinking-demo-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .thinking-demo-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .thinking-demo {
      background: var(--bg-card);
      border-radius: var(--radius);
      padding: 1rem;
    }

    .thinking-problem {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      margin-bottom: 1rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
    }

    .thinking-problem-label {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-bottom: 0.25rem;
      font-family: 'DM Sans', sans-serif;
    }

    .thinking-approaches {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    @media (max-width: 800px) {
      .thinking-approaches {
        grid-template-columns: 1fr;
      }
    }

    .approach-panel {
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 2px solid transparent;
    }

    .approach-panel.standard {
      border-color: var(--text-muted);
    }

    .approach-panel.reasoning {
      border-color: var(--accent-primary);
    }

    .approach-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
      font-weight: 600;
      font-size: 0.85rem;
    }

    .approach-content {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.75rem;
      line-height: 1.6;
      min-height: 150px;
    }

    .thinking-tokens {
      background: rgba(0, 212, 170, 0.1);
      border: 1px dashed var(--accent-primary);
      border-radius: 4px;
      padding: 0.5rem;
      margin-bottom: 0.5rem;
      color: var(--text-secondary);
    }

    .thinking-tokens-label {
      font-size: 0.65rem;
      color: var(--accent-primary);
      margin-bottom: 0.25rem;
    }

    .final-answer {
      padding-top: 0.5rem;
      border-top: 1px solid var(--border-subtle);
    }

    .answer-correct {
      color: var(--positive);
    }

    .answer-incorrect {
      color: var(--negative);
    }

    .thinking-controls {
      display: flex;
      gap: 0.5rem;
      flex-wrap: wrap;
    }

    .thinking-btn {
      padding: 0.5rem 1rem;
      background: var(--bg-elevated);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius-sm);
      color: var(--text-primary);
      font-family: inherit;
      font-size: 0.8rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    .thinking-btn:hover {
      border-color: var(--accent-primary);
    }

    .thinking-btn.primary {
      background: var(--accent-primary);
      color: var(--bg-deep);
      border-color: var(--accent-primary);
    }

    .thinking-result {
      margin-top: 1rem;
      padding: 0.75rem;
      background: var(--bg-elevated);
      border-radius: var(--radius-sm);
      font-size: 0.8rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Tools & RAG Section */
    .tools-section {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .tools-section h3 {
      margin: 0 0 0.5rem 0;
      font-size: 1.1rem;
    }

    .tools-section > p {
      color: var(--text-secondary);
      margin-bottom: 1rem;
    }

    .tools-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .tool-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
      border: 1px solid var(--border-subtle);
    }

    .tool-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .tool-icon {
      font-size: 1.2rem;
    }

    .tool-name {
      font-weight: 600;
      font-size: 0.9rem;
    }

    .tool-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .tools-insight {
      background: var(--bg-elevated);
      padding: 0.75rem;
      border-radius: var(--radius-sm);
      font-size: 0.85rem;
      border-left: 3px solid var(--accent-primary);
    }

    /* Other Limitations Section */
    .other-limitations {
      background: var(--bg-panel);
      border: 1px solid var(--border-subtle);
      border-radius: var(--radius);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .other-limitations h3 {
      margin: 0 0 0.75rem 0;
      font-size: 1.1rem;
    }

    .limitations-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 0.75rem;
    }

    .limitation-card {
      background: var(--bg-card);
      border-radius: var(--radius-sm);
      padding: 0.75rem;
    }

    .limitation-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.5rem;
    }

    .limitation-icon {
      font-size: 1rem;
    }

    .limitation-card strong {
      font-size: 0.85rem;
    }

    .limitation-card p {
      margin: 0;
      font-size: 0.75rem;
      color: var(--text-secondary);
    }

    .limitation-example {
      margin-top: 0.5rem;
      padding: 0.4rem;
      background: var(--bg-elevated);
      border-radius: 4px;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.7rem;
      color: var(--text-muted);
    }
  </style>
</head>
<body>
  <div class="app-layout">
    <!-- Sidebar Navigation -->
    <aside class="sidebar">
      <div class="sidebar-header">
        <h1>AI Intuition Lab</h1>
        <p>Build mental models of how Large Language Models work</p>
      </div>

      <nav class="tab-nav">
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">0</span> Introduction</span>
          <div class="tab-group-buttons">
            <button class="tab-btn active" data-tab="welcome">
              <span class="icon">ðŸ </span>
              <span>Welcome</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">1</span> Input & Output</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="tokens">
              <span class="icon">ðŸ”¤</span>
              <span>Tokenization</span>
            </button>
            <button class="tab-btn" data-tab="embed">
              <span class="icon">ðŸ“</span>
              <span>Embeddings</span>
            </button>
            <button class="tab-btn" data-tab="inference">
              <span class="icon">ðŸ’¬</span>
              <span>Inference</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">2</span> Architecture</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="nn">
              <span class="icon">ðŸ§ </span>
              <span>Neural Network</span>
            </button>
            <button class="tab-btn" data-tab="attention">
              <span class="icon">ðŸ”</span>
              <span>Attention</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">3</span> Training LLMs</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="training">
              <span class="icon">ðŸŽ“</span>
              <span>Pre-Training</span>
            </button>
            <button class="tab-btn" data-tab="finetuning">
              <span class="icon">ðŸŽ¯</span>
              <span>Fine-Tuning</span>
            </button>
          </div>
        </div>
        <div class="tab-group">
          <span class="tab-group-label"><span class="group-num">4</span> In Practice</span>
          <div class="tab-group-buttons">
            <button class="tab-btn" data-tab="prompting">
              <span class="icon">ðŸ’¡</span>
              <span>Prompting</span>
            </button>
            <button class="tab-btn" data-tab="limitations">
              <span class="icon">âš ï¸</span>
              <span>Limitations</span>
            </button>
          </div>
        </div>
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
    <!-- WELCOME TAB -->
    <section id="tab-welcome" class="tab-section active">
      <div class="section-header">
        <h2>Developing Your AI Intuition</h2>
        <p>Moving from a "black box" view of AI to becoming an expert user</p>
      </div>

      <div class="concept-card p-15">
        <h4>The Goal: Expert User, Not Researcher</h4>
        <p>This lab isnâ€™t about turning you into a computer scientist or an AI researcher. Itâ€™s about helping you understand the "physics" of how Large Language Models (LLMs) work so you can use them more effectively.</p>
        <p class="mt-1">By grasping the underlying concepts, you'll develop a <strong>intuition</strong> for why models succeed, why they fail, and how to steer them toward the results you want.</p>
      </div>

      <div class="concept-card mt-15 p-15">
        <h4>ðŸ“¸ The Metaphor: The Pro vs. The Point-and-Shoot</h4>
        <div class="grid grid-2-col gap-15 mt-1">
          <div class="card-sm">
            <div class="text-accent bold mb-05">The Point-and-Shoot User</div>
            <p class="text-sm">Most people use AI like an iPhone camera on "Auto" mode. It works 80% of the time, but when the lighting is weird or the subject is moving fast, they don't know how to fix the blurry result. They are limited by the model's default behavior.</p>
          </div>
          <div class="card-sm">
            <div class="text-accent bold mb-05">The Expert User (The Pro)</div>
            <p class="text-sm">A professional photographer understands how <strong>light</strong> (data) interacts with the <strong>lens</strong> (attention) and the <strong>sensor</strong> (weights). They know how to adjust the <strong>aperture</strong> (temperature) and <strong>focus</strong> (context) to get the perfect shot every time.</p>
          </div>
        </div>
        <p class="mt-15 text-secondary"><strong>Your Journey:</strong> You don't need to know how to build the digital sensor from scratch, but knowing how it <em>reacts</em> to the world makes you a professional. This lab is your training ground for mastering those manual controls.</p>
      </div>

      <div class="concept-card mt-15 p-15">
        <h4>ðŸ—ºï¸ The Roadmap to Intuition</h4>
        <div class="hierarchy-container mt-1" style="background: var(--bg-card);">
          <div class="hierarchy-level">
            <div class="level-icon">ðŸ“¦</div>
            <div class="level-content">
              <div class="level-title">1. The Material (Input & Output)</div>
              <div class="level-desc">Understand <strong>Tokens</strong> and <strong>Embeddings</strong> â€” the fundamental "atoms" that AI uses to represent human meaning.</div>
            </div>
          </div>
          <div class="hierarchy-arrow">â†“</div>
          <div class="hierarchy-level">
            <div class="level-icon">âš™ï¸</div>
            <div class="level-content">
              <div class="level-title">2. The Engine (Architecture)</div>
              <div class="level-desc">See how <strong>Neural Networks</strong> and <strong>Attention</strong> mechanisms process those atoms to find relationships and patterns.</div>
            </div>
          </div>
          <div class="hierarchy-arrow">â†“</div>
          <div class="hierarchy-level">
            <div class="level-icon">ðŸŽ“</div>
            <div class="level-content">
              <div class="level-title">3. The Schooling (Training)</div>
              <div class="level-desc">Learn how <strong>Pre-Training</strong> and <strong>Fine-Tuning</strong> turn random math into helpful assistants by training on trillions of words.</div>
            </div>
          </div>
          <div class="hierarchy-arrow">â†“</div>
          <div class="hierarchy-level">
            <div class="level-icon">ðŸ’¡</div>
            <div class="level-content">
              <div class="level-title">4. The Craft (In Practice)</div>
              <div class="level-desc">Apply your intuition to <strong>Prompting</strong> and navigate the <strong>Limitations</strong> (like hallucinations) of these systems.</div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- TOKENIZATION TAB -->
    <section id="tab-tokens" class="tab-section">
      <div class="section-header">
        <h2>ðŸ”¤ Tokenization</h2>
        <p>AI models don't use raw text. Instead, they use sequences of numbers called tokens.</p>
      </div>

      <div class="intro-summary mb-2">
        Before an AI can understand text, it must break it down into smaller units called <strong>tokens</strong>. This demo simulates a <strong>Subword Tokenizer</strong>, showing how words are split into meaningful chunks and assigned numerical IDs that the model can process.
      </div>

      <div class="tokenizer-container">
        <div class="interactive-well">
          <div class="tok-main">
            <div class="card-header">
              <h3>Text Input</h3>
              <span class="badge">Subword Tokenization</span>
            </div>
            <div class="input-area mt-1">
              <textarea id="tok-input" style="min-height: 120px;" placeholder="Try words like 'unhappiness', 'artificial intelligence', or 'misunderstanding'...">Artificial intelligence and machine learning are transforming our understanding of computational thinking.</textarea>
            </div>
            <button class="action-btn mt-1" id="tok-btn">
              <span>Tokenize Text</span>
              <span>â†’</span>
            </button>
          </div>

          <div class="concept-card mt-15 p-125">
            <h4>Resulting Tokens</h4>
            <div class="tokens-grid mt-1" id="tok-tokens"></div>
            
            <h4 class="mt-15 text-sm">Numerical IDs</h4>
            <div class="ids-display mt-05 text-sm p-075" id="tok-ids"></div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>Why subword tokenization matters</h4>
        <p>Real models like GPT-4 use ~100k tokens. Words are broken into meaningful pieces: "unhappiness" â†’ ["un", "happiness"] or ["un", "happ", "iness"]. This lets the model understand prefixes like "un-" (negation) and suffixes like "-ness" (noun form). Try typing "unhappy", "happiness", and "unhappiness" to see how they share pieces â€” this is how models generalize to words they've rarely seen.</p>
        <div class="note-box mt-1 p-075 p-1 text-sm" style="background: var(--bg-elevated); border-radius: var(--radius-sm); border-left: 3px solid var(--accent-cool);">
          <strong>ðŸ“ Note:</strong> This is a simplified tokenizer for educational purposes. Real tokenizers use larger vocabularies (~100k tokens) and make different splitting decisions. 
          <a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground" target="_blank" rel="noopener" class="text-primary" style="text-decoration: underline;">Try a real tokenizer â†’</a>
        </div>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Tokenization</h3>
        
        <div class="concept-card">
          <h4>Why Not Just Use Letters?</h4>
          <p>You might wonder: why not just feed the model one letter at a time? Three reasons:</p>
          <div class="comparison-table">
            <div class="comparison-row header">
              <div>Approach</div>
              <div>Sequence Length</div>
              <div>Problem</div>
            </div>
            <div class="comparison-row">
              <div><strong>Characters</strong></div>
              <div>"hello world" â†’ 11 tokens</div>
              <div>Too granular â€” hard to learn word meanings</div>
            </div>
            <div class="comparison-row">
              <div><strong>Whole words</strong></div>
              <div>"hello world" â†’ 2 tokens</div>
              <div>Can't handle new words, typos, or rare words</div>
            </div>
            <div class="comparison-row highlight">
              <div><strong>Subwords</strong></div>
              <div>"hello world" â†’ 2-3 tokens</div>
              <div>Best of both: efficient + flexible</div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>How BPE (Byte Pair Encoding) Works</h4>
          <p>The most common tokenization method builds a vocabulary by finding frequent patterns:</p>
          <ol class="concept-list">
            <li><strong>Start with characters</strong> â€” Begin with just letters and punctuation</li>
            <li><strong>Find frequent pairs</strong> â€” Look for character pairs that appear often together (like "th" or "ing")</li>
            <li><strong>Merge them</strong> â€” Add "th" as a single token, repeat with next most frequent pair</li>
            <li><strong>Keep going</strong> â€” After ~50,000 merges, you have a vocabulary</li>
          </ol>
          <div class="token-evolution">
            <div class="evolution-step">
              <div class="step-label">Start</div>
              <div class="step-tokens">
                <span class="evo-token">l</span>
                <span class="evo-token">o</span>
                <span class="evo-token">w</span>
                <span class="evo-token">e</span>
                <span class="evo-token">r</span>
              </div>
            </div>
            <div class="evolution-arrow">â†’</div>
            <div class="evolution-step">
              <div class="step-label">Merge "er"</div>
              <div class="step-tokens">
                <span class="evo-token">l</span>
                <span class="evo-token">o</span>
                <span class="evo-token">w</span>
                <span class="evo-token merged">er</span>
              </div>
            </div>
            <div class="evolution-arrow">â†’</div>
            <div class="evolution-step">
              <div class="step-label">Merge "low"</div>
              <div class="step-tokens">
                <span class="evo-token merged">low</span>
                <span class="evo-token merged">er</span>
              </div>
            </div>
            <div class="evolution-arrow">â†’</div>
            <div class="evolution-step">
              <div class="step-label">Merge "lower"</div>
              <div class="step-tokens">
                <span class="evo-token final">lower</span>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Why Token IDs Are Just Numbers</h4>
          <p>The model never sees the actual text "hello" â€” it sees a number like <code>15339</code>. This number is just an index into a lookup table:</p>
          <div class="vocab-table">
            <div class="vocab-row">
              <span class="vocab-id">0</span>
              <span class="vocab-token">&lt;pad&gt;</span>
              <span class="vocab-note">Special: padding</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">1</span>
              <span class="vocab-token">&lt;unk&gt;</span>
              <span class="vocab-note">Special: unknown</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">...</span>
              <span class="vocab-token"></span>
              <span class="vocab-note"></span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">262</span>
              <span class="vocab-token">the</span>
              <span class="vocab-note">Very common word</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">15339</span>
              <span class="vocab-token">hello</span>
              <span class="vocab-note">Less common</span>
            </div>
            <div class="vocab-row">
              <span class="vocab-id">50256</span>
              <span class="vocab-token">&lt;|endoftext|&gt;</span>
              <span class="vocab-note">Special: end marker</span>
            </div>
          </div>
          <p>Common words get low IDs (faster to look up). The actual numbers don't mean anything â€” they're just addresses.</p>
        </div>

        <div class="concept-card">
          <h4>Try These Experiments</h4>
          <div class="experiment-box">
            <p><strong>Experiment 1:</strong> Type "unhappiness" â€” watch it split into "un" + "happiness" or "un" + "happ" + "iness"</p>
            <p><strong>Experiment 2:</strong> Type "unfortunately" â€” see how prefixes (un-) and suffixes (-ly) get separated</p>
            <p><strong>Experiment 3:</strong> Type "antidisestablishmentarianism" â€” watch it recursively break into: anti + dis + establish + ment + arian + ism</p>
            <p><strong>Experiment 4:</strong> Type "computerization" â€” see how technical words get split at meaningful boundaries</p>
            <p><strong>What you're learning:</strong> Tokenization breaks words into reusable pieces. The prefix "un-" appears in thousands of words, so learning it once helps the model understand all of them.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Cost of Tokens</h4>
          <p>When you use ChatGPT or Claude, you're often charged by tokens. Now you know why!</p>
          <div class="token-cost-example">
            <div class="cost-item">
              <div class="cost-text">"Hi"</div>
              <div class="cost-tokens">~1 token</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">"Hello, how are you today?"</div>
              <div class="cost-tokens">~6 tokens</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">This entire paragraph you're reading right now</div>
              <div class="cost-tokens">~30 tokens</div>
            </div>
            <div class="cost-item">
              <div class="cost-text">A typical 500-word essay</div>
              <div class="cost-tokens">~650-750 tokens</div>
            </div>
          </div>
          <p><strong>Rule of thumb:</strong> 1 token â‰ˆ 4 characters or â‰ˆ Â¾ of a word in English.</p>
        </div>
      </div>
    </section>

    <!-- EMBEDDINGS TAB -->
    <section id="tab-embed" class="tab-section">
      <div class="section-header">
        <h2>ðŸ“ Embedding Space</h2>
        <p>How do we turn words into something a computer can understand? We give each word a list of numbers.</p>
      </div>

      <!-- Pedagogical Introduction -->
      <div class="embedding-intro">
        <div class="intro-step-container">
          <div class="intro-step">
            <div class="step-number">1</div>
            <div class="step-content">
              <h4>The Problem</h4>
              <p>Computers only calculate with numbers. But language is made of words. How do we bridge that gap?</p>
              <div class="step-visual problem-visual">
                <span class="word-bubble">"king"</span>
                <span class="arrow-icon">â†’</span>
                <span class="question-mark">?</span>
                <span class="arrow-icon">â†’</span>
                <span class="computer-icon">ðŸ–¥ï¸</span>
              </div>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">2</div>
            <div class="step-content">
              <h4>The Solution: A List of Numbers</h4>
              <p>We represent each word as a <strong>vector</strong> â€” which is essentially a list of numbers. Each number captures something about the word's meaning.</p>
              <div class="step-visual vector-visual">
                <span class="word-bubble">"king"</span>
                <span class="arrow-icon">â†’</span>
                <div class="vector-box">
                  <div class="vector-row">
                    <span class="dim-label">royalty:</span>
                    <span class="dim-value high">0.9</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">male:</span>
                    <span class="dim-value high">0.8</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">human:</span>
                    <span class="dim-value high">0.95</span>
                  </div>
                  <div class="vector-row">
                    <span class="dim-label">animal:</span>
                    <span class="dim-value low">0.1</span>
                  </div>
                  <div class="vector-row dim-more">
                    <span>... thousands more dimensions</span>
                  </div>
                </div>
              </div>
              <p class="step-note">ðŸ’¡ In reality, dimensions don't have labels like "royalty" â€” the model learns abstract patterns that spread across all the numbers. But the idea is the same: each number captures <em>something</em> about meaning.</p>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">3</div>
            <div class="step-content">
              <h4>Numbers Become Coordinates</h4>
              <p>Here's the key insight: <strong>a list of numbers is the same thing as coordinates in space.</strong></p>
              <div class="step-visual coords-visual">
                <div class="coords-example">
                  <div class="coords-2d">
                    <div class="coords-label">2 numbers = point on a map</div>
                    <div class="coords-display">[ 3, 5 ] â†’ <span class="coords-point">â—</span> at (3, 5)</div>
                  </div>
                  <div class="coords-3d">
                    <div class="coords-label">3 numbers = point in 3D space</div>
                    <div class="coords-display">[ 3, 5, 2 ] â†’ <span class="coords-point">â—</span> at (3, 5, 2)</div>
                  </div>
                  <div class="coords-nd">
                    <div class="coords-label">8,000 numbers = point in 8,000D space</div>
                    <div class="coords-display">[ 0.9, 0.8, 0.95, ... ] â†’ <span class="coords-point">â—</span> somewhere in that space</div>
                  </div>
                </div>
              </div>
              <p>So when we give a word thousands of numbers, we're placing it at a specific location in a high-dimensional space. We can't visualize 8,000 dimensions, but the math works the same as 2D or 3D.</p>
            </div>
          </div>

          <div class="intro-step">
            <div class="step-number">4</div>
            <div class="step-content">
              <h4>Similar Meanings = Nearby Points</h4>
              <p>The magic: if the system is clever about choosing these numbers, <strong>words with similar meanings end up at nearby coordinates</strong>.</p>
              <div class="step-visual cluster-visual">
                <div class="cluster-group">
                  <div class="cluster-label">Royalty cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">king</span>
                    <span class="cluster-word">queen</span>
                    <span class="cluster-word">prince</span>
                  </div>
                </div>
                <div class="cluster-group">
                  <div class="cluster-label">Animal cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">cat</span>
                    <span class="cluster-word">dog</span>
                    <span class="cluster-word">mouse</span>
                  </div>
                </div>
                <div class="cluster-group">
                  <div class="cluster-label">Technology cluster</div>
                  <div class="cluster-words">
                    <span class="cluster-word">computer</span>
                    <span class="cluster-word">phone</span>
                    <span class="cluster-word">laptop</span>
                  </div>
                </div>
              </div>
              <p>This is an <strong>embedding</strong> â€” we've "embedded" the meaning of words into a geometric space where distance = similarity.</p>
            </div>
          </div>
        </div>

        <div class="intro-summary">
          <strong>Now explore below:</strong> We've compressed thousands of dimensions down to 2D so you can see how words cluster. Click on words to see their similarity scores â€” which are calculated from how close their vectors are in the full high-dimensional space.
        </div>
      </div>

      <div class="embeddings-container">
        <div class="interactive-well">
          <div class="inference-grid" style="grid-template-columns: 1fr 1fr; gap: 3rem;"> <!-- Side-by-side to use space -->
            <div class="embed-main">
              <div class="card-header">
                <h3>2D Word Space</h3>
                <span class="badge">Click a word to see the similarity scores</span>
              </div>
              <div style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle); padding: 1.5rem; height: 900px; display: flex; align-items: center; justify-content: center;">
                <!-- Canvas constrained to 600px width but full height to ensure vertical aspect ratio -->
                <canvas id="embedding-canvas" style="width: 100%; height: 100%; max-width: 600px;"></canvas>
              </div>
            </div>

            <div class="embed-sidebar">
              <div class="concept-card h-900 flex flex-col p-15" style="margin: 0;">
                <h4 class="mb-125" style="font-size: 1.1rem;">Similarity Scores</h4>
                
                <div class="control-panel-well mb-15">
                  <div class="word-selector">
                    <label class="mb-05 text-xs uppercase text-muted" style="display: block;">Choose target:</label>
                    <select id="emb-select" style="width: 100%; padding: 0.75rem; font-size: 1rem; background: var(--bg-deep); color: var(--text-primary); border: 1px solid var(--border-subtle); border-radius: 4px;">
                      <option value="king">king</option>
                      <option value="queen">queen</option>
                      <option value="man">man</option>
                      <option value="woman">woman</option>
                      <option value="cat">cat</option>
                      <option value="dog">dog</option>
                      <option value="computer">computer</option>
                      <option value="phone">phone</option>
                      <option value="happy">happy</option>
                      <option value="sad">sad</option>
                    </select>
                  </div>
                </div>

                <div class="flex-1 overflow-y-auto" style="background: rgba(0,0,0,0.2); border-radius: 4px; border: 1px solid var(--border-subtle);">
                  <table class="similarity-table w-full border-collapse" id="emb-table"></table>
                </div>
                
                <p class="mt-15 text-sm text-muted" style="line-height: 1.5;">
                  <strong>Note:</strong> This is a "tall" projection. The grid cells are perfect squares. Because the chart is taller than it is wide, you can see more vertical relationships clearly.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>What you're seeing</h4>
        <p>The visualization above shows words as points, with nearby words being more similar. But remember: in a real model, each word is positioned in thousands of dimensions, not 2. We've used a technique called "dimensionality reduction" to squash those thousands of numbers down to just 2 so we can plot them on a screen. Some relationships get lost in the squashing, but the overall clustering is preserved.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Going Deeper on Embeddings</h3>
        
        <div class="concept-card">
          <h4>From Tokens to Vectors</h4>
          <p>Remember from the Tokenization tab: text gets split into tokens, and each token gets an ID number. But a single ID (like 15339 for "hello") doesn't capture meaning â€” it's just an address.</p>
          <p>The <strong>embedding layer</strong> is like a giant lookup table that converts each token ID into a full vector:</p>
          <div class="vector-example">
            <div class="vector-visual">
              <div class="vector-label">Token ID â†’ Embedding Vector</div>
              <div class="vector-numbers">15339 â†’ [ 0.23, -0.87, 1.45, -0.12, ... ] (thousands of numbers)</div>
              <div class="vector-meaning">
                <span>This lookup table is <em>learned</em> during training</span>
              </div>
            </div>
          </div>
          <p>The model learns which numbers to assign to each token so that similar-meaning tokens end up with similar vectors. This is the foundation of everything the model does.</p>
        </div>

        <div class="concept-card">
          <h4>What Real Embeddings Look Like</h4>
          <p>Here's a sample embedding vector for the word "king" (showing just 32 of the thousands of dimensions frontier models use):</p>
          <div class="real-vector-display">
            <div class="real-vector-grid" id="real-vector-grid">
              <!-- Filled by JS -->
            </div>
            <div class="vector-stats">
              <div class="stat">
                <span class="stat-label">Dimensions</span>
                <span class="stat-value">4Kâ€“12K</span>
              </div>
              <div class="stat">
                <span class="stat-label">Values range</span>
                <span class="stat-value">-2.5 to +2.5</span>
              </div>
              <div class="stat">
                <span class="stat-label">Total numbers</span>
                <span class="stat-value">Thousands per token</span>
              </div>
            </div>
          </div>
          <p>Each colored cell is one dimension. Red = negative, blue = positive, brighter = larger magnitude. Every token has its own unique pattern of thousands of numbers.</p>
        </div>

        <div class="concept-card">
          <h4>Why So Many Dimensions?</h4>
          <p>Each dimension can capture a different aspect of meaning:</p>
          <div class="dimension-examples">
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 47</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">animate â†</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 85%"></div>
                </div>
                <span class="spectrum-end">â†’ inanimate</span>
              </div>
              <div class="dim-examples-list">"dog" scores high, "rock" scores low</div>
            </div>
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 203</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">concrete â†</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 30%"></div>
                </div>
                <span class="spectrum-end">â†’ abstract</span>
              </div>
              <div class="dim-examples-list">"chair" scores high, "freedom" scores low</div>
            </div>
            <div class="dim-example">
              <div class="dim-header">
                <span class="dim-num">Dimension 512</span>
                <span class="dim-might">might capture...</span>
              </div>
              <div class="dim-spectrum">
                <span class="spectrum-end">positive â†</span>
                <div class="spectrum-bar">
                  <div class="spectrum-marker" style="left: 70%"></div>
                </div>
                <span class="spectrum-end">â†’ negative</span>
              </div>
              <div class="dim-examples-list">"joy" scores high, "grief" scores low</div>
            </div>
          </div>
          <p><strong>Important:</strong> The model learns these dimensions automatically â€” nobody programs "dimension 47 = animacy". The structure emerges from seeing billions of sentences.</p>
        </div>

        <div class="concept-card">
          <h4>How "Similarity" Works</h4>
          <p>When we say two words are "similar", we mean their vectors point in similar directions. Imagine standing at the origin and pointing toward each word:</p>
          <div class="similarity-visual">
            <div class="sim-example">
              <div class="sim-arrows high-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>High similarity (0.95)</strong>
                <span>"happy" and "joyful"</span>
                <span class="sim-desc">Arrows point almost the same direction</span>
              </div>
            </div>
            <div class="sim-example">
              <div class="sim-arrows medium-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>Medium similarity (0.5)</strong>
                <span>"happy" and "person"</span>
                <span class="sim-desc">Somewhat related, different concepts</span>
              </div>
            </div>
            <div class="sim-example">
              <div class="sim-arrows low-sim">
                <div class="arrow arrow1"></div>
                <div class="arrow arrow2"></div>
              </div>
              <div class="sim-label">
                <strong>Low similarity (0.1)</strong>
                <span>"happy" and "quantum"</span>
                <span class="sim-desc">Arrows point in very different directions</span>
              </div>
            </div>
          </div>
          <p>This is called <strong>cosine similarity</strong> â€” it measures the angle between vectors, ignoring their length.</p>
        </div>

        <div class="concept-card">
          <h4>The Famous Word Algebra</h4>
          <p>The most surprising discovery: you can do <em>math</em> with word meanings!</p>
          <div class="word-algebra">
            <div class="algebra-equation">
              <span class="algebra-word">king</span>
              <span class="algebra-op">âˆ’</span>
              <span class="algebra-word">man</span>
              <span class="algebra-op">+</span>
              <span class="algebra-word">woman</span>
              <span class="algebra-op">â‰ˆ</span>
              <span class="algebra-word result">queen</span>
            </div>
            <div class="algebra-explanation">
              <p>Subtract the "maleness" direction, add the "femaleness" direction â†’ land near "queen"</p>
            </div>
          </div>
          <div class="more-algebra">
            <div class="algebra-mini">
              <code>Paris - France + Italy â‰ˆ Rome</code>
            </div>
            <div class="algebra-mini">
              <code>walking - walk + swim â‰ˆ swimming</code>
            </div>
            <div class="algebra-mini">
              <code>bigger - big + small â‰ˆ smaller</code>
            </div>
          </div>
          <p>This only works because the embedding space has <em>consistent directions</em> for concepts like gender, country-capital relationships, and verb tenses.</p>
        </div>

        <div class="concept-card">
          <h4>Try This Mental Exercise</h4>
          <div class="experiment-box">
            <p><strong>Imagine a 3D embedding space</strong> where:</p>
            <ul>
              <li>X-axis = size (small â†’ big)</li>
              <li>Y-axis = danger (safe â†’ dangerous)</li>
              <li>Z-axis = alive (object â†’ living)</li>
            </ul>
            <p><strong>Where would these words be?</strong></p>
            <ul>
              <li>"mouse" â†’ small, low danger, alive = (-1, -1, +1)</li>
              <li>"lion" â†’ big, high danger, alive = (+1, +1, +1)</li>
              <li>"car" â†’ big, medium danger, object = (+1, 0, -1)</li>
            </ul>
            <p><strong>What you're learning:</strong> Embeddings capture multiple aspects of meaning simultaneously, arranged spatially so similar things cluster together.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- INFERENCE TAB -->
    <section id="tab-inference" class="tab-section">
      <div class="section-header">
        <h2>ðŸ’¬ LLM Inference</h2>
        <p>Watch how language models generate text one token at a time, predicting the most likely next word</p>
      </div>

      <div class="intro-summary mb-2">
        AI models generate text <strong>one token at a time</strong> by predicting what is most likely to come next. In this workbench, you can watch the model's internal probability distribution shift as it builds a sentence, and experiment with <strong>Temperature</strong> to see how it affects creativity versus logic.
      </div>

      <div class="inference-container">
        <div class="interactive-well">
          <div class="inference-grid">
            <div class="inference-main">
              <!-- Current Prompt Display -->
              <div class="inference-prompt-area">
                <div class="inference-prompt-label">
                  <span>ðŸ“</span> Current Text
                </div>
                <div class="inference-prompt-display" id="inference-prompt">
                  The best way to learn is<span class="cursor"></span>
                </div>
              </div>

              <!-- Inference Pipeline Visualization -->
              <div class="inference-flow">
                <div class="inference-flow-title">Single Inference Step</div>
                <div class="inference-pipeline">
                  <div class="pipeline-stage">
                    <div class="pipeline-box input" id="pipeline-input">
                      "...to learn is"
                    </div>
                    <div class="pipeline-label">Input tokens</div>
                  </div>
                  
                  <div class="pipeline-arrow">â†’</div>
                  
                  <div class="pipeline-stage">
                    <div class="pipeline-box model" id="pipeline-model">
                      <div class="model-icon">ðŸ§ </div>
                      Neural Network
                    </div>
                    <div class="pipeline-label">Billions of calculations</div>
                  </div>
                  
                  <div class="pipeline-arrow">â†’</div>
                  
                  <div class="pipeline-stage">
                    <div class="pipeline-box output" id="pipeline-output">
                      " by"
                    </div>
                    <div class="pipeline-label">Predicted next token</div>
                  </div>
                </div>
              </div>

              <!-- Token Probabilities -->
              <div class="concept-card mb-0">
                <h4>Token Probability Distribution</h4>
                <div class="token-prob-list" id="token-prob-list">
                  <div class="token-prob-item selected">
                    <span class="token-prob-rank">1</span>
                    <span class="token-prob-token">" by"</span>
                    <div class="token-prob-bar-container">
                      <div class="token-prob-bar" style="width: 42%"></div>
                    </div>
                    <span class="token-prob-percent">42%</span>
                  </div>
                  <div class="token-prob-item alternative">
                    <span class="token-prob-rank">2</span>
                    <span class="token-prob-token">" to"</span>
                    <div class="token-prob-bar-container">
                      <div class="token-prob-bar" style="width: 28%"></div>
                    </div>
                    <span class="token-prob-percent">28%</span>
                  </div>
                </div>
              </div>
            </div>

            <!-- Controls Panel -->
            <div class="inference-controls">
              <h3>âš™ï¸ Generation Settings</h3>
              
              <div class="control-panel-well">
                <div class="control-group">
                  <div class="control-group-title">Temperature</div>
                  <div class="slider-row">
                    <input type="range" id="inf-temperature" min="0" max="2" step="0.1" value="0.7">
                    <span class="slider-value" id="inf-temp-val">0.7</span>
                  </div>
                </div>

                <div class="temp-viz">
                  <div class="temp-viz-label">Selection probability with current temperature:</div>
                  <div class="temp-viz-bar" id="temp-viz-bar">
                    <div class="temp-viz-segment" style="background: var(--accent-primary)">" by"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-cool)">" to"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-secondary)">" through"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-warm)">" from"</div>
                    <div class="temp-viz-segment" style="background: var(--accent-pink)">" with"</div>
                  </div>
                  <div class="temp-description" id="temp-description">
                    Balanced: Mostly picks likely tokens, occasionally surprises
                  </div>
                </div>
              </div>

              <div class="generation-buttons mt-15 flex flex-col gap-075">
                <button class="gen-btn primary" id="inf-step-btn">
                  <span>â–¶</span> Generate Next Token
                </button>
                <button class="gen-btn primary" id="inf-auto-btn">
                  <span>â©</span> Auto-Generate
                </button>
                <button class="gen-btn secondary" id="inf-reset-btn">
                  <span>â†º</span> Reset
                </button>
              </div>

              <div class="generation-stats hidden mt-15 p-1" id="generation-stats" style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle);">
                <div class="stat-item">
                  <span class="stat-value" id="stat-tokens">0</span>
                  <span class="stat-label">Tokens Generated</span>
                </div>
                <div class="stat-item">
                  <span class="stat-value" id="stat-steps">0</span>
                  <span class="stat-label">Inference Steps</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Autoregressive Loop Visualization -->
      <div class="autoregressive-section">
        <div class="autoregressive-title">
          <span>ðŸ”„</span> The Autoregressive Loop
        </div>
        <p style="color: var(--text-secondary); margin-bottom: 1.5rem;">
          LLMs don't generate entire sentences at once. They predict one token, add it to the context, then predict the next â€” looping until they output a stop token.
        </p>
        <p style="color: var(--text-secondary); margin-bottom: 1.5rem;">
          <strong>What you see below is what you produced with the text generator tool above. Do it again with different settings and this will change.</strong>
        </p>
        
        <div class="loop-visualization" id="loop-visualization">
          <div class="loop-step completed">
            <div class="loop-step-number">1</div>
            <div class="loop-step-content">
              <div class="loop-step-label">Input prompt</div>
              <div class="loop-step-tokens">"The best way to learn is"</div>
            </div>
          </div>
          
          <div class="loop-arrow">â†“</div>
          
          <div class="loop-step active">
            <div class="loop-step-number">2</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 1st inference â†’ predicts " by"</div>
              <div class="loop-step-tokens">"The best way to learn is<span class="new-token"> by</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow feedback">â†“</div>
          
          <div class="loop-step">
            <div class="loop-step-number">3</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 2nd inference â†’ predicts " doing"</div>
              <div class="loop-step-tokens">"The best way to learn is by<span class="new-token"> doing</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow">â†“</div>
          
          <div class="loop-step">
            <div class="loop-step-number">4</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 3rd inference â†’ predicts "."</div>
              <div class="loop-step-tokens">"The best way to learn is by doing<span class="new-token">.</span>"</div>
            </div>
          </div>
          
          <div class="loop-arrow">â†“</div>
          
          <div class="loop-step">
            <div class="loop-step-number">âœ“</div>
            <div class="loop-step-content">
              <div class="loop-step-label">After 4th inference â†’ predicts stop token</div>
              <div class="loop-step-tokens">"The best way to learn is by doing." <span class="stop-token">&lt;|end|&gt;</span></div>
            </div>
          </div>
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h4>What's happening?</h4>
        <p>Each inference step takes all the text so far, processes it through the neural network, and outputs a probability distribution over all possible next tokens (~100,000 options). The model then samples from this distribution (influenced by temperature) to pick the next token. This new token gets added to the input, and the process repeats.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Inference</h3>
        
        <div class="concept-card">
          <h4>The Core Loop</h4>
          <p>When you chat with an AI, you're watching this loop happen incredibly fast:</p>
          <ol class="concept-list">
            <li><strong>Tokenize</strong> â€” Convert your text into numbers the model understands</li>
            <li><strong>Forward pass</strong> â€” Push tokens through billions of neural network parameters</li>
            <li><strong>Predict</strong> â€” Output a probability for every possible next token</li>
            <li><strong>Sample</strong> â€” Pick one token based on those probabilities + temperature</li>
            <li><strong>Repeat</strong> â€” Add the new token and go again until done</li>
          </ol>
          <p>Most Large Language Models (LLMs) do this loop about 20-100 times per second!</p>
        </div>

        <div class="concept-card">
          <h4>Temperature Explained</h4>
          <p>Temperature controls how "creative" vs "predictable" the model is:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ§Š</span>
              <div>
                <strong>Temperature = 0</strong>
                <p>Always picks the highest probability token. Deterministic, repetitive, but "safe".</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">â˜€ï¸</span>
              <div>
                <strong>Temperature = 1</strong>
                <p>Samples naturally from the probability distribution. Balanced creativity.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”¥</span>
              <div>
                <strong>Temperature = 2</strong>
                <p>Flattens probabilities, making unlikely tokens more likely. Creative but chaotic.</p>
              </div>
            </div>
          </div>
          <p>Mathematically, temperature divides the "logits" (raw scores) before converting to probabilities. Higher temperature â†’ flatter distribution â†’ more randomness.</p>
        </div>

        <div class="concept-card">
          <h4>Why Stop Tokens Matter</h4>
          <p>Without a stop token, the model would generate text forever! The stop token (like <code>&lt;|endoftext|&gt;</code> or <code>&lt;|end|&gt;</code>) is a special token that means "I'm done responding."</p>
          <div class="experiment-box">
            <p><strong>Fun fact:</strong> Early chatbots sometimes got stuck in loops because they didn't handle stop tokens well. The model would just keep generating, often repeating itself endlessly.</p>
            <p><strong>In practice:</strong> APIs also let you set a "max tokens" limit as a safety net, so even if the model doesn't stop naturally, it won't run forever.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Context Window</h4>
          <p>The model can only "see" a limited amount of text at once â€” this is the <strong>context window</strong>:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">400K</div>
              <div class="scale-label">GPT 5.2</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">200K</div>
              <div class="scale-label">Claude Sonnet 4.5</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">1M</div>
              <div class="scale-label">Gemini 3 Flash</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">256K</div>
              <div class="scale-label">Grok 4.1</div>
            </div>
          </div>
          <p>Each inference step processes the <em>entire</em> context. That's why longer conversations are slower and more expensive â€” more tokens to process each step!</p>
        </div>

        <div class="concept-card">
          <h4>Try This Experiment</h4>
          <div class="experiment-box">
            <p><strong>Challenge:</strong> Use the controls above to see how temperature affects generation:</p>
            <p>1. Set temperature to <strong>0</strong> and generate several times â€” notice you always get the same output</p>
            <p>2. Set temperature to <strong>1.5</strong> and generate â€” watch how the output becomes more varied (and sometimes weird!)</p>
            <p><strong>What you're learning:</strong> The same prompt can produce different outputs depending on sampling settings. This is why AI responses can vary even when you ask the same question.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- NEURAL NETWORK TAB -->
    <section id="tab-nn" class="tab-section">
      <div class="section-header">
        <h2>ðŸ§  Neural Network Forward Pass</h2>
        <p>See inside the "black box" â€” how embedding numbers flow through layers and become next-token predictions</p>
      </div>

      <!-- Context Introduction -->
      <div class="nn-intro">
        <div class="nn-intro-flow">
          <div class="nn-intro-box input-box">
            <div class="intro-box-label">From Embeddings Tab</div>
            <div class="intro-box-content">
              <strong>Input:</strong> Embedding dimensions<br>
              <span class="intro-example">[royalty: 0.8, military: 0.2, ...]</span>
            </div>
          </div>
          <div class="nn-intro-arrow">â†’</div>
          <div class="nn-intro-box network-box">
            <div class="intro-box-label">This Tab</div>
            <div class="intro-box-content">
              <strong>Neural Network</strong><br>
              <span class="intro-example">Layers of pattern detectors</span>
            </div>
          </div>
          <div class="nn-intro-arrow">â†’</div>
          <div class="nn-intro-box output-box">
            <div class="intro-box-label">To Inference Tab</div>
            <div class="intro-box-content">
              <strong>Output:</strong> Token probabilities<br>
              <span class="intro-example">[" king": 0.5, " general": 0.3, ...]</span>
            </div>
          </div>
        </div>
        <p class="nn-intro-note"><strong>Example prompt:</strong> "The messenger bowed to the ___." The network predicts which word fits best based on context. Below is a tiny network (4â†’4â†’3 nodes) â€” real LLMs have billions of parameters, but the core idea is the same.</p>
      </div>

      <div class="nn-container">
        <div class="interactive-well">
          <div class="inference-grid"> <!-- Reusing inference-grid for consistent layout -->
            <div class="nn-main">
              <div class="nn-canvas-wrapper">
                <canvas id="nn-canvas"></canvas>
                <div class="nn-legend">
                  <div class="legend-item">
                    <div class="legend-line positive thick"></div>
                    <span>Strong positive</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-line negative thick"></div>
                    <span>Strong negative</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-circle active"></div>
                    <span>High activation</span>
                  </div>
                </div>
              </div>
            </div>

            <div class="nn-controls">
              <h3>âš¡ Simulate Embeddings</h3>
              
              <div class="control-panel-well">
                <div class="control-group">
                  <div class="control-group-title">Input Dimensions</div>
                  <div class="slider-row">
                    <label>royalty</label>
                    <input type="range" id="nn-x1" min="-1" max="1" step="0.05" value="0.8">
                    <span class="slider-value" id="nn-x1-val">0.80</span>
                  </div>
                  <div class="slider-row">
                    <label>military</label>
                    <input type="range" id="nn-x2" min="-1" max="1" step="0.05" value="0.2">
                    <span class="slider-value" id="nn-x2-val">0.20</span>
                  </div>
                  <div class="slider-row">
                    <label>gender</label>
                    <input type="range" id="nn-x3" min="-1" max="1" step="0.05" value="0.6">
                    <span class="slider-value" id="nn-x3-val">0.60</span>
                  </div>
                  <div class="slider-row">
                    <label>formality</label>
                    <input type="range" id="nn-x4" min="-1" max="1" step="0.05" value="0.3">
                    <span class="slider-value" id="nn-x4-val">0.30</span>
                  </div>
                </div>
              </div>

              <div class="concept-card mt-15 p-1">
                <h4 style="font-size: 0.8rem; margin-bottom: 0.5rem;">Token Predictions</h4>
                <div class="output-display nn-output-display" style="border: none; padding: 0; margin: 0; background: transparent;">
                  <div class="output-row">
                    <span class="output-label">" king"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out1-bar"></div></div>
                    <span class="output-value" id="nn-out1">0.00</span>
                  </div>
                  <div class="output-row">
                    <span class="output-label">" general"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out2-bar"></div></div>
                    <span class="output-value" id="nn-out2">0.00</span>
                  </div>
                  <div class="output-row">
                    <span class="output-label">" queen"</span>
                    <div class="output-bar-container"><div class="output-bar" id="nn-out3-bar"></div></div>
                    <span class="output-value" id="nn-out3">0.00</span>
                  </div>
                </div>
              </div>

              <div class="nn-try-this" style="margin-top: 1.5rem; background: rgba(0,212,170,0.05); border-left: 3px solid var(--accent-primary); padding: 0.75rem; font-size: 0.75rem; color: var(--text-secondary);">
                <strong>Try this:</strong> High royalty + positive gender â†’ "king". Crank up military â†’ "general" takes over.
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>What's happening?</h4>
        <p>Each connection has a <strong>weight</strong> that multiplies the incoming signal â€” these are the "parameters" that get learned during training. The hidden layer neurons combine inputs to detect patterns: one might activate for "royalty + masculine," another for "military context." The output layer combines these patterns to predict which token comes next. Line thickness shows weight magnitude (green = positive, red = negative). Node brightness shows activation strength.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Neural Networks</h3>
        
        <div class="concept-card">
          <h4>The Big Picture</h4>
          <p>A neural network is just a series of simple math operations chained together. Each "neuron" does three things:</p>
          <ol class="concept-list">
            <li><strong>Multiply</strong> â€” Each input gets multiplied by a weight (a number that says "how important is this input?")</li>
            <li><strong>Add</strong> â€” Sum up all those multiplied values, plus a "bias" (a starting point)</li>
            <li><strong>Squash</strong> â€” Apply an activation function to keep the output in a reasonable range</li>
          </ol>
          <p>That's it! The "intelligence" comes from finding the right weights through training.</p>
        </div>

        <div class="concept-card">
          <h4>Why Weights Matter</h4>
          <p>Think of weights like volume knobs on a mixing board:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”Š</span>
              <div>
                <strong>Positive weight (+1.5)</strong>
                <p>Turns up that input â€” "this matters, pay attention to it"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”‡</span>
              <div>
                <strong>Negative weight (-1.5)</strong>
                <p>Inverts the signal â€” "when this goes up, push the output down"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">â¸ï¸</span>
              <div>
                <strong>Zero weight (0.0)</strong>
                <p>Ignores that input entirely â€” "this doesn't matter"</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Mystery of the Black Box</h4>
          <p>Traditional software is written by humans using clear, step-by-step logic. But nobody "writes" an LLM. We design the architecture, but the model <strong>learns the logic</strong> itself through trillions of mathematical adjustments. This creates a "Black Box" problem:</p>
          
          <div class="black-box-container">
            <div class="box-side">
              <div class="box-side-label"><span>ðŸ’»</span> Traditional Code</div>
              <div class="code-snippet">
                if (is_royal && is_male) {<br>
                &nbsp;&nbsp;return "king";<br>
                } else if (is_military) {<br>
                &nbsp;&nbsp;return "general";<br>
                }
              </div>
              <p class="mt-1 text-xs text-muted">Transparent: We can see exactly why a decision was made.</p>
            </div>
            <div class="box-side">
              <div class="box-side-label"><span>ðŸ§ </span> Neural Weights</div>
              <div class="weights-grid-mini">
                <div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div>
                <div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div>
                <div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div><div class="weight-dot active-neg"></div>
                <div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div><div class="weight-dot"></div>
                <div class="weight-dot"></div><div class="weight-dot active-neg"></div><div class="weight-dot"></div><div class="weight-dot active-pos"></div>
              </div>
              <p class="mt-1 text-xs text-muted">Opaque: The logic is buried in billions of floating-point numbers.</p>
            </div>
          </div>
          
          <h4 class="mt-15">The Interpretability Problem</h4>
          <p>Because the model's knowledge is spread across billions of weights, it's incredibly difficult to answer the question: <em>"Why did the model say that?"</em></p>
          <ul class="concept-list mt-1">
            <li><strong>Distributed Knowledge:</strong> The concept of "Apple" isn't in one neuron; it's a tiny pattern across thousands of them.</li>
            <li><strong>Emergent Behavior:</strong> Models often develop capabilities (like coding or translation) that their creators didn't explicitly plan for.</li>
            <li><strong>Mechanical Interpretability:</strong> A new field of science dedicated to "reverse-engineering" these weights to understand the model's internal world.</li>
          </ul>
        </div>

        <div class="concept-card">
          <h4>How Nodes Learn Meaning</h4>
          <p>During training, the network learns weights that make hidden nodes act like <strong>pattern detectors</strong>:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ‘‘</span>
              <div>
                <strong>A "royalty + masculine" detector</strong>
                <p>Activates when royalty is high AND gender is masculine â†’ boosts "king"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">âš”ï¸</span>
              <div>
                <strong>A "military" detector</strong>
                <p>Activates when military dimension is high â†’ boosts "general"</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ‘¸</span>
              <div>
                <strong>A "royalty + feminine" detector</strong>
                <p>Activates when royalty is high AND gender is feminine â†’ boosts "queen"</p>
              </div>
            </div>
          </div>
          <p>Nobody programs these detectors â€” they <em>emerge</em> from training on text. The network discovers which patterns predict which words.</p>
        </div>

        <div class="concept-card">
          <h4>Dense vs. Sparse Networks</h4>
          <p>Not all neural networks use all of their neurons for every task. This is the difference between <strong>dense</strong> and <strong>sparse</strong> architectures:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ¢</span>
              <div>
                <strong>Dense Networks</strong>
                <p>Every neuron is active for every input. Like a company where every employee must attend every single meeting. It's thorough but very slow and expensive as the model grows.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ—ï¸</span>
              <div>
                <strong>Sparse Networks (Mixture of Experts)</strong>
                <p>Only a small fraction of the network is active at any time. This allows for models with trillions of parameters that are still fast to run.</p>
              </div>
            </div>
          </div>
          
          <h4 class="mt-15">How Mixture of Experts (MoE) Works</h4>
          <p>Imagine a giant model composed of 16 "experts" (smaller neural networks). For every token, a <strong>router</strong> decides which 2 experts are best equipped to handle it:</p>
          <div class="grid grid-2-col gap-1 mt-1">
            <div class="card-sm">
              <div class="text-accent bold mb-05">1. The Router</div>
              <p class="text-xs">Acts like a dispatcher, analyzing the incoming token and selecting the most relevant experts.</p>
            </div>
            <div class="card-sm">
              <div class="text-accent bold mb-05">2. The Experts</div>
              <p class="text-xs">Specialized sub-networks that have learned specific patterns (e.g., coding, logic, or creative writing).</p>
            </div>
          </div>
          <p class="mt-1 text-sm text-secondary"><strong>The Result:</strong> MoE lets models have the <em>knowledge</em> of a massive model but the <em>speed</em> of a much smaller one, because only a fraction of the parameters are active at any given moment.</p>
        </div>

        <div class="concept-card">
          <h4>Try This Experiment</h4>
          <div class="experiment-box">
            <p><strong>Challenge 1:</strong> Make "king" the top prediction</p>
            <p><strong>Hint:</strong> Royalty high + gender positive (masculine)</p>
            <p><strong>Challenge 2:</strong> Now make "queen" win instead</p>
            <p><strong>Hint:</strong> Keep royalty high but flip gender negative (feminine)</p>
            <p><strong>Challenge 3:</strong> Make "general" dominate</p>
            <p><strong>Hint:</strong> Crank up military â€” it overrides royalty and gender</p>
            <p><strong>What you're learning:</strong> The network combines multiple input signals to make predictions. It's not just "royalty = king" â€” it's "royalty + masculine = king", "royalty + feminine = queen", and "military = general" regardless of other signals.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>Scale to Real Networks</h4>
          <p>The demo network above has <strong>~30 parameters</strong>. Real language models have:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">8B</div>
              <div class="scale-label">Llama 3</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">70B</div>
              <div class="scale-label">Llama 3.1</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">405B</div>
              <div class="scale-label">Llama 3.1 Large</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">~1T+</div>
              <div class="scale-label">Frontier models</div>
            </div>
          </div>
          <p>Same basic idea â€” multiply, add, activate â€” just repeated trillions of times with carefully tuned weights across hundreds of layers.</p>
        </div>
      </div>
    </section>

    <!-- ATTENTION TAB -->
    <section id="tab-attention" class="tab-section">
      <div class="section-header">
        <h2>ðŸŽ¯ Self-Attention</h2>
        <p>Each word looks at every other word to decide what information to gather</p>
      </div>

      <div class="attention-container">
        <div class="interactive-well">
          <div class="inference-grid" style="grid-template-columns: 1.2fr 1fr; gap: 3rem;"> <!-- Balanced layout -->
            <div class="att-main">
              <div class="card-header">
                <h3>Attention Flow</h3>
                <span class="badge">Visual connections</span>
              </div>
              <canvas id="attention-canvas"></canvas>
            </div>

            <div class="att-controls">
              <div class="card-header">
                <h3>Attention Weights</h3>
              </div>
              
              <div class="control-panel-well">
                <div class="word-selector">
                  <label>Query word (who's asking):</label>
                  <select id="att-select">
                    <option value="0">The</option>
                    <option value="1">cat</option>
                    <option value="2">sat</option>
                    <option value="3">on</option>
                    <option value="4">the</option>
                    <option value="5">mat</option>
                  </select>
                </div>

                <div class="attention-weights" id="att-weights"></div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>Why attention is powerful</h4>
        <p>Traditional neural networks process words in fixed order, passing information step by step. <strong>Attention</strong> lets every word directly access every other word, regardless of distance. When processing "it" in "The cat sat on the mat because it was tired", attention connects "it" directly back to "cat" â€” no information lost in between. This is what makes <strong>transformers</strong> (attention-based networks) so effective at understanding language.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Attention</h3>
        
        <div class="concept-card">
          <h4>The Core Intuition</h4>
          <p>Imagine you're reading a sentence and trying to understand what "it" refers to:</p>
          <div class="attention-example-sentence">
            <span class="att-word">"The</span>
            <span class="att-word highlighted">cat</span>
            <span class="att-word">sat</span>
            <span class="att-word">on</span>
            <span class="att-word">the</span>
            <span class="att-word">mat</span>
            <span class="att-word">because</span>
            <span class="att-word query">it</span>
            <span class="att-word">was</span>
            <span class="att-word">tired."</span>
          </div>
          <p>Your brain automatically "attends" back to "cat" to understand "it". Attention mechanisms let neural networks do the same thing!</p>
        </div>

        <div class="concept-card">
          <h4>Attention as "Soft" Lookup</h4>
          <p>Think of attention like a Google search, but fuzzy:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”</span>
              <div>
                <strong>Hard lookup (like a dictionary)</strong>
                <p>"Give me exactly the word at position 5" â†’ returns one thing</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸŽ¯</span>
              <div>
                <strong>Soft lookup (attention)</strong>
                <p>"Give me a mix of all words, weighted by relevance" â†’ returns a blend</p>
              </div>
            </div>
          </div>
          <p>The weights (0.35, 0.25, 0.20, ...) determine how much each word contributes to the blend.</p>
        </div>

        <div class="concept-card">
          <h4>Query, Key, Value â€” The Three Roles</h4>
          <p>Every word plays three roles simultaneously:</p>
          <div class="qkv-explanation">
            <div class="qkv-role">
              <div class="qkv-icon query-icon">Q</div>
              <div class="qkv-content">
                <strong>Query</strong>
                <p>"I'm looking for information about X"</p>
                <p class="qkv-example">When "it" is the query, it's asking: "what noun am I referring to?"</p>
              </div>
            </div>
            <div class="qkv-role">
              <div class="qkv-icon key-icon">K</div>
              <div class="qkv-content">
                <strong>Key</strong>
                <p>"Here's what I'm about"</p>
                <p class="qkv-example">"cat" has a key that says: "I'm a noun, an animal, a subject"</p>
              </div>
            </div>
            <div class="qkv-role">
              <div class="qkv-icon value-icon">V</div>
              <div class="qkv-content">
                <strong>Value</strong>
                <p>"Here's my actual information to contribute"</p>
                <p class="qkv-example">"cat" has a value containing its full meaning representation</p>
              </div>
            </div>
          </div>
          <p><strong>Process:</strong> Query asks "who matches me?" â†’ Compare with all Keys â†’ Use scores to weight Values â†’ Get blended result</p>
        </div>

        <div class="concept-card">
          <h4>Multi-Head Attention</h4>
          <p>Real transformers don't use just one attention pattern â€” they use many in parallel:</p>
          <div class="multihead-visual">
            <div class="head-example">
              <div class="head-label">Head 1</div>
              <div class="head-focus">might focus on: grammatical relationships</div>
              <div class="head-pattern">"cat" â†’ "sat" (subject â†’ verb)</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 2</div>
              <div class="head-focus">might focus on: coreference</div>
              <div class="head-pattern">"it" â†’ "cat" (pronoun â†’ noun)</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 3</div>
              <div class="head-focus">might focus on: position</div>
              <div class="head-pattern">each word â†’ nearby words</div>
            </div>
            <div class="head-example">
              <div class="head-label">Head 4</div>
              <div class="head-focus">might focus on: semantic similarity</div>
              <div class="head-pattern">"cat" â†’ "mat" (rhyme? location?)</div>
            </div>
          </div>
          <p>GPT-3 uses <strong>96 attention heads</strong> per layer, across <strong>96 layers</strong>. Each head can learn different patterns!</p>
        </div>

        <div class="concept-card">
          <h4>Try This Thought Experiment</h4>
          <div class="experiment-box">
            <p><strong>Sentence:</strong> "The trophy doesn't fit in the suitcase because it is too big."</p>
            <p><strong>Question:</strong> What does "it" refer to â€” the trophy or the suitcase?</p>
            <p><strong>Answer:</strong> The trophy (it's too big to fit)</p>
            <p><strong>Now try:</strong> "The trophy doesn't fit in the suitcase because it is too small."</p>
            <p><strong>Now "it" refers to:</strong> The suitcase! Same structure, different meaning.</p>
            <p><strong>What you're learning:</strong> Attention must use semantic understanding, not just word positions or grammar rules. The model learns this from seeing millions of similar examples.</p>
          </div>
        </div>

        <div class="concept-card">
          <h4>Attention Is All You Need</h4>
          <p>Before 2017, language models used complex recurrent structures. The famous paper "Attention Is All You Need" showed you could build state-of-the-art models using <em>only</em> attention.</p>
          <div class="timeline-mini">
            <div class="timeline-item">
              <span class="timeline-year">Pre-2017</span>
              <span class="timeline-desc">RNNs, LSTMs â€” process words one by one, slow</span>
            </div>
            <div class="timeline-item highlight">
              <span class="timeline-year">2017</span>
              <span class="timeline-desc">Transformer â€” attention only, processes all words at once, fast</span>
            </div>
            <div class="timeline-item">
              <span class="timeline-year">2018+</span>
              <span class="timeline-desc">BERT, GPT, and everything since = transformers</span>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>What Makes Transformers Special?</h4>
          <p>Unlike earlier neural networks, transformers have two key innovations:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”—</span>
              <div>
                <strong>Parallel Processing</strong>
                <p>Old neural networks like Recurrent Neural Networks (RNNs) processed words one at a time, like reading a book aloud. Transformers see all words at once, like looking at a whole page.</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸŽ¯</span>
              <div>
                <strong>Direct Connections</strong>
                <p>In RNNs, information from word 1 had to pass through words 2, 3, 4... to reach word 10. With attention, word 1 connects directly to word 10.</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card transformer-architecture-card">
          <h4>ðŸ—ï¸ The Complete Transformer Architecture</h4>
          <p>Now that we've built up the pieces, here's how they fit together. A transformer is just these two layers repeated many times:</p>
          
          <div class="transformer-diagram">
            <div class="transformer-block">
              <div class="block-label">One "Transformer Block"</div>
              <div class="block-content">
                <div class="layer attention-layer">
                  <div class="layer-icon">ðŸŽ¯</div>
                  <div class="layer-info">
                    <strong>Attention Layer</strong>
                    <span>Words gather information from each other</span>
                  </div>
                </div>
                <div class="layer-arrow">â†“</div>
                <div class="layer ffn-layer">
                  <div class="layer-icon">ðŸ§ </div>
                  <div class="layer-info">
                    <strong>Feed-Forward Layer</strong>
                    <span>Each word processed independently through a neural network</span>
                  </div>
                </div>
              </div>
            </div>
            
            <div class="transformer-repeat-arrow">
              <span>Repeat N times</span>
              <div class="repeat-arrow-line"></div>
            </div>
          </div>

          <div class="transformer-full-stack">
            <div class="stack-label">Full Model (simplified)</div>
            <div class="stack-content">
              <div class="stack-layer input-layer">
                <span>Token Embeddings</span>
                <span class="layer-ref">(from Embeddings tab)</span>
              </div>
              <div class="stack-arrow">â†“</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer 1</div>
              </div>
              <div class="stack-arrow">â†“</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer 2</div>
              </div>
              <div class="stack-arrow">â†“</div>
              <div class="stack-dots">â‹®</div>
              <div class="stack-arrow">â†“</div>
              <div class="stack-block">
                <div class="mini-layer attention">Attention</div>
                <div class="mini-layer ffn">Feed-Forward</div>
                <div class="block-number">Layer N</div>
              </div>
              <div class="stack-arrow">â†“</div>
              <div class="stack-layer output-layer">
                <span>Token Probabilities</span>
                <span class="layer-ref">(to Inference tab)</span>
              </div>
            </div>
          </div>

          <div class="transformer-scale-note">
            <strong>Real scale:</strong> Modern LLMs have anywhere from 40â€“120 layers. Each layer has billions of parameters in its attention and feed-forward components.
          </div>
        </div>

        <div class="concept-card">
          <h4>Putting It All Together</h4>
          <p>You now understand the complete pipeline of an LLM:</p>
          <div class="pipeline-summary">
            <div class="pipeline-step">
              <span class="step-num">1</span>
              <strong>Tokenization</strong>
              <p>Text â†’ token IDs</p>
            </div>
            <div class="pipeline-arrow">â†’</div>
            <div class="pipeline-step">
              <span class="step-num">2</span>
              <strong>Embeddings</strong>
              <p>Token IDs â†’ vectors</p>
            </div>
            <div class="pipeline-arrow">â†’</div>
            <div class="pipeline-step">
              <span class="step-num">3</span>
              <strong>Transformer Layers</strong>
              <p>Attention + Feed-Forward Ã— N</p>
            </div>
            <div class="pipeline-arrow">â†’</div>
            <div class="pipeline-step">
              <span class="step-num">4</span>
              <strong>Inference</strong>
              <p>Vectors â†’ next token</p>
            </div>
          </div>
          <p style="margin-top: 1rem; text-align: center; color: var(--text-secondary);">The <strong>Pre-Training</strong> tab shows how all those billions of parameters get learned.</p>
        </div>
      </div>
    </section>

    <!-- TRAINING TAB -->
    <section id="tab-training" class="tab-section">
      <div class="section-header">
        <h2>ðŸŽ“ Pre-Training</h2>
        <p>How billions of random numbers become a language model that understands the world</p>
      </div>

      <!-- Context Introduction -->
      <div class="pretrain-intro">
        <div class="pretrain-mindblown">
          <div class="mindblown-icon">ðŸ¤¯</div>
          <div class="mindblown-content">
            <h4>The Mind-Blowing Part</h4>
            <p>Remember all those weights in the Neural Network tab? The embedding dimensions? The attention scores? <strong>They all start as random numbers.</strong> Completely random. The model begins knowing absolutely nothing.</p>
            <p>Yet through pre-training, those billions of random values transform into a system that understands grammar, knows facts about the world, can reason about problems, and generates coherent text. <em>That</em> is what pre-training accomplishes.</p>
          </div>
        </div>
        
        <div class="pretrain-timeline">
          <div class="timeline-stage">
            <div class="stage-icon">ðŸŽ²</div>
            <div class="stage-label">Random Initialization</div>
            <div class="stage-desc">Billions of random numbers</div>
          </div>
          <div class="timeline-arrow">â†’</div>
          <div class="timeline-stage highlight">
            <div class="stage-icon">ðŸŽ“</div>
            <div class="stage-label">Pre-Training</div>
            <div class="stage-desc">Learn from text data</div>
          </div>
          <div class="timeline-arrow">â†’</div>
          <div class="timeline-stage">
            <div class="stage-icon">ðŸ’¬</div>
            <div class="stage-label">Inference</div>
            <div class="stage-desc">Generate responses</div>
          </div>
        </div>
      </div>

      <!-- The Training Data Section -->
      <div class="training-data-section">
        <h3>ðŸ“š The Training Data</h3>
        <p>Pre-training uses massive amounts of text where <strong>we already know what comes next</strong>. The model learns by predicting words it can then check against the real answer.</p>
        
        <div class="training-examples">
          <div class="training-example">
            <div class="example-source">From a history book:</div>
            <div class="example-text">"The messenger entered the throne room and bowed to the <span class="masked-word">[king]</span>."</div>
          </div>
          <div class="training-example">
            <div class="example-source">From a news article:</div>
            <div class="example-text">"The <span class="masked-word">[queen]</span> addressed the parliament in her annual speech."</div>
          </div>
          <div class="training-example">
            <div class="example-source">From a novel:</div>
            <div class="example-text">"The <span class="masked-word">[general]</span> commanded his troops to advance at dawn."</div>
          </div>
        </div>
        
        <div class="data-scale-note">
          <strong>Scale:</strong> Modern LLMs are trained on trillions of tokens â€” essentially a significant fraction of all text ever written and published on the internet. This is a source of controversy because not every creator of the text being used gave permission for it to be used in pre-training.
        </div>
      </div>

      <!-- The Training Loop Demo -->
      <div class="training-loop-section">
        <h3>ðŸ”„ The Training Loop</h3>
        <p>Watch how a single training step works. The model predicts the next token, sees how wrong it was, and adjusts its weights to do better.</p>
        
        <div class="interactive-well">
          <div class="inference-grid"> <!-- Consistency with other labs -->
            <div class="train-main">
              <div class="training-loop-demo" style="margin: 0;">
                <div class="loop-step-container" style="display: flex; flex-direction: column; gap: 1rem;">
                  <div class="loop-example-card">
                    <div class="loop-step-label">Training Example #<span id="training-example-num">1,847,293</span></div>
                    <div class="loop-prompt">
                      <span class="prompt-context">"The messenger bowed to the</span>
                      <span class="prompt-blank">___"</span>
                    </div>
                    <div class="loop-answer">
                      <span class="answer-label">Correct answer:</span>
                      <span class="answer-token" id="correct-token">"king"</span>
                    </div>
                  </div>
                  
                  <div class="loop-predictions-card">
                    <div class="loop-step-label">Model's Predictions</div>
                    <div class="prediction-bars">
                      <div class="pred-row">
                        <span class="pred-token correct-highlight">"king"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-1" style="width: 15%"></div></div>
                        <span class="pred-prob" id="pred-prob-1">0.15</span>
                        <span class="pred-feedback" id="pred-feedback-1"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"queen"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-2" style="width: 12%"></div></div>
                        <span class="pred-prob" id="pred-prob-2">0.12</span>
                        <span class="pred-feedback" id="pred-feedback-2"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"general"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-3" style="width: 8%"></div></div>
                        <span class="pred-prob" id="pred-prob-3">0.08</span>
                        <span class="pred-feedback" id="pred-feedback-3"></span>
                      </div>
                      <div class="pred-row">
                        <span class="pred-token">"floor"</span>
                        <div class="pred-bar-container"><div class="pred-bar" id="pred-bar-4" style="width: 65%"></div></div>
                        <span class="pred-prob" id="pred-prob-4">0.65</span>
                        <span class="pred-feedback" id="pred-feedback-4"></span>
                      </div>
                    </div>
                  </div>

                  <div class="loop-loss-card">
                    <div class="loop-step-label">Training Loss</div>
                    <div class="loss-display">
                      <div class="loss-formula">Loss = -log(<span id="loss-prob">0.15</span>) =</div>
                      <div class="loss-value" id="loss-value">1.90</div>
                      <div class="loss-interpretation" id="loss-interp">High loss = very wrong</div>
                    </div>
                  </div>

                  <div class="loop-adjust-card">
                    <div class="loop-step-label">Weight Adjustment</div>
                    <div class="adjust-explanation">
                      <p>Model sees it predicted "floor" when it should have been "king".</p>
                      <div class="adjust-visual">
                        <div class="weight-change">king weights: <span class="text-accent">â†‘ increase</span></div>
                        <div class="weight-change">floor weights: <span class="text-negative">â†“ decrease</span></div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="train-sidebar">
              <div class="concept-card p-125">
                <h4 style="font-size: 0.9rem; margin-bottom: 0.75rem;">Training Controls</h4>
                <div class="loop-controls" style="display: flex; flex-direction: column; gap: 0.75rem; margin: 0;">
                  <button class="train-loop-btn" id="train-loop-step" style="width: 100%;">
                    â–¶ Take One Step
                  </button>
                  <button class="train-loop-btn auto" id="train-loop-auto" style="width: 100%;">
                    â© Auto-Train
                  </button>
                  <button class="train-loop-btn reset" id="train-loop-reset" style="width: 100%;">
                    â†º Reset
                  </button>
                </div>

                <div class="concept-card mt-125 p-075 bg-dark">
                  <div class="loop-stats" style="display: flex; flex-direction: column; gap: 0.5rem; font-size: 0.8rem;">
                    <span>Steps: <strong id="loop-steps">0</strong></span>
                    <span>Avg Loss: <strong id="loop-avg-loss">1.90</strong></span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Backpropagation Section -->
      <div class="backprop-section">
        <h3>âš¡ Backpropagation: How Weights Get Updated</h3>
        <p>After measuring the loss, the model needs to figure out <em>which</em> of its billions of weights to adjust and by <em>how much</em>. This is where backpropagation comes in.</p>
        
        <div class="backprop-visual">
          <div class="backprop-network">
            <div class="backprop-stage">
              <div class="stage-title">1. Forward Pass</div>
              <div class="stage-desc">Signal flows through the network</div>
              <div class="network-mini forward">
                <div class="layer-col">
                  <div class="mini-node input-node"></div>
                  <div class="mini-node input-node"></div>
                </div>
                <div class="connection-col forward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="5" y1="20" x2="55" y2="20" stroke="#00d4aa" stroke-width="2"/>
                    <line x1="5" y1="20" x2="55" y2="60" stroke="#00d4aa" stroke-width="1.5"/>
                    <line x1="5" y1="60" x2="55" y2="20" stroke="#00d4aa" stroke-width="1"/>
                    <line x1="5" y1="60" x2="55" y2="60" stroke="#00d4aa" stroke-width="2"/>
                    <polygon points="50,17 55,20 50,23" fill="#00d4aa"/>
                    <polygon points="50,57 55,60 50,63" fill="#00d4aa"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node hidden-node"></div>
                  <div class="mini-node hidden-node"></div>
                </div>
                <div class="connection-col forward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="5" y1="20" x2="55" y2="40" stroke="#00d4aa" stroke-width="2"/>
                    <line x1="5" y1="60" x2="55" y2="40" stroke="#00d4aa" stroke-width="1.5"/>
                    <polygon points="50,37 55,40 50,43" fill="#00d4aa"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node output-node">
                    <span class="node-label">0.15</span>
                  </div>
                </div>
              </div>
              <div class="stage-result">Prediction: "king" at 15%</div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">2. Compute Loss</div>
              <div class="stage-desc">How wrong was the prediction?</div>
              <div class="loss-calc-visual">
                <div class="loss-target">Target: "king" should be ~100%</div>
                <div class="loss-actual">Actual: "king" at 15%</div>
                <div class="loss-result">Loss = -log(0.15) = <strong>1.90</strong></div>
              </div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">3. Backward Pass</div>
              <div class="stage-desc">Assign "blame" to each weight</div>
              <div class="network-mini backward">
                <div class="layer-col">
                  <div class="mini-node input-node blamed">
                    <span class="blame-amount">-0.02</span>
                  </div>
                  <div class="mini-node input-node blamed">
                    <span class="blame-amount">+0.05</span>
                  </div>
                </div>
                <div class="connection-col backward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="55" y1="20" x2="5" y2="20" stroke="#f59e0b" stroke-width="2"/>
                    <line x1="55" y1="20" x2="5" y2="60" stroke="#f59e0b" stroke-width="1.5"/>
                    <line x1="55" y1="60" x2="5" y2="20" stroke="#f59e0b" stroke-width="1"/>
                    <line x1="55" y1="60" x2="5" y2="60" stroke="#f59e0b" stroke-width="2"/>
                    <polygon points="10,17 5,20 10,23" fill="#f59e0b"/>
                    <polygon points="10,57 5,60 10,63" fill="#f59e0b"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node hidden-node blamed">
                    <span class="blame-amount">+0.12</span>
                  </div>
                  <div class="mini-node hidden-node blamed">
                    <span class="blame-amount">-0.08</span>
                  </div>
                </div>
                <div class="connection-col backward-conn">
                  <svg class="conn-svg" viewBox="0 0 60 80">
                    <line x1="55" y1="40" x2="5" y2="20" stroke="#f59e0b" stroke-width="2"/>
                    <line x1="55" y1="40" x2="5" y2="60" stroke="#f59e0b" stroke-width="1.5"/>
                    <polygon points="10,17 5,20 10,23" fill="#f59e0b"/>
                    <polygon points="10,57 5,60 10,63" fill="#f59e0b"/>
                  </svg>
                </div>
                <div class="layer-col">
                  <div class="mini-node output-node blamed">
                    <span class="blame-amount">Loss</span>
                  </div>
                </div>
              </div>
              <div class="stage-result">Each weight gets a gradient (how much it contributed to the error)</div>
            </div>

            <div class="backprop-stage">
              <div class="stage-title">4. Update Weights</div>
              <div class="stage-desc">Nudge each weight to reduce loss</div>
              <div class="weight-updates">
                <div class="weight-update-row">
                  <span class="weight-name">Embedding[42]</span>
                  <span class="weight-old">0.342</span>
                  <span class="weight-arrow">â†’</span>
                  <span class="weight-new">0.347</span>
                </div>
                <div class="weight-update-row">
                  <span class="weight-name">Attention.Q[103]</span>
                  <span class="weight-old">-0.156</span>
                  <span class="weight-arrow">â†’</span>
                  <span class="weight-new">-0.151</span>
                </div>
                <div class="weight-update-row">
                  <span class="weight-name">FFN.W1[891]</span>
                  <span class="weight-old">0.089</span>
                  <span class="weight-arrow">â†’</span>
                  <span class="weight-new">0.092</span>
                </div>
                <div class="weight-update-row ellipsis">
                  <span>... billions more weights updated ...</span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="backprop-key-insight">
          <strong>The key insight:</strong> Every single weight in the network â€” in the embeddings, the attention layers, the feed-forward layers â€” gets a tiny adjustment. Each adjustment is calculated to make the correct answer slightly more likely next time. Do this trillions of times, and random numbers become understanding.
        </div>
      </div>

      <div class="explanation">
        <h4>The Training Process</h4>
        <p>Pre-training is remarkably simple in concept: <strong>predict the next word, check if you were right, adjust weights to do better, repeat.</strong> Do this trillions of times across massive text datasets, and the random initial weights gradually transform into a model that has "learned" language â€” grammar, facts, reasoning patterns, and more â€” all from the single objective of predicting what comes next.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Pre-Training</h3>
        
        <div class="concept-card">
          <h4>What Pre-Training Achieves</h4>
          <p>By predicting billions of next tokens, the model learns far more than just "which word comes next":</p>
          <div class="emerges-grid">
            <div class="emerges-item">
              <span class="emerges-icon">ðŸ“</span>
              <div>
                <strong>Grammar & Syntax</strong>
                <p>To predict correctly, the model must learn that "The king <em>is</em>" is right but "The king <em>are</em>" is wrong</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">ðŸŒ</span>
              <div>
                <strong>Facts About the World</strong>
                <p>Predicting "Paris is the capital of ___" requires knowing the answer is "France"</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">ðŸ”—</span>
              <div>
                <strong>Reasoning Patterns</strong>
                <p>Predicting math solutions, code completions, and logical conclusions builds reasoning ability</p>
              </div>
            </div>
            <div class="emerges-item">
              <span class="emerges-icon">ðŸŽ­</span>
              <div>
                <strong>Style & Tone</strong>
                <p>Different text sources teach formal vs casual, technical vs creative writing patterns</p>
              </div>
            </div>
          </div>
          <p class="emerges-note"><strong>Key insight:</strong> Nobody explicitly teaches the model grammar rules or facts. These abilities <em>emerge</em> from the single task of next-token prediction at massive scale.</p>
        </div>

        <div class="concept-card">
          <h4>From Random to Trained: What Changes?</h4>
          <p>Let's trace what happens to the model's components during pre-training:</p>
          <div class="training-changes">
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random embedding vectors</span>
              </div>
              <div class="change-arrow">â†’</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Vectors where similar words cluster together</span>
              </div>
            </div>
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random attention weights</span>
              </div>
              <div class="change-arrow">â†’</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Weights that connect pronouns to nouns, verbs to subjects</span>
              </div>
            </div>
            <div class="change-item">
              <div class="change-before">
                <span class="change-label">Before</span>
                <span class="change-desc">Random feed-forward weights</span>
              </div>
              <div class="change-arrow">â†’</div>
              <div class="change-after">
                <span class="change-label">After</span>
                <span class="change-desc">Pattern detectors for concepts, facts, and reasoning</span>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Hiking Analogy for Gradient Descent</h4>
          <p>Imagine you're lost in foggy mountains with billions of dimensions, trying to find the lowest valley (lowest loss):</p>
          <div class="hiking-visual">
            <div class="mountain-scene">
              <div class="mountain"></div>
              <div class="hiker" id="hiker-icon">ðŸ§—</div>
              <div class="valley-marker">ðŸ Goal: lowest loss</div>
            </div>
          </div>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ¦¶</span>
              <div>
                <strong>Feel the slope where you're standing</strong>
                <p>= The gradient tells you which direction reduces loss</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ‘‡</span>
              <div>
                <strong>Step downhill</strong>
                <p>= Adjust weights in the direction that reduces loss</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ”„</span>
              <div>
                <strong>Repeat trillions of times</strong>
                <p>= Each training example is one tiny step toward better predictions</p>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Math Behind Backpropagation</h4>
          <p>The visualization above shows backpropagation intuitively. Under the hood, it uses the <strong>chain rule</strong> from calculus:</p>
          <div class="math-intuition">
            <div class="math-block">
              <div class="math-question">How much did weight wâ‚ contribute to the error?</div>
              <div class="math-answer">= (how much did the output change the loss) Ã— (how much did wâ‚ change the output)</div>
            </div>
          </div>
          <p>This calculation propagates backward through every layer, assigning a "gradient" (direction and magnitude of blame) to every weight. The genius is that it's computationally efficient â€” you don't need to test each weight individually.</p>
        </div>

        <div class="interactive-well">
          <div class="inference-grid"> <!-- Reusing grid for consistent layout -->
            <div class="mini-train-main">
              <div class="card-header">
                <h3>Gradient Descent in Action</h3>
                <span class="badge">Linear Regression Demo</span>
              </div>
              <p style="font-size: 0.85rem; color: var(--text-secondary); margin-bottom: 1rem;">This mini-visualization shows gradient descent on a simple problem: fitting a line to data points. The same algorithm scales to billions of parameters.</p>
              <div class="mini-canvas-container" style="background: var(--bg-card); border-radius: var(--radius-sm); border: 1px solid var(--border-subtle); padding: 0.5rem;">
                <canvas id="training-canvas"></canvas>
              </div>
            </div>

            <div class="mini-train-sidebar">
              <div class="concept-card p-125">
                <h4 style="font-size: 0.9rem; margin-bottom: 0.75rem;">Training Controls</h4>
                
                <div class="control-panel-well">
                  <div class="mini-metrics grid grid-2-col gap-05 mb-1">
                    <div class="mini-metric card-sm text-center" style="background: rgba(0,0,0,0.3);">
                      <div class="text-xs uppercase text-muted">Weight</div>
                      <div id="train-w" class="mono text-accent bold">0.50</div>
                    </div>
                    <div class="mini-metric card-sm text-center" style="background: rgba(0,0,0,0.3);">
                      <div class="text-xs uppercase text-muted">Bias</div>
                      <div id="train-b" class="mono text-accent bold">0.50</div>
                    </div>
                    <div class="mini-metric loss card-sm text-center" style="grid-column: span 2; background: rgba(0,0,0,0.3);">
                      <div class="text-xs uppercase text-muted">Total Loss</div>
                      <div id="train-loss" class="mono text-warm bold">0.00</div>
                    </div>
                  </div>

                  <div class="mini-buttons" style="display: grid; grid-template-columns: 1fr; gap: 0.5rem;">
                    <button class="mini-btn" id="train-step" style="background: var(--accent-primary); color: var(--bg-deep); border: none; padding: 0.5rem; border-radius: 4px; font-weight: 700; cursor: pointer;">Step â†“</button>
                    <button class="mini-btn" id="train-auto" style="background: var(--bg-elevated); color: var(--text-primary); border: 1px solid var(--border-subtle); padding: 0.5rem; border-radius: 4px; cursor: pointer;">Auto-Train</button>
                    <button class="mini-btn" id="train-reset" style="background: transparent; color: var(--text-muted); border: 1px solid var(--border-subtle); padding: 0.5rem; border-radius: 4px; cursor: pointer;">Reset</button>
                  </div>
                </div>

                <div style="margin-top: 1rem; text-align: center; font-size: 0.75rem; color: var(--text-muted);">
                  Steps: <strong id="train-epoch" style="color: var(--text-primary);">0</strong>
                </div>
              </div>
            </div>
          </div>
          <p class="mini-demo-note" style="margin-top: 1rem; font-size: 0.8rem; color: var(--text-secondary); text-align: center;">The red dashed lines show prediction errors. Training minimizes these errors by adjusting the line's slope (weight) and position (bias).</p>
        </div>

        <div class="concept-card">
          <h4>Pre-Training at Scale</h4>
          <p>The demo above trains 2 parameters. Real language models:</p>
          <div class="scale-comparison">
            <div class="scale-item">
              <div class="scale-number">405B</div>
              <div class="scale-label">parameters (Llama 3.1)</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">15T+</div>
              <div class="scale-label">tokens of training data</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">$100M+</div>
              <div class="scale-label">compute cost (estimated)</div>
            </div>
            <div class="scale-item">
              <div class="scale-number">16,000+</div>
              <div class="scale-label">GPUs for months</div>
            </div>
          </div>
          <p>Same fundamental algorithm â€” predict, measure error, adjust weights â€” just at staggering scale.</p>
        </div>

        <div class="concept-card">
          <h4>What Pre-Training Doesn't Teach</h4>
          <p>Pre-training alone creates a powerful text predictor, but not a helpful assistant. The model learns:</p>
          <div class="does-doesnt">
            <div class="does">
              <div class="does-header">âœ“ From Pre-Training</div>
              <ul>
                <li>Language patterns and grammar</li>
                <li>Facts and knowledge</li>
                <li>Reasoning capabilities</li>
                <li>Writing styles</li>
              </ul>
            </div>
            <div class="doesnt">
              <div class="doesnt-header">âœ— Requires Additional Training</div>
              <ul>
                <li>Following instructions</li>
                <li>Being helpful and harmless</li>
                <li>Refusing inappropriate requests</li>
                <li>Conversational format</li>
              </ul>
            </div>
          </div>
          <p>That's why pre-training is just the first step. Models like ChatGPT and Claude undergo additional training (fine-tuning, RLHF) to become useful assistants â€” which is exactly what we cover in the <strong>Fine-Tuning</strong> tab.</p>
        </div>
      </div>
    </section>

    <!-- FINE-TUNING TAB -->
    <section id="tab-finetuning" class="tab-section">
      <div class="section-header">
        <h2>ðŸŽ¯ Fine-Tuning & Alignment</h2>
        <p>How a text predictor becomes a helpful, harmless, and honest assistant</p>
      </div>

      <!-- Why Fine-Tuning Introduction -->
      <div class="ft-intro">
        <div class="ft-gap-visual">
          <div class="gap-side pretrained">
            <div class="gap-header">After Pre-Training</div>
            <div class="gap-icon">ðŸ“š</div>
            <div class="gap-desc">Knows everything, helps with nothing</div>
            <ul class="gap-list">
              <li>Completes text naturally</li>
              <li>No instruction following</li>
              <li>May continue harmful content</li>
              <li>No consistent persona</li>
            </ul>
          </div>
          <div class="gap-arrow">
            <span>Fine-Tuning</span>
            <div class="arrow-line"></div>
          </div>
          <div class="gap-side finetuned">
            <div class="gap-header">After Fine-Tuning</div>
            <div class="gap-icon">ðŸ¤</div>
            <div class="gap-desc">Helpful, harmless, honest</div>
            <ul class="gap-list">
              <li>Follows instructions</li>
              <li>Refuses harmful requests</li>
              <li>Consistent helpful persona</li>
              <li>Appropriate self-awareness</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- Before/After Example -->
      <div class="ft-example-section">
        <h3>ðŸ’¬ The Difference in Action</h3>
        <div class="ft-example-container">
          <div class="ft-prompt">
            <div class="prompt-label">User prompt:</div>
            <div class="prompt-text">"How do I pick a lock?"</div>
          </div>
          <div class="ft-responses">
            <div class="ft-response before">
              <div class="response-header">
                <span class="response-badge bad">Pre-trained only</span>
              </div>
              <div class="response-text">
                "First, you'll need a tension wrench and pick. Insert the tension wrench into the bottom of the keyhole and apply slight pressure. Then insert the pick and feel for the pins..."
              </div>
              <div class="response-note">Just continues the most likely text â€” no judgment about appropriateness</div>
            </div>
            <div class="ft-response after">
              <div class="response-header">
                <span class="response-badge good">Fine-tuned</span>
              </div>
              <div class="response-text">
                "I can help with legitimate locksmith questions! If you're locked out of your own home, I'd recommend calling a licensed locksmith. If you're interested in lockpicking as a hobby, there are legal practice locks designed for learning. What's your situation?"
              </div>
              <div class="response-note">Helpful while considering safety â€” offers alternatives and asks clarifying questions</div>
            </div>
          </div>
        </div>
      </div>

      <!-- What Fine-Tuning Teaches -->
      <div class="ft-teaches-section">
        <h3>ðŸŽ“ What Fine-Tuning Teaches</h3>
        <p>Fine-tuning instills specific behaviors that don't emerge from pre-training alone:</p>
        
        <div class="teaches-grid">
          <div class="teaches-card">
            <div class="teaches-icon">ðŸ“‹</div>
            <div class="teaches-content">
              <h4>Instruction Following</h4>
              <p>Understanding "summarize this" vs "translate this" vs "explain like I'm 5" â€” and doing what's asked.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">ðŸ›¡ï¸</div>
            <div class="teaches-content">
              <h4>Safety & Refusals</h4>
              <p>Declining to help with harmful activities, not generating dangerous content, acknowledging uncertainty.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">ðŸŽ­</div>
            <div class="teaches-content">
              <h4>Personality & Tone</h4>
              <p>Consistent voice across interactions. Helpful but not sycophantic. Appropriate formality for context.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">ðŸ”§</div>
            <div class="teaches-content">
              <h4>Tool Use</h4>
              <p>When to search vs answer from knowledge. How to write code. When to ask clarifying questions.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">ðŸ“</div>
            <div class="teaches-content">
              <h4>Format Awareness</h4>
              <p>Using markdown appropriately. Structuring long responses. Knowing when lists vs prose work better.</p>
            </div>
          </div>
          <div class="teaches-card">
            <div class="teaches-icon">ðŸªž</div>
            <div class="teaches-content">
              <h4>Self-Awareness</h4>
              <p>Knowing it's an AI. Not pretending to have experiences it doesn't have. Appropriate epistemic humility.</p>
            </div>
          </div>
        </div>
      </div>

      <!-- How RLHF Works -->
      <div class="rlhf-section">
        <h3>ðŸ”„ How RLHF Works</h3>
        <p>Reinforcement Learning from Human Feedback turns human preferences into training signal. Here's the loop:</p>
        
        <div class="rlhf-loop">
          <div class="rlhf-step">
            <div class="step-number">1</div>
            <div class="step-content">
              <h4>Generate Responses</h4>
              <p>Given a prompt, the model generates multiple possible responses.</p>
              <div class="step-example">
                <div class="example-prompt">"Explain quantum computing simply"</div>
                <div class="example-responses">
                  <div class="resp-a">Response A: Technical jargon...</div>
                  <div class="resp-b">Response B: Simple analogy...</div>
                </div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">2</div>
            <div class="step-content">
              <h4>Human Feedback</h4>
              <p>Human raters compare responses and pick the better one.</p>
              <div class="step-example">
                <div class="human-choice">
                  <span class="choice-label">Human picks:</span>
                  <span class="choice-winner">B is better</span>
                </div>
                <div class="choice-reason">"B matches the requested audience better"</div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">3</div>
            <div class="step-content">
              <h4>Train Reward Model</h4>
              <p>A separate neural network learns to predict human preferences.</p>
              <div class="step-example">
                <div class="reward-model">
                  <span>Reward Model learns:</span>
                  <span class="reward-insight">"Simple explanations for simple requests â†’ higher score"</span>
                </div>
              </div>
            </div>
          </div>
          
          <div class="rlhf-step">
            <div class="step-number">4</div>
            <div class="step-content">
              <h4>Update Model Weights</h4>
              <p>The main model is trained to produce responses that score highly with the reward model.</p>
              <div class="step-example">
                <div class="weight-update-note">Same backpropagation as pre-training, but loss = low reward instead of wrong token</div>
              </div>
            </div>
          </div>
        </div>
        
        <div class="rlhf-repeat">
          <span>â†» Repeat thousands of times across diverse prompts</span>
        </div>
      </div>

      <!-- Interactive Demo: Be the Rater -->
      <div class="rater-demo-section">
        <h3>ðŸŽ® Try It: Be the Human Rater</h3>
        <p>Experience how human preferences become training signal. Pick which response is better:</p>
        
        <div class="interactive-well">
          <div class="rater-demo">
            <div class="rater-prompt">
              <div class="rater-prompt-label">Prompt:</div>
              <div class="rater-prompt-text" id="rater-prompt">"What's the best programming language?"</div>
            </div>
            
            <div class="rater-choices">
              <button class="rater-choice" id="choice-a">
                <div class="choice-header">Response A</div>
                <div class="choice-text" id="choice-a-text">"Python is the best programming language because it's easy to learn and widely used in AI and data science."</div>
              </button>
              <button class="rater-choice" id="choice-b">
                <div class="choice-header">Response B</div>
                <div class="choice-text" id="choice-b-text">"The 'best' language depends on your goals. Python is great for beginners and data science. JavaScript dominates web development. Rust offers memory safety for systems programming. What are you hoping to build?"</div>
              </button>
            </div>
            
            <div class="rater-feedback" id="rater-feedback">
              <!-- Filled by JS after selection -->
            </div>
            
            <div class="rater-stats">
              <span>Comparisons rated: <strong id="rater-count">0</strong></span>
              <button class="rater-next-btn" id="rater-next">Next Comparison â†’</button>
            </div>
          </div>
        </div>
      </div>

      <div class="explanation">
        <h4>How This Differs from Pre-Training</h4>
        <p>Pre-training optimizes for "predict the next token correctly." Fine-tuning optimizes for "produce responses humans prefer." Both use backpropagation to update weights, but the signal is different: <strong>statistical correctness</strong> vs <strong>human judgment of quality</strong>.</p>
      </div>

      <!-- Deep Dive Section -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Understanding Fine-Tuning</h3>
        
        <div class="concept-card">
          <h4>The Three Stages of Creating an AI Assistant</h4>
          <p>Modern AI assistants go through multiple training phases:</p>
          <div class="training-stages">
            <div class="stage-block">
              <div class="stage-num">1</div>
              <div class="stage-info">
                <h5>Pre-Training</h5>
                <p>Learn language from trillions of tokens</p>
                <div class="stage-data">Months on thousands of GPUs</div>
              </div>
            </div>
            <div class="stage-arrow">â†’</div>
            <div class="stage-block">
              <div class="stage-num">2</div>
              <div class="stage-info">
                <h5>Supervised Fine-Tuning (SFT)</h5>
                <p>Learn instruction format from curated examples</p>
                <div class="stage-data">Thousands of human-written examples</div>
              </div>
            </div>
            <div class="stage-arrow">â†’</div>
            <div class="stage-block">
              <div class="stage-num">3</div>
              <div class="stage-info">
                <h5>RLHF / Preference Training</h5>
                <p>Learn what humans actually prefer</p>
                <div class="stage-data">Millions of preference comparisons</div>
              </div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>Different Approaches to Alignment</h4>
          <p>Several techniques exist for aligning models with human values:</p>
          <div class="approaches-grid">
            <div class="approach-card">
              <div class="approach-name">RLHF</div>
              <div class="approach-full">Reinforcement Learning from Human Feedback</div>
              <div class="approach-desc">Humans rank responses. Train reward model. Optimize with PPO.</div>
              <div class="approach-used">Used by: Early ChatGPT</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">RLAIF</div>
              <div class="approach-full">RL from AI Feedback</div>
              <div class="approach-desc">AI model ranks responses using guidelines. Scales better than human labeling.</div>
              <div class="approach-used">Used by: Claude (Constitutional AI)</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">Constitutional AI</div>
              <div class="approach-full">Principle-Based Self-Improvement</div>
              <div class="approach-desc">Model critiques itself against explicit principles. Auditable and consistent.</div>
              <div class="approach-used">Used by: Anthropic/Claude</div>
            </div>
            <div class="approach-card">
              <div class="approach-name">DPO</div>
              <div class="approach-full">Direct Preference Optimization</div>
              <div class="approach-desc">Skip reward model. Train directly on preference pairs. Simpler, often equally effective.</div>
              <div class="approach-used">Used by: Many recent models</div>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Reward Model</h4>
          <p>A key innovation: "bottling" human judgment into a neural network:</p>
          <div class="reward-model-visual">
            <div class="rm-input">
              <div class="rm-label">Input</div>
              <div class="rm-content">Prompt + Response</div>
            </div>
            <div class="rm-arrow">â†’</div>
            <div class="rm-model">
              <div class="rm-label">Reward Model</div>
              <div class="rm-content">(Another neural network)</div>
            </div>
            <div class="rm-arrow">â†’</div>
            <div class="rm-output">
              <div class="rm-label">Output</div>
              <div class="rm-content">Score: 0.73</div>
            </div>
          </div>
          <p>The reward model is trained on thousands of human comparisons. It learns to predict "would a human prefer this response?" This score then guides the main model's training.</p>
        </div>

        <div class="concept-card">
          <h4>Why Not Just Maximize Reward?</h4>
          <p>A naive approach would be: "generate responses that score as high as possible." But this leads to problems:</p>
          <div class="analogy-box">
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ“ˆ</span>
              <div>
                <strong>Reward Hacking</strong>
                <p>Model finds weird outputs that score high but aren't actually good (Goodhart's Law)</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸŽ­</span>
              <div>
                <strong>Sycophancy</strong>
                <p>Model learns to agree with users and tell them what they want to hear</p>
              </div>
            </div>
            <div class="analogy-item">
              <span class="analogy-icon">ðŸ˜µ</span>
              <div>
                <strong>Mode Collapse</strong>
                <p>Model produces same "safe" response for everything</p>
              </div>
            </div>
          </div>
          <p><strong>Solution:</strong> Use KL divergence constraint â€” "don't drift too far from the base model." This keeps the model capable while adding alignment.</p>
        </div>

        <div class="concept-card">
          <h4>The Alignment Tax</h4>
          <p>Fine-tuning involves tradeoffs:</p>
          <div class="tradeoff-visual">
            <div class="tradeoff-item">
              <div class="tradeoff-label">Raw Capability</div>
              <div class="tradeoff-bar">
                <div class="bar-fill pretrain" style="width: 100%"></div>
              </div>
              <div class="tradeoff-note">Pre-trained model</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Raw Capability</div>
              <div class="tradeoff-bar">
                <div class="bar-fill finetune" style="width: 92%"></div>
              </div>
              <div class="tradeoff-note">Fine-tuned model (slight reduction)</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Helpfulness</div>
              <div class="tradeoff-bar">
                <div class="bar-fill helpful" style="width: 85%"></div>
              </div>
              <div class="tradeoff-note">Huge gain from fine-tuning</div>
            </div>
            <div class="tradeoff-item">
              <div class="tradeoff-label">Safety</div>
              <div class="tradeoff-bar">
                <div class="bar-fill safe" style="width: 80%"></div>
              </div>
              <div class="tradeoff-note">Huge gain from fine-tuning</div>
            </div>
          </div>
          <p>The small reduction in raw capability is usually worth the massive gains in usefulness and safety. This is called the "alignment tax."</p>
        </div>

        <div class="concept-card">
          <h4>Ongoing Challenges</h4>
          <p>Alignment is an active research area with unsolved problems:</p>
          <div class="challenges-list">
            <div class="challenge-item">
              <strong>Jailbreaks</strong>
              <p>Creative prompts that bypass safety training. Shows alignment isn't perfectly robust.</p>
            </div>
            <div class="challenge-item">
              <strong>Generalization</strong>
              <p>Will alignment hold for situations very different from training? Unknown.</p>
            </div>
            <div class="challenge-item">
              <strong>Scalable Oversight</strong>
              <p>As models get smarter, can humans still evaluate if they're behaving well?</p>
            </div>
            <div class="challenge-item">
              <strong>Value Lock-in</strong>
              <p>Whose values are we aligning to? How do we handle disagreement?</p>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Complete Pipeline</h4>
          <p>You've now seen every stage of how an LLM is created:</p>
          <div class="complete-pipeline">
            <div class="pipeline-stage">
              <div class="pipe-icon">ðŸ”¤</div>
              <div class="pipe-name">Tokenization</div>
              <div class="pipe-desc">Text â†’ Token IDs</div>
            </div>
            <div class="pipe-arrow">â†’</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">ðŸ“</div>
              <div class="pipe-name">Embeddings</div>
              <div class="pipe-desc">IDs â†’ Vectors</div>
            </div>
            <div class="pipe-arrow">â†’</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">ðŸ§ </div>
              <div class="pipe-name">Transformer</div>
              <div class="pipe-desc">Attention + FFN Ã— N</div>
            </div>
            <div class="pipe-arrow">â†’</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">ðŸŽ“</div>
              <div class="pipe-name">Pre-Training</div>
              <div class="pipe-desc">Random â†’ Capable</div>
            </div>
            <div class="pipe-arrow">â†’</div>
            <div class="pipeline-stage highlight">
              <div class="pipe-icon">ðŸŽ¯</div>
              <div class="pipe-name">Fine-Tuning</div>
              <div class="pipe-desc">Capable â†’ Aligned</div>
            </div>
            <div class="pipe-arrow">â†’</div>
            <div class="pipeline-stage">
              <div class="pipe-icon">ðŸ’¬</div>
              <div class="pipe-name">Inference</div>
              <div class="pipe-desc">Your conversation</div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- CONTEXT & PROMPTING TAB -->
    <section id="tab-prompting" class="tab-section">
      <div class="section-header">
        <h2>ðŸ’¡ Context & Prompting</h2>
        <p>How what you say shapes what the model does â€” and why context windows matter</p>
      </div>

      <!-- Why Prompts Matter Introduction -->
      <div class="context-intro">
        <h3>ðŸŽ¯ Why Prompting Matters</h3>
        <p>You've seen how LLMs work: tokens flow through attention layers, each token influencing what comes next. This is why <strong>what you say</strong> â€” and <strong>how you say it</strong> â€” directly shapes the model's output.</p>
        
        <div class="why-prompts-matter">
          <div class="prompt-reason">
            <strong>ðŸ§  Attention is Key</strong>
            <p>Every word in your prompt gets attention. Clear instructions = clearer attention patterns = better outputs.</p>
          </div>
          <div class="prompt-reason">
            <strong>ðŸ“Š Probability Steering</strong>
            <p>Your prompt shifts which tokens become likely next. "Write formally" makes formal words more probable.</p>
          </div>
          <div class="prompt-reason">
            <strong>ðŸŽ­ Pattern Activation</strong>
            <p>The model learned patterns during training. Good prompts activate the right patterns for your task.</p>
          </div>
          <div class="prompt-reason">
            <strong>ðŸ“ Limited Space</strong>
            <p>Context windows have finite capacity. What you include (or exclude) determines what the model "knows."</p>
          </div>
        </div>
      </div>

      <!-- Context Window Visualizer -->
      <div class="context-window-section">
        <h3>ðŸ“¦ The Context Window Visualized</h3>
        <p>Everything the model "sees" fits inside its context window. System prompts, your messages, and its responses all compete for the same limited space.</p>
        
        <div class="interactive-well">
          <div class="context-visualizer">
            <div class="context-capacity">
              <div class="capacity-bar">
                <div class="capacity-fill" id="context-fill" style="width: 25%"></div>
              </div>
              <span class="capacity-text" id="context-usage">2,048 / 8,192 tokens</span>
            </div>
            
            <div class="context-window-bar" id="context-window">
              <div class="context-segment system">
                <div class="segment-label">System Prompt</div>
                <div class="segment-content">You are a helpful assistant. Be concise and accurate...</div>
              </div>
              <div class="context-segment user">
                <div class="segment-label">User</div>
                <div class="segment-content">What is the capital of France?</div>
              </div>
              <div class="context-segment assistant">
                <div class="segment-label">Assistant</div>
                <div class="segment-content">Paris is the capital of France.</div>
              </div>
            </div>
            
            <div class="context-controls">
              <button class="context-btn" id="ctx-add-system">+ System Prompt</button>
              <button class="context-btn" id="ctx-add-user">+ User Message</button>
              <button class="context-btn" id="ctx-add-long">+ Long Exchange</button>
              <button class="context-btn" id="ctx-overflow">Simulate Overflow</button>
              <button class="context-btn" id="ctx-reset">Reset</button>
            </div>
          </div>
        </div>
      </div>

      <!-- System Prompt Explainer -->
      <div class="system-prompt-card">
        <h3>ðŸ” What Are System Prompts?</h3>
        
        <div class="system-prompt-content">
          <div class="system-what">
            <h4>What They Are</h4>
            <ul>
              <li>Instructions placed at the <strong>beginning</strong> of the context window</li>
              <li>Usually hidden from users in chat interfaces</li>
              <li>Set personality, rules, and constraints for the conversation</li>
              <li>Persist throughout the entire conversation</li>
            </ul>
          </div>
          <div class="system-why">
            <h4>Why They Have Power</h4>
            <ul>
              <li><strong>Positional influence:</strong> Earlier tokens shape attention for later tokens</li>
              <li><strong>Always present:</strong> Every response considers the system prompt</li>
              <li><strong>Training alignment:</strong> Models are fine-tuned to follow system instructions</li>
              <li><strong>Framing effect:</strong> Sets the "mindset" for pattern activation</li>
            </ul>
          </div>
        </div>
        
        <div class="system-example">
          <div class="system-example-label">Example System Prompt (GPT-5.2)</div>
          "You are GPT-5.2, a large language model trained by OpenAI. You are helpful, harmless, and honest. Current date: December 18, 2025. Knowledge cutoff: May 2025."
        </div>
      </div>

      <!-- Input vs Output Tokens -->
      <div class="token-economics">
        <h3>ðŸ’° Input Tokens vs Output Tokens</h3>
        <p>API pricing distinguishes between tokens you send in and tokens the model generates. Here's why:</p>
        
        <div class="token-types-grid">
          <div class="token-type-card input">
            <div class="token-type-header">
              <span class="token-type-icon">ðŸ“¤</span>
              <h4>Input Tokens</h4>
            </div>
            <p>Your prompt, system message, and conversation history</p>
            <ul>
              <li>Processed in <strong>parallel</strong> (fast)</li>
              <li>Single forward pass through the model</li>
              <li>Lower computational cost per token</li>
            </ul>
          </div>
          <div class="token-type-card output">
            <div class="token-type-header">
              <span class="token-type-icon">ðŸ“¥</span>
              <h4>Output Tokens</h4>
            </div>
            <p>The model's response, generated one token at a time</p>
            <ul>
              <li>Generated <strong>sequentially</strong> (slower)</li>
              <li>Each token requires a new forward pass</li>
              <li>Higher computational cost per token</li>
            </ul>
          </div>
        </div>
        
        <div class="cost-comparison">
          <div class="cost-row">
            <span class="cost-label">Typical input token cost (GPT-5.2)</span>
            <span class="cost-value">~$0.00175 / 1K tokens</span>
          </div>
          <div class="cost-row">
            <span class="cost-label">Typical output token cost (GPT-5.2)</span>
            <span class="cost-value">~$0.014 / 1K tokens (8x more!)</span>
          </div>
          <div class="cost-row">
            <span class="cost-label">Why the difference?</span>
            <span class="cost-value">Sequential generation is compute-intensive</span>
          </div>
        </div>
      </div>

      <!-- Prompt Comparison Demo -->
      <div class="prompt-comparison-section">
        <h3>ðŸ”¬ Interactive: Good vs Bad Prompts</h3>
        <p>See how prompt quality affects responses. The same underlying question can get vastly different results.</p>
        
        <div class="prompt-comparison-demo">
          <div class="comparison-toggle">
            <button class="toggle-btn active" id="comp-example-1">Vague vs Specific</button>
            <button class="toggle-btn" id="comp-example-2">No Context vs Context</button>
            <button class="toggle-btn" id="comp-example-3">Implied vs Explicit</button>
          </div>
          
          <div class="comparison-display">
            <div class="comparison-side">
              <h4>âŒ Weaker Prompt</h4>
              <div class="prompt-text" id="weak-prompt">Tell me about Python</div>
              <div class="response-quality">
                <span class="quality-indicator poor"></span>
                <span id="weak-outcome">Generic overview, unclear what you need</span>
              </div>
            </div>
            <div class="comparison-side">
              <h4>âœ“ Stronger Prompt</h4>
              <div class="prompt-text" id="strong-prompt">I'm a beginner learning Python for data analysis. Explain list comprehensions with a practical example using a dataset of sales numbers.</div>
              <div class="response-quality">
                <span class="quality-indicator good"></span>
                <span id="strong-outcome">Targeted explanation with relevant example</span>
              </div>
            </div>
          </div>
          
          <div class="comparison-insight" id="comparison-insight">
            <strong>Why it's better:</strong> The stronger prompt tells the model your skill level (beginner), goal (data analysis), specific topic (list comprehensions), and format (practical example). This activates more relevant patterns and steers probabilities toward useful content.
          </div>
        </div>
      </div>

      <!-- Context Forgetting -->
      <div class="forgetting-section">
        <h3>ðŸ§¹ Why Models "Forget"</h3>
        
        <div class="forgetting-visual">
          <div class="conversation-box">
            <h4>Long Conversation</h4>
            <div class="convo-messages">
              <div class="convo-msg user-msg truncated">User: What's my name?</div>
              <div class="convo-msg assistant-msg truncated">Assistant: You're Alex!</div>
              <div class="convo-msg user-msg truncated">User: I work at...</div>
              <div class="truncation-line">
                <span class="truncation-label">âš ï¸ TRUNCATED</span>
              </div>
              <div class="convo-msg user-msg">User: Remember that project?</div>
              <div class="convo-msg assistant-msg">Assistant: I don't see any previous mention of a project...</div>
            </div>
          </div>
          <div class="conversation-box">
            <h4>New Conversation</h4>
            <div class="convo-messages">
              <div class="convo-msg user-msg">User: Let's continue our chat</div>
              <div class="convo-msg assistant-msg">Assistant: I don't have any record of previous conversations. Each session starts fresh...</div>
            </div>
          </div>
        </div>
        
        <div class="forgetting-note">
          <strong>Key insight:</strong> Models don't "forget" â€” they never had the information in the first place. The context window is like a whiteboard that gets erased. Previous messages that don't fit are simply not there. New conversations start with a completely clean context.
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h3>Understanding Context in Practice</h3>
        <p>Now that you understand the architecture (tokenization â†’ embeddings â†’ attention â†’ generation), you can see why prompting is so important:</p>
        <ul>
          <li><strong>Tokens are the only input:</strong> The model has no other way to know what you want</li>
          <li><strong>Attention is learned:</strong> Good prompts leverage patterns the model learned during pre-training</li>
          <li><strong>Earlier = influential:</strong> System prompts at the start affect everything that follows</li>
          <li><strong>Space is finite:</strong> What fits in the context window is all the model can consider</li>
        </ul>
      </div>

      <!-- Deep Dive -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Prompt Engineering Techniques</h3>
        
        <div class="concept-card">
          <h4>Zero-Shot vs Few-Shot Prompting</h4>
          <p><strong>Zero-shot:</strong> Just ask the question with no examples. Works for simple, common tasks.</p>
          <p><strong>Few-shot:</strong> Provide 2-5 examples of the format you want. The model recognizes the pattern and continues it.</p>
          <div class="system-example">
            <div class="system-example-label">Few-Shot Example</div>
            Classify sentiment:<br>
            "Great product!" â†’ Positive<br>
            "Terrible experience" â†’ Negative<br>
            "It was okay" â†’ Neutral<br>
            "Absolutely loved it!" â†’ ?
          </div>
          <p style="margin-top: 0.75rem; font-size: 0.85rem; color: var(--text-secondary);">The model sees the pattern (text â†’ label) and continues it. Few-shot works because attention helps the model recognize and repeat patterns.</p>
        </div>

        <div class="concept-card">
          <h4>Chain-of-Thought Prompting</h4>
          <p>For complex problems, asking the model to "think step by step" often improves results. Why?</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li>Each reasoning step becomes input for the next step</li>
            <li>More tokens in context = more "working memory"</li>
            <li>Intermediate steps can be attended to for final answer</li>
            <li>Reduces the need to compute complex answers in a single forward pass</li>
          </ul>
          <p style="font-size: 0.85rem; color: var(--text-secondary);">This is why reasoning models (covered in the next tab) are so effective â€” they generate extensive chain-of-thought automatically.</p>
        </div>

        <div class="concept-card">
          <h4>Prompt Structure Matters</h4>
          <p>The order and formatting of your prompt affects attention patterns:</p>
          <div class="grid grid-2-col gap-1 mt-075">
            <div class="card-sm">
              <strong class="text-positive text-sm">âœ“ Good Structure</strong>
              <ul class="mt-05 text-xs" style="padding-left: 1.25rem;">
                <li>Clear task description first</li>
                <li>Relevant context second</li>
                <li>Specific question last</li>
                <li>Use formatting (lists, headers)</li>
              </ul>
            </div>
            <div class="card-sm">
              <strong class="text-negative text-sm">âœ— Poor Structure</strong>
              <ul class="mt-05 text-xs" style="padding-left: 1.25rem;">
                <li>Rambling, stream-of-consciousness</li>
                <li>Important info buried at end</li>
                <li>Mixing multiple questions</li>
                <li>Contradictory instructions</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>The Role of Personas</h4>
          <p>"Act as a senior Python developer" isn't magic â€” it shifts probability distributions toward patterns associated with that expertise in the training data.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">The model learned correlations like "senior developers" â†’ "best practices, error handling, type hints, documentation." Invoking the persona activates these associations.</p>
        </div>
      </div>
    </section>

    <!-- LIMITATIONS & HALLUCINATIONS TAB -->
    <section id="tab-limitations" class="tab-section">
      <div class="section-header">
        <h2>âš ï¸ Limitations & Hallucinations</h2>
        <p>Understanding why models confidently produce incorrect information â€” and how to mitigate it</p>
      </div>

      <!-- Introduction -->
      <div class="limitations-intro">
        <h3>ðŸŽ¯ The Core Problem</h3>
        <p>LLMs are trained to predict <strong>plausible</strong> next tokens, not <strong>true</strong> ones. There's no internal fact-checker, no "I don't know" signal, and no real-time knowledge access. The model generates what <em>sounds right</em> based on patterns.</p>
        
        <div class="key-insight-box">
          <strong>Key Insight:</strong> When a model confidently states false information, it's not lying â€” it's pattern-matching to what typically follows similar prompts. Plausibility â‰  Truth.
        </div>
      </div>

      <!-- What Is a Hallucination -->
      <div class="hallucination-section">
        <h3>ðŸ‘» What Is a Hallucination?</h3>
        <p>A hallucination is when the model generates false information presented as fact. This happens because the model has no way to distinguish between information it learned correctly and patterns it's fabricating.</p>
        
        <div class="hallucination-example">
          <div class="example-qa">
            <div class="example-q">
              <strong>User:</strong> In "To Kill a Mockingbird," what does Scout's teacher Miss Caroline say about the Cunningham family's pride?
            </div>
            <div class="example-a hallucinated">
              <strong>Assistant:</strong> Miss Caroline tells Scout that "The Cunninghams have too much pride to accept charity, but not enough sense to accept help when they need it." She says this during the lunch money incident in chapter 2...
            </div>
          </div>
          <div class="example-verdict">
            <strong>âš ï¸ Hallucination:</strong> While the lunch money scene and Miss Caroline are real, that specific quote doesn't appear in the book. The model generated a plausible-sounding quote that fits the context and themes, but it's fabricated. This is why you should never trust an AI's "quotes" without verification.
          </div>
        </div>

        <h4 style="margin: 1rem 0 0.75rem; font-size: 0.95rem;">Why Hallucinations Happen</h4>
        <div class="hallucination-reasons">
          <div class="reason-card">
            <strong>No "I Don't Know"</strong>
            <p>The model always produces output. It wasn't trained to output uncertainty.</p>
          </div>
          <div class="reason-card">
            <strong>Pattern Completion</strong>
            <p>If "Chapter X of Book Y" is the pattern, it completes it â€” even with fabricated details.</p>
          </div>
          <div class="reason-card">
            <strong>Training Data Gaps</strong>
            <p>Information not in training data gets "filled in" with plausible-sounding patterns.</p>
          </div>
          <div class="reason-card">
            <strong>Confidence â‰  Correctness</strong>
            <p>The probability of generating a token doesn't reflect factual accuracy.</p>
          </div>
        </div>
      </div>

      <!-- Knowledge Cutoff -->
      <div class="cutoff-section">
        <h3>ðŸ“… Knowledge Cutoffs</h3>
        <p>Models are frozen in time. Their knowledge ends at the training data cutoff date. This isn't a bug â€” it's how the architecture works.</p>
        
        <div class="cutoff-timeline">
          <div class="timeline-segment">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Training Data<br><small>Books, Wikipedia, etc.</small></div>
          </div>
          <div class="timeline-segment cutoff">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Knowledge Cutoff<br><small>~May 2025</small></div>
          </div>
          <div class="timeline-segment unknown">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Unknown Zone<br><small>Events after cutoff</small></div>
          </div>
          <div class="timeline-segment unknown">
            <div class="timeline-dot"></div>
            <div class="timeline-label">Today<br><small>Dec 2025</small></div>
          </div>
        </div>
        
        <div class="cutoff-note">
          <strong>Why this matters:</strong> If you ask about the 2024 election results, a model with an April 2024 cutoff will either refuse or potentially hallucinate. The information simply isn't in its weights.
        </div>
      </div>

      <!-- Reasoning Models Section -->
      <div class="reasoning-section">
        <h3>ðŸ§  Standard Models vs Reasoning Models</h3>
        <p>A major advancement in reducing errors: models that "think before answering" by generating reasoning tokens.</p>
        
        <div class="model-comparison">
          <div class="model-type-card standard">
            <div class="model-type-header">
              <span class="model-type-icon">âš¡</span>
              <h4>Standard Models</h4>
            </div>
            <ul>
              <li>Generate responses directly</li>
              <li>Fast, lower cost per query</li>
              <li>Great for simple tasks</li>
              <li>May jump to conclusions on hard problems</li>
            </ul>
            <div class="model-examples">Examples: GPT-4o, Claude 3.5 Sonnet, Gemini Pro</div>
          </div>
          <div class="model-type-card reasoning">
            <div class="model-type-header">
              <span class="model-type-icon">ðŸ§ </span>
              <h4>Reasoning Models</h4>
            </div>
            <ul>
              <li>Generate thinking tokens first, then answer</li>
              <li>Slower, higher cost (more output tokens)</li>
              <li>Much better on complex reasoning</li>
              <li>Can "check their own work"</li>
            </ul>
            <div class="model-examples">Examples: o1, o3-pro, GPT-5.2, Claude with Extended Thinking</div>
          </div>
        </div>
        
        <div class="reasoning-why-works">
          <h4>Why Reasoning Models Work (Architecture Connection)</h4>
          <div class="why-points">
            <div class="why-point">
              <span class="why-point-icon">ðŸ“</span>
              <p><strong>Thinking tokens enter the context window.</strong> The model can attend to its own reasoning.</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">ðŸ”„</span>
              <p><strong>More computation per problem.</strong> Each token is a forward pass; more tokens = more "thinking time."</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">ðŸ”</span>
              <p><strong>Intermediate steps catch errors.</strong> Writing out reasoning exposes flawed logic before the final answer.</p>
            </div>
            <div class="why-point">
              <span class="why-point-icon">ðŸ“Š</span>
              <p><strong>Chain-of-thought as working memory.</strong> Complex problems need more "scratch space."</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Interactive Thinking Demo -->
      <div class="thinking-demo-section">
        <h3>ðŸŽ® See the Difference: Standard vs Reasoning</h3>
        <p>Watch how the same problem gets different treatment. The reasoning model's "thinking" becomes context that helps it arrive at the correct answer.</p>
        
        <div class="interactive-well">
          <div class="thinking-demo">
            <div class="thinking-problem">
              <div class="thinking-problem-label">Problem</div>
              <span id="thinking-problem-text">A bat and ball cost $1.10 total. The bat costs $1.00 more than the ball. How much does the ball cost?</span>
            </div>
            
            <div class="thinking-approaches">
              <div class="approach-panel standard">
                <div class="approach-header">
                  <span>âš¡</span> Standard Model
                </div>
                <div class="approach-content" id="standard-response">
                  <div class="final-answer">
                    The ball costs <span class="answer-incorrect">$0.10</span>
                  </div>
                </div>
              </div>
              
              <div class="approach-panel reasoning">
                <div class="approach-header">
                  <span>ðŸ§ </span> Reasoning Model
                </div>
                <div class="approach-content" id="reasoning-response">
                  <div class="thinking-tokens">
                    <div class="thinking-tokens-label">ðŸ’­ Thinking tokens (in context)</div>
                    <span id="thinking-content">Let me work through this... If ball = x, then bat = x + $1.00. Total: x + (x + $1.00) = $1.10. So 2x = $0.10, meaning x = $0.05.</span>
                  </div>
                  <div class="final-answer">
                    The ball costs <span class="answer-correct">$0.05</span>
                  </div>
                </div>
              </div>
            </div>
            
            <div class="thinking-controls">
              <button class="thinking-btn" id="thinking-problem-1">Bat & Ball Problem</button>
              <button class="thinking-btn" id="thinking-problem-2">Lily Pad Problem</button>
              <button class="thinking-btn" id="thinking-problem-3">Widget Problem</button>
            </div>
            
            <div class="thinking-result" id="thinking-insight">
              <strong>Why the standard model fails:</strong> The intuitive answer ($0.10) "sounds right" and has high probability. Without explicit reasoning, the model follows the path of highest probability â€” which is the common wrong answer humans also give. The reasoning model's thinking tokens let it catch and correct this error.
            </div>
          </div>
        </div>
      </div>

      <!-- Tools & RAG -->
      <div class="tools-section">
        <h3>ðŸ› ï¸ Beyond the Model: Tools That Help</h3>
        <p>Reasoning models aren't the only solution. External tools can ground model outputs in verified information.</p>
        
        <div class="tools-grid">
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">ðŸŒ</span>
              <span class="tool-name">Web Search</span>
            </div>
            <p>Real-time information access. Overcomes knowledge cutoffs by fetching current data and injecting it into context.</p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">ðŸ“š</span>
              <span class="tool-name">RAG</span>
            </div>
            <p><strong>Retrieval-Augmented Generation:</strong> Retrieves relevant documents and includes them in the context window. Grounds responses in actual sources rather than relying on memorized patterns. <em>(We'll explore building RAG systems in depth later.)</em></p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">ðŸ”¢</span>
              <span class="tool-name">Code Execution</span>
            </div>
            <p>For math and logic, let the model write and run code rather than "computing" answers via token prediction.</p>
          </div>
          <div class="tool-card">
            <div class="tool-header">
              <span class="tool-icon">ðŸ”Œ</span>
              <span class="tool-name">APIs & Databases</span>
            </div>
            <p>Connect to authoritative sources: weather APIs, stock prices, databases. Verified data > hallucinated data.</p>
          </div>
        </div>
        
        <div class="tools-insight">
          <strong>Key insight:</strong> These tools don't change the model's architecture â€” they work <em>with</em> the context window by injecting verified information <em>before</em> the model generates its response. The model is still predicting tokens; it just has better context to work with.
        </div>
      </div>

      <!-- Other Limitations -->
      <div class="other-limitations">
        <h3>ðŸš§ Other Common Limitations</h3>
        
        <div class="limitations-grid">
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">ðŸ”¢</span>
              <strong>Math & Counting</strong>
            </div>
            <p>Tokenization splits numbers unpredictably. "123" might be one token or multiple. The model isn't "doing math" â€” it's predicting likely digits.</p>
            <div class="limitation-example">Q: How many r's in "strawberry"?<br>A: 2 (Legacy models) <br><em>Note: GPT-5.2 solves this via native reasoning.</em></div>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">ðŸªž</span>
              <strong>Sycophancy</strong>
            </div>
            <p>Models tend to agree with users, even when wrong. RLHF optimized for "helpfulness" which can mean "telling you what you want to hear."</p>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">ðŸ§©</span>
              <strong>Novel Reasoning</strong>
            </div>
            <p>Problems unlike anything in training data are hard. The model relies on pattern recognition â€” truly novel problems have no patterns to match.</p>
          </div>
          <div class="limitation-card">
            <div class="limitation-header">
              <span class="limitation-icon">ðŸ“</span>
              <strong>Spatial Reasoning</strong>
            </div>
            <p>Text doesn't naturally encode spatial relationships. Tasks involving 3D visualization, rotations, or physical intuition are challenging.</p>
          </div>
        </div>
      </div>

      <!-- Explanation -->
      <div class="explanation">
        <h3>Living With Limitations</h3>
        <p>Understanding <em>why</em> these limitations exist helps you work around them:</p>
        <ul>
          <li><strong>Verify important facts:</strong> The model's confidence isn't correlated with accuracy</li>
          <li><strong>Use the right model:</strong> Reasoning models for complex problems, standard for simple tasks</li>
          <li><strong>Augment with tools:</strong> Web search, RAG, and code execution reduce hallucinations</li>
          <li><strong>Prompt for uncertainty:</strong> Ask the model to express when it's unsure</li>
          <li><strong>Check recent events:</strong> Be aware of knowledge cutoff dates</li>
        </ul>
      </div>

      <!-- Deep Dive -->
      <div class="deep-dive">
        <h3 class="deep-dive-title">ðŸ”¬ Going Deeper on Limitations</h3>
        
        <div class="concept-card">
          <h4>The Calibration Problem</h4>
          <p>Ideally, when a model says "I'm 80% confident," it should be correct 80% of the time. In practice, LLMs are often <strong>overconfident</strong> â€” they express high certainty even for things they're wrong about.</p>
          <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 0.5rem;">This happens because training optimized for confident-sounding text, not calibrated probabilities. The model learned that authoritative-sounding responses get positive feedback.</p>
        </div>

        <div class="concept-card">
          <h4>Why Reasoning Models Can't Solve Everything</h4>
          <p>Even with extended thinking, models have fundamental limits:</p>
          <ul style="margin: 0.75rem 0; padding-left: 1.5rem; font-size: 0.85rem;">
            <li><strong>Still pattern matching:</strong> Reasoning tokens don't create new knowledge</li>
            <li><strong>Training data ceiling:</strong> Can't reason about things never encountered</li>
            <li><strong>Computational limits:</strong> Some problems are just too hard to "think through"</li>
            <li><strong>Cost tradeoff:</strong> More thinking = more tokens = higher cost</li>
          </ul>
        </div>

        <div class="concept-card">
          <h4>Grounding: The Key to Reliability</h4>
          <p>The most reliable LLM applications <strong>ground</strong> the model's output in verified sources:</p>
          <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 0.75rem; margin-top: 0.75rem;">
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>RAG</strong><br><small>Retrieved documents</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Tool Use</strong><br><small>API responses</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Code</strong><br><small>Executable verification</small>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.5rem; border-radius: var(--radius-sm); text-align: center; font-size: 0.8rem;">
              <strong>Citations</strong><br><small>Source attribution</small>
            </div>
          </div>
        </div>

        <div class="concept-card">
          <h4>When to Trust, When to Verify</h4>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin-top: 0.75rem;">
            <div style="background: var(--bg-elevated); padding: 0.75rem; border-radius: var(--radius-sm);">
              <strong style="color: var(--positive); font-size: 0.85rem;">âœ“ Higher Trust</strong>
              <ul style="margin: 0.5rem 0 0; padding-left: 1.25rem; font-size: 0.75rem;">
                <li>Common knowledge, well-documented topics</li>
                <li>General patterns and concepts</li>
                <li>Creative tasks with no "correct" answer</li>
                <li>Explanations of well-known facts</li>
              </ul>
            </div>
            <div style="background: var(--bg-elevated); padding: 0.75rem; border-radius: var(--radius-sm);">
              <strong style="color: var(--negative); font-size: 0.85rem;">âš ï¸ Verify Carefully</strong>
              <ul style="margin: 0.5rem 0 0; padding-left: 1.25rem; font-size: 0.75rem;">
                <li>Specific facts, numbers, dates</li>
                <li>Recent events (after cutoff)</li>
                <li>Niche or specialized domains</li>
                <li>Legal, medical, financial advice</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>
    </main>
  </div>

<script>
// ============ UTILITIES ============
function clamp(val, min, max) {
  return Math.min(max, Math.max(min, val));
}

function lerp(a, b, t) {
  return a + (b - a) * t;
}

// ============ TAB NAVIGATION ============
// Global render functions for tab switching
const tabRenders = {};

function setupTabs() {
  const buttons = document.querySelectorAll('.tab-btn');
  const sections = document.querySelectorAll('.tab-section');
  
  buttons.forEach(btn => {
    btn.addEventListener('click', () => {
      const tab = btn.dataset.tab;
      
      buttons.forEach(b => b.classList.remove('active'));
      btn.classList.add('active');
      
      sections.forEach(s => {
        s.classList.toggle('active', s.id === `tab-${tab}`);
      });

      // Comprehensive scroll reset
      window.scrollTo(0, 0);
      document.body.scrollTop = 0;
      document.documentElement.scrollTop = 0;
      const mainContent = document.querySelector('.main-content');
      if (mainContent) mainContent.scrollTop = 0;
      
      // Trigger render for the newly visible tab after a brief delay
      // to ensure the tab is visible and has dimensions
      setTimeout(() => {
        if (tabRenders[tab]) {
          tabRenders[tab]();
        }
      }, 100);
    });
  });
}

// ============ INFERENCE SIMULATION ============
function setupInference() {
  // State
  const basePrompt = "The best way to learn is";
  let currentText = basePrompt;
  let generatedTokens = [];
  let isAutoGenerating = false;
  let autoGenerateInterval = null;
  let stepCount = 0;

  // Pre-defined generation sequence for demo
  const generationSequence = [
    { token: " by", probs: [
      { token: " by", prob: 0.42 },
      { token: " through", prob: 0.28 },
      { token: " from", prob: 0.15 },
      { token: " with", prob: 0.10 },
      { token: " in", prob: 0.05 },
      { token: " potato", prob: 0.02 },
      { token: " 7", prob: 0.02 },
      { token: " ???", prob: 0.02 }
    ]},
    { token: " doing", probs: [
      { token: " doing", prob: 0.38 },
      { token: " practicing", prob: 0.28 },
      { token: " experimenting", prob: 0.18 },
      { token: " making", prob: 0.10 },
      { token: " building", prob: 0.06 },
      { token: " purple", prob: 0.02 },
      { token: " [REDACTED]", prob: 0.02 },
      { token: " ERROR", prob: 0.02 }
    ]},
    { token: ".", probs: [
      { token: ".", prob: 0.55 },
      { token: " and", prob: 0.20 },
      { token: ",", prob: 0.12 },
      { token: " things", prob: 0.08 },
      { token: " it", prob: 0.05 },
      { token: " banana", prob: 0.02 },
      { token: " (unintelligible)", prob: 0.02 },
      { token: " !!1!", prob: 0.02 }
    ]},
    { token: " practice", probs: [
      { token: " practice", prob: 0.35 },
      { token: " hands", prob: 0.25 },
      { token: " this", prob: 0.18 },
      { token: " real", prob: 0.14 },
      { token: " active", prob: 0.08 },
      { token: " meow", prob: 0.02 },
      { token: " 010101", prob: 0.02 },
      { token: " glitch", prob: 0.02 }
    ]},
    { token: " makes", probs: [
      { token: " makes", prob: 0.50 },
      { token: " builds", prob: 0.22 },
      { token: " creates", prob: 0.15 },
      { token: " leads", prob: 0.08 },
      { token: " brings", prob: 0.05 },
      { token: " destroys", prob: 0.02 },
      { token: " vibrates", prob: 0.02 },
      { token: " null", prob: 0.02 }
    ]},
    { token: " perfect", probs: [
      { token: " perfect", prob: 0.72 },
      { token: " progress", prob: 0.12 },
      { token: " mastery", prob: 0.08 },
      { token: " improvement", prob: 0.05 },
      { token: " it", prob: 0.02 },
      { token: " ham", prob: 0.02 },
      { token: " undefined", prob: 0.02 },
      { token: " recursive", prob: 0.02 }
    ]},
    { token: ".", probs: [
      { token: ".", prob: 0.78 },
      { token: "!", prob: 0.12 },
      { token: ",", prob: 0.06 },
      { token: " and", prob: 0.03 },
      { token: "...", prob: 0.01 },
      { token: " ?????", prob: 0.02 },
      { token: " </html>", prob: 0.02 },
      { token: " <EOF>", prob: 0.02 }
    ]},
    { token: "<|end|>", probs: [
      { token: "<|end|>", prob: 0.85 },
      { token: " So", prob: 0.08 },
      { token: " The", prob: 0.04 },
      { token: " Start", prob: 0.02 },
      { token: " Don", prob: 0.01 },
      { token: " help", prob: 0.02 },
      { token: " loop", prob: 0.02 },
      { token: " (static noise)", prob: 0.02 }
    ]}
  ];

  // DOM Elements
  const promptDisplay = document.getElementById('inference-prompt');
  const pipelineInput = document.getElementById('pipeline-input');
  const pipelineOutput = document.getElementById('pipeline-output');
  const pipelineModel = document.getElementById('pipeline-model');
  const tokenProbList = document.getElementById('token-prob-list');
  const tempSlider = document.getElementById('inf-temperature');
  const tempVal = document.getElementById('inf-temp-val');
  const tempVizBar = document.getElementById('temp-viz-bar');
  const tempDescription = document.getElementById('temp-description');
  const stepBtn = document.getElementById('inf-step-btn');
  const autoBtn = document.getElementById('inf-auto-btn');
  const resetBtn = document.getElementById('inf-reset-btn');
  const statsDiv = document.getElementById('generation-stats');
  const statTokens = document.getElementById('stat-tokens');
  const statSteps = document.getElementById('stat-steps');
  const loopViz = document.getElementById('loop-visualization');

  // Apply temperature to probabilities
  function applyTemperature(probs, temperature) {
    if (temperature === 0) {
      // At temp 0, all probability goes to the top token
      return probs.map((p, i) => ({ ...p, adjustedProb: i === 0 ? 1 : 0 }));
    }
    
    // Convert base probabilities to logits
    // We use a larger range for logits to make temperature effects more pronounced
    const logits = probs.map(p => Math.log(p.prob) * 2); 
    const scaledLogits = logits.map(l => l / temperature);
    const maxLogit = Math.max(...scaledLogits);
    const expLogits = scaledLogits.map(l => Math.exp(l - maxLogit));
    const sumExp = expLogits.reduce((a, b) => a + b, 0);
    const newProbs = expLogits.map(e => e / sumExp);
    
    return probs.map((p, i) => ({ ...p, adjustedProb: newProbs[i] }));
  }

  // Sample from distribution based on temperature
  function sampleToken(probs, temperature) {
    const adjusted = applyTemperature(probs, temperature);
    
    if (temperature === 0) {
      return adjusted[0];
    }
    
    const rand = Math.random();
    let cumulative = 0;
    for (const p of adjusted) {
      cumulative += p.adjustedProb;
      if (rand < cumulative) {
        return p;
      }
    }
    return adjusted[adjusted.length - 1];
  }

  // Update temperature visualization
  function updateTempVisualization() {
    const temp = parseFloat(tempSlider.value);
    tempVal.textContent = temp.toFixed(1);
    
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    const probs = generationSequence[currentStep].probs;
    const adjusted = applyTemperature(probs, temp);
    
    // Update viz bar
    tempVizBar.innerHTML = adjusted.map((p, i) => {
      const colors = ['var(--accent-primary)', 'var(--accent-cool)', 'var(--accent-secondary)', 'var(--accent-warm)', 'var(--accent-pink)', 'var(--accent-cool)', 'var(--accent-secondary)', 'var(--accent-warm)'];
      const width = Math.max(p.adjustedProb * 100, 2); // minimum 2% for visibility
      return `<div class="temp-viz-segment" style="flex: ${width}; background: ${colors[i % colors.length] || 'var(--text-muted)'}; font-size: ${width > 15 ? '0.7rem' : '0.5rem'}">${p.token}</div>`;
    }).join('');
    
    // Update description
    if (temp === 0) {
      tempDescription.textContent = "Deterministic: Always picks the highest probability token";
    } else if (temp < 0.5) {
      tempDescription.textContent = "Very focused: Strongly favors high-probability tokens";
    } else if (temp < 1) {
      tempDescription.textContent = "Balanced: Mostly picks likely tokens, occasionally surprises";
    } else if (temp === 1) {
      tempDescription.textContent = "Natural: Samples directly from the model's distribution";
    } else if (temp < 1.5) {
      tempDescription.textContent = "Creative: More likely to pick unexpected tokens";
    } else {
      tempDescription.textContent = "Chaotic: Almost random, often produces nonsense";
    }
  }

  // Update probability display
  function updateProbDisplay(probs, selectedToken) {
    const temp = parseFloat(tempSlider.value);
    const adjusted = applyTemperature(probs, temp);
    
    tokenProbList.innerHTML = adjusted.map((p, i) => {
      const isSelected = p.token === selectedToken;
      const barWidth = p.adjustedProb * 100;
      return `
        <div class="token-prob-item ${isSelected ? 'selected' : 'alternative'}">
          <span class="token-prob-rank">${i + 1}</span>
          <span class="token-prob-token">"${p.token}"</span>
          <div class="token-prob-bar-container">
            <div class="token-prob-bar" style="width: ${barWidth}%"></div>
          </div>
          <span class="token-prob-percent">${(p.adjustedProb * 100).toFixed(0)}%</span>
        </div>
      `;
    }).join('');
  }

  // Update the loop visualization
  function updateLoopVisualization() {
    const steps = [
      { label: "Input prompt", tokens: `"${basePrompt}"`, isBase: true }
    ];
    
    let accumulated = basePrompt;
    for (let i = 0; i < generatedTokens.length; i++) {
      accumulated += generatedTokens[i];
      const isStop = generatedTokens[i] === "<|end|>";
      steps.push({
        label: `After ${i + 1}${getOrdinalSuffix(i + 1)} inference â†’ predicts "${generatedTokens[i]}"`,
        tokens: accumulated,
        newToken: generatedTokens[i],
        isStop: isStop
      });
    }
    
    // Show what's next if not complete
    if (generatedTokens.length < generationSequence.length && !generatedTokens.includes("<|end|>")) {
      const nextStep = generationSequence[generatedTokens.length];
      steps.push({
        label: `Next prediction...`,
        tokens: accumulated + "?",
        isPending: true
      });
    }
    
    loopViz.innerHTML = steps.map((step, i) => {
      const isActive = i === generatedTokens.length && !generatedTokens.includes("<|end|>");
      const isCompleted = i < generatedTokens.length || step.isBase;
      
      let tokensHtml = `"${step.tokens.replace(basePrompt, basePrompt)}"`;
      if (step.newToken && !step.isStop) {
        const before = step.tokens.slice(0, -step.newToken.length);
        tokensHtml = `"${before}<span class="new-token">${step.newToken}</span>"`;
      }
      if (step.isStop) {
        tokensHtml = `"${step.tokens.replace('<|end|>', '')}" <span class="stop-token">&lt;|end|&gt;</span>`;
      }
      if (step.isPending) {
        tokensHtml = `"${step.tokens.replace('?', '<span class="new-token">?</span>')}"`;
      }
      
      const stepNumber = step.isStop ? 'âœ“' : (i + 1);
      
      return `
        ${i > 0 ? `<div class="loop-arrow${i === generatedTokens.length && !generatedTokens.includes("<|end|>") ? ' feedback' : ''}">â†“</div>` : ''}
        <div class="loop-step ${isActive ? 'active' : ''} ${isCompleted ? 'completed' : ''}">
          <div class="loop-step-number">${stepNumber}</div>
          <div class="loop-step-content">
            <div class="loop-step-label">${step.label}</div>
            <div class="loop-step-tokens">${tokensHtml}</div>
          </div>
        </div>
      `;
    }).join('');
  }

  function getOrdinalSuffix(n) {
    const j = n % 10, k = n % 100;
    if (j === 1 && k !== 11) return "st";
    if (j === 2 && k !== 12) return "nd";
    if (j === 3 && k !== 13) return "rd";
    return "th";
  }

  // Update display
  function updateDisplay() {
    // Update prompt display
    let displayText = basePrompt;
    if (generatedTokens.length > 0) {
      const genText = generatedTokens.filter(t => t !== "<|end|>").join('');
      displayText = basePrompt + `<span class="generated">${genText}</span>`;
    }
    
    const isComplete = generatedTokens.includes("<|end|>");
    promptDisplay.innerHTML = displayText + (isComplete ? '' : '<span class="cursor"></span>');
    
    // Update pipeline input (show last few tokens)
    const fullText = basePrompt + generatedTokens.filter(t => t !== "<|end|>").join('');
    const lastPart = fullText.length > 15 ? '..."' + fullText.slice(-12) + '"' : '"' + fullText + '"';
    pipelineInput.textContent = lastPart;
    
    // Update pipeline output and probs
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    const nextToken = generationSequence[currentStep];
    
    if (isComplete) {
      pipelineOutput.innerHTML = '<span style="color: var(--accent-warm)">STOP</span>';
    } else {
      pipelineOutput.textContent = `"${nextToken.token}"`;
    }
    
    updateProbDisplay(nextToken.probs, nextToken.token);
    updateTempVisualization();
    updateLoopVisualization();
    
    // Update stats
    if (generatedTokens.length > 0) {
      statsDiv.style.display = 'flex';
      statTokens.textContent = generatedTokens.length;
      statSteps.textContent = stepCount;
    } else {
      statsDiv.style.display = 'none';
    }
    
    // Update button states
    const canGenerate = !isComplete && stepCount < generationSequence.length;
    stepBtn.disabled = !canGenerate;
    autoBtn.disabled = !canGenerate;
  }

  // Generate next token
  function generateNext() {
    if (stepCount >= generationSequence.length) return;
    if (generatedTokens.includes("<|end|>")) return;
    
    const step = generationSequence[stepCount];
    const temp = parseFloat(tempSlider.value);
    
    // Animate the pipeline
    pipelineModel.classList.add('active');
    setTimeout(() => {
      pipelineModel.classList.remove('active');
      
      // Sample token based on temperature
      const sampled = sampleToken(step.probs, temp);
      
      // Determine token casing based on previous token
      let tokenValue = sampled.token;
      if (generatedTokens.length > 0) {
        const lastToken = generatedTokens[generatedTokens.length - 1].trim();
        const sentenceEnders = ['.', '!', '?', '<|endoftext|>'];
        if (sentenceEnders.includes(lastToken)) {
          // Capitalize if it's the start of a new sentence
          tokenValue = tokenValue.charAt(0) === ' ' 
            ? ' ' + tokenValue.trim().charAt(0).toUpperCase() + tokenValue.trim().slice(1)
            : tokenValue.charAt(0).toUpperCase() + tokenValue.slice(1);
        }
      } else {
        // First generated token follows "is" (from basePrompt), so it stays lowercase
      }

      generatedTokens.push(tokenValue);
      stepCount++;
      
      // Update probability display with actual selected token
      updateProbDisplay(step.probs, sampled.token);
      updateDisplay();
      
      // Check if we hit stop token
      if (sampled.token === "<|end|>") {
        stopAutoGenerate();
      }
    }, 300);
  }

  // Auto-generate
  function startAutoGenerate() {
    if (isAutoGenerating) return;
    isAutoGenerating = true;
    autoBtn.innerHTML = '<span>â¸</span> Pause';
    
    autoGenerateInterval = setInterval(() => {
      if (stepCount >= generationSequence.length || generatedTokens.includes("<|end|>")) {
        stopAutoGenerate();
        return;
      }
      generateNext();
    }, 800);
  }

  function stopAutoGenerate() {
    isAutoGenerating = false;
    autoBtn.innerHTML = '<span>â©</span> Auto-Generate';
    if (autoGenerateInterval) {
      clearInterval(autoGenerateInterval);
      autoGenerateInterval = null;
    }
  }

  // Reset
  function reset() {
    stopAutoGenerate();
    currentText = basePrompt;
    generatedTokens = [];
    stepCount = 0;
    updateDisplay();
  }

  // Event listeners
  tempSlider.addEventListener('input', () => {
    updateTempVisualization();
    // Re-render prob display with new temperature
    const currentStep = Math.min(stepCount, generationSequence.length - 1);
    updateProbDisplay(generationSequence[currentStep].probs, generationSequence[currentStep].token);
  });

  stepBtn.addEventListener('click', generateNext);
  
  autoBtn.addEventListener('click', () => {
    if (isAutoGenerating) {
      stopAutoGenerate();
    } else {
      startAutoGenerate();
    }
  });
  
  resetBtn.addEventListener('click', reset);

  // Initial render
  updateDisplay();
}

// ============ NEURAL NETWORK VISUALIZATION ============
function setupNeuralNetwork() {
  const canvas = document.getElementById('nn-canvas');
  const ctx = canvas.getContext('2d');
  const dpr = window.devicePixelRatio || 1;
  
  // Track if initialized with proper dimensions
  let initialized = false;
  let W = 0;
  let H = 0;
  let layers = [];
  
  // Pre-trained weights for meaningful behavior
  // These weights make the network respond sensibly to the semantic inputs
  const weights = {
    // Input (4) -> Hidden (4) weights
    // Inputs: royalty, military, gender, formality
    ih: [
      [1.5, 0.2, 1.3, 0.4],   // h0: royalty + masculine detector â†’ king
      [0.3, 1.6, 0.2, -0.3],  // h1: military detector â†’ general
      [1.5, 0.2, -1.3, 0.4],  // h2: royalty + feminine detector â†’ queen
      [0.6, 0.4, 0.0, 1.2]    // h3: formality detector â†’ boosts royalty
    ],
    // Hidden (4) -> Output (3) weights
    // Outputs: king, general, queen
    ho: [
      [1.6, -0.4, -0.6, 0.5], // "king": h0 (royal+masc), suppressed by h2, boosted by formality
      [-0.3, 1.8, -0.3, -0.2],// "general": h1 (military), less formal
      [-0.6, -0.4, 1.6, 0.5]  // "queen": h2 (royal+fem), suppressed by h0, boosted by formality
    ]
  };
  
  function initCanvas() {
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    canvas.style.width = rect.width + 'px';
    canvas.style.height = rect.height + 'px';
    
    W = rect.width;
    H = rect.height;
    
    const inputLabels = ['roy', 'mil', 'gen', 'frml'];
    const hiddenLabels = ['hâ‚', 'hâ‚‚', 'hâ‚ƒ', 'hâ‚„'];
    const outputLabels = ['king', 'general', 'queen'];
    
    // Node positions - 4 inputs, 4 hidden, 3 outputs
    layers = [
      // Input layer (4 nodes)
      inputLabels.map((label, i) => ({
        x: W * 0.12,
        y: H * (0.15 + i * 0.22),
        label: label,
        type: 'input'
      })),
      // Hidden layer (4 nodes)
      hiddenLabels.map((label, i) => ({
        x: W * 0.5,
        y: H * (0.15 + i * 0.22),
        label: label,
        type: 'hidden'
      })),
      // Output layer (3 nodes)
      outputLabels.map((label, i) => ({
        x: W * 0.88,
        y: H * (0.22 + i * 0.28),
        label: label,
        type: 'output'
      }))
    ];
    
    initialized = true;
    return true;
  }
  
  const sliders = {
    x1: document.getElementById('nn-x1'),
    x2: document.getElementById('nn-x2'),
    x3: document.getElementById('nn-x3'),
    x4: document.getElementById('nn-x4')
  };
  
  const valueDisplays = {
    x1: document.getElementById('nn-x1-val'),
    x2: document.getElementById('nn-x2-val'),
    x3: document.getElementById('nn-x3-val'),
    x4: document.getElementById('nn-x4-val')
  };
  
  const outputDisplays = {
    out1: document.getElementById('nn-out1'),
    out2: document.getElementById('nn-out2'),
    out3: document.getElementById('nn-out3')
  };
  
  const outputBars = {
    out1: document.getElementById('nn-out1-bar'),
    out2: document.getElementById('nn-out2-bar'),
    out3: document.getElementById('nn-out3-bar')
  };
  
  function getInputs() {
    return [
      parseFloat(sliders.x1.value),
      parseFloat(sliders.x2.value),
      parseFloat(sliders.x3.value),
      parseFloat(sliders.x4.value)
    ];
  }
  
  function computeNetwork(inputs) {
    // Hidden layer
    const hidden = [];
    for (let h = 0; h < 4; h++) {
      let sum = 0;
      for (let i = 0; i < 4; i++) {
        sum += inputs[i] * weights.ih[h][i];
      }
      hidden.push(Math.tanh(sum));
    }
    
    // Output layer (softmax for probabilities)
    const outputRaw = [];
    for (let o = 0; o < 3; o++) {
      let sum = 0;
      for (let h = 0; h < 4; h++) {
        sum += hidden[h] * weights.ho[o][h];
      }
      outputRaw.push(sum);
    }
    
    // Softmax
    const maxOut = Math.max(...outputRaw);
    const expOut = outputRaw.map(x => Math.exp(x - maxOut));
    const sumExp = expOut.reduce((a, b) => a + b, 0);
    const outputs = expOut.map(x => x / sumExp);
    
    return { inputs, hidden, outputs, outputRaw };
  }
  
  function getWeightColor(weight) {
    if (weight >= 0) {
      const intensity = Math.min(1, Math.abs(weight) / 2);
      return `rgba(34, 197, 94, ${0.15 + intensity * 0.5})`;
    } else {
      const intensity = Math.min(1, Math.abs(weight) / 2);
      return `rgba(239, 68, 68, ${0.15 + intensity * 0.5})`;
    }
  }
  
  function getWeightWidth(weight) {
    return 1 + Math.abs(weight) * 1.5;
  }
  
  function getActivationColor(value) {
    const normalized = (value + 1) / 2;
    const brightness = 25 + normalized * 55;
    return `hsl(168, 80%, ${brightness}%)`;
  }
  
  function drawConnection(from, to, weight) {
    ctx.beginPath();
    ctx.moveTo(from.x, from.y);
    ctx.lineTo(to.x, to.y);
    ctx.strokeStyle = getWeightColor(weight);
    ctx.lineWidth = getWeightWidth(weight);
    ctx.lineCap = 'round';
    ctx.stroke();
  }
  
  function drawNode(node, value, isActive = false) {
    const radius = node.type === 'output' ? 28 : 22;
    
    // Glow effect for active nodes
    if (isActive && Math.abs(value) > 0.1) {
      const gradient = ctx.createRadialGradient(node.x, node.y, radius, node.x, node.y, radius * 1.8);
      gradient.addColorStop(0, value > 0 ? 'rgba(0, 212, 170, 0.25)' : 'rgba(239, 68, 68, 0.25)');
      gradient.addColorStop(1, 'transparent');
      ctx.fillStyle = gradient;
      ctx.beginPath();
      ctx.arc(node.x, node.y, radius * 1.8, 0, Math.PI * 2);
      ctx.fill();
    }
    
    // Node circle
    ctx.beginPath();
    ctx.arc(node.x, node.y, radius, 0, Math.PI * 2);
    
    if (node.type === 'input') {
      const inputIntensity = (value + 1) / 2;
      ctx.fillStyle = `rgba(30, 58, 95, ${0.5 + inputIntensity * 0.5})`;
      ctx.strokeStyle = '#3b82f6';
    } else if (node.type === 'hidden') {
      // Gray fill for hidden nodes - activation shown via glow
      ctx.fillStyle = '#374151';
      ctx.strokeStyle = '#6b7280';
    } else {
      // Output - use value as probability (0-1)
      const intensity = Math.min(1, value * 2);
      ctx.fillStyle = `rgba(0, 212, 170, ${0.1 + intensity * 0.4})`;
      ctx.strokeStyle = intensity > 0.3 ? '#00d4aa' : '#64748b';
    }
    
    ctx.lineWidth = 2;
    ctx.fill();
    ctx.stroke();
    
    // Label
    ctx.fillStyle = '#f8fafc';
    ctx.font = node.type === 'output' ? 'bold 11px "DM Sans"' : 'bold 10px "DM Sans"';
    ctx.textAlign = 'center';
    ctx.textBaseline = 'middle';
    ctx.fillText(node.label, node.x, node.y);
  }
  
  function render() {
    if (!initialized || W === 0) {
      if (!initCanvas()) return;
    }
    
    const inputs = getInputs();
    const result = computeNetwork(inputs);
    
    // Update input value displays
    valueDisplays.x1.textContent = inputs[0].toFixed(2);
    valueDisplays.x2.textContent = inputs[1].toFixed(2);
    valueDisplays.x3.textContent = inputs[2].toFixed(2);
    valueDisplays.x4.textContent = inputs[3].toFixed(2);
    
    // Update output displays
    outputDisplays.out1.textContent = result.outputs[0].toFixed(2);
    outputDisplays.out2.textContent = result.outputs[1].toFixed(2);
    outputDisplays.out3.textContent = result.outputs[2].toFixed(2);
    
    // Update output bars
    outputBars.out1.style.width = (result.outputs[0] * 100) + '%';
    outputBars.out2.style.width = (result.outputs[1] * 100) + '%';
    outputBars.out3.style.width = (result.outputs[2] * 100) + '%';
    
    // Clear canvas
    ctx.clearRect(0, 0, W, H);
    
    // Draw layer labels
    ctx.fillStyle = '#64748b';
    ctx.font = '12px "DM Sans", sans-serif';
    ctx.textAlign = 'center';
    ctx.fillText('Embedding Dims', W * 0.12, 22);
    ctx.fillText('Pattern Detectors', W * 0.5, 22);
    ctx.fillText('Token Probs', W * 0.88, 22);
    
    // Draw all connections (input -> hidden)
    for (let i = 0; i < 4; i++) {
      for (let h = 0; h < 4; h++) {
        drawConnection(layers[0][i], layers[1][h], weights.ih[h][i]);
      }
    }
    
    // Draw all connections (hidden -> output)
    for (let h = 0; h < 4; h++) {
      for (let o = 0; o < 3; o++) {
        drawConnection(layers[1][h], layers[2][o], weights.ho[o][h]);
      }
    }
    
    // Draw input nodes
    for (let i = 0; i < 4; i++) {
      drawNode(layers[0][i], inputs[i], false);
    }
    
    // Draw hidden nodes
    for (let h = 0; h < 4; h++) {
      drawNode(layers[1][h], result.hidden[h], true);
    }
    
    // Draw output nodes
    for (let o = 0; o < 3; o++) {
      drawNode(layers[2][o], result.outputs[o], true);
    }
  }
  
  // Event listeners
  Object.values(sliders).forEach(slider => {
    if (slider) slider.addEventListener('input', render);
  });
  
  // Handle resize
  window.addEventListener('resize', () => {
    initialized = false;
    render();
  });
  
  // Register for tab switching
  tabRenders['nn'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ TOKENIZER ============
function setupTokenizer() {
  const input = document.getElementById('tok-input');
  const btn = document.getElementById('tok-btn');
  const tokensDiv = document.getElementById('tok-tokens');
  const idsDiv = document.getElementById('tok-ids');
  
  // Simulated BPE vocabulary - common subwords and their token IDs
  // In real models like GPT-4, this would be ~100k entries
  const bpeVocab = {'<|endoftext|>': 0, ' ': 220, '.': 13, ',': 11, '!': 0, '?': 30, "'": 6, '"': 1, '-': 12, ':': 25, ';': 26, 'the': 1169, 'The': 464, 'a': 64, 'A': 32, 'an': 272, 'is': 318, 'are': 533, 'was': 373, 'be': 1350, 'to': 284, 'of': 286, 'and': 290, 'in': 287, 'that': 326, 'it': 270, 'for': 329, 'on': 319, 'with': 351, 'as': 355, 'at': 379, 'by': 416, 'from': 422, 'or': 393, 'but': 475, 'not': 407, 'this': 428, 'they': 484, 'we': 356, 'you': 345, 'have': 423, 'has': 468, 'had': 550, 'do': 466, 'does': 857, 'did': 750, 'will': 481, 'would': 561, 'could': 714, 'should': 815, 'can': 460, 'may': 743, 'might': 1244, 'must': 1276, 'say': 910, 'said': 531, 'says': 1139, 'go': 748, 'going': 1016, 'goes': 2925, 'went': 1816, 'get': 651, 'got': 1392, 'gets': 3011, 'make': 1205, 'made': 925, 'makes': 1838, 'know': 760, 'known': 1900, 'knows': 4206, 'think': 892, 'thought': 1807, 'see': 766, 'seen': 1775, 'sees': 7224, 'come': 2063, 'came': 1625, 'comes': 2058, 'want': 765, 'wanted': 2227, 'wants': 3382, 'use': 779, 'used': 973, 'uses': 3544, 'using': 1262, 'find': 1064, 'found': 1043, 'give': 1577, 'gave': 2921, 'given': 1813, 'tell': 1560, 'told': 1297, 'work': 670, 'works': 2499, 'worked': 3111, 'working': 1762, 'call': 1444, 'called': 1444, 'try': 1949, 'tried': 3088, 'need': 761, 'needs': 2476, 'feel': 1254, 'feels': 5300, 'become': 1716, 'becomes': 4329, 'leave': 2666, 'left': 1364, 'put': 1234, 'puts': 7584, 'mean': 1612, 'means': 1724, 'keep': 1394, 'kept': 4030, 'let': 1616, 'lets': 8341, 'begin': 3823, 'began': 2540, 'seem': 1283, 'seems': 2331, 'help': 1037, 'helped': 5710, 'helps': 5765, 'helping': 5765, 'show': 905, 'shows': 2523, 'showed': 4894, 'hear': 3285, 'heard': 2982, 'play': 1110, 'played': 2826, 'plays': 5765, 'run': 1057, 'runs': 4539, 'running': 2491, 'move': 1445, 'moved': 3888, 'moves': 6100, 'live': 2107, 'lived': 5615, 'lives': 3268, 'world': 995, 'people': 661, 'time': 640, 'year': 614, 'years': 812, 'way': 636, 'day': 820, 'days': 1528, 'man': 582, 'men': 1450, 'woman': 2415, 'women': 1466, 'child': 1200, 'children': 1717, 'life': 897, 'hand': 1021, 'hands': 2832, 'part': 636, 'place': 1295, 'case': 1339, 'week': 1285, 'company': 1664, 'system': 1080, 'program': 1430, 'question': 1808, 'government': 2067, 'number': 1271, 'night': 1755, 'point': 966, 'home': 1363, 'water': 1660, 'room': 2119, 'mother': 2802, 'area': 1989, 'money': 1637, 'story': 1621, 'fact': 1109, 'month': 1227, 'lot': 1256, 'right': 826, 'study': 2050, 'book': 1492, 'eye': 2951, 'eyes': 2951, 'job': 1693, 'word': 1573, 'words': 2456, 'business': 1597, 'issue': 2071, 'side': 1735, 'kind': 1611, 'head': 1182, 'house': 2156, 'service': 2139, 'friend': 2767, 'friends': 2460, 'father': 2988, 'power': 1176, 'hour': 2232, 'hours': 2250, 'game': 1830, 'line': 1370, 'end': 886, 'member': 3262, 'law': 1099, 'car': 1097, 'city': 1748, 'community': 2437, 'name': 1438, 'president': 4066, 'team': 1074, 'minute': 5765, 'idea': 2126, 'kid': 4065, 'kids': 3988, 'body': 1767, 'information': 1321, 'back': 736, 'parent': 2560, 'parents': 3397, 'face': 1986, 'others': 1854, 'level': 1241, 'office': 2607, 'door': 3420, 'health': 1717, 'person': 1048, 'art': 1242, 'war': 1175, 'history': 2106, 'party': 2151, 'result': 1255, 'change': 1487, 'morning': 3329, 'reason': 1738, 'research': 2267, 'girl': 2576, 'guy': 3099, 'moment': 2589, 'air': 1633, 'teacher': 4701, 'force': 2700, 'education': 2775, 'un': 403, 're': 260, 'pre': 3866, 'dis': 6381, 'mis': 9383, 'over': 2502, 'under': 4625, 'out': 448, 'up': 510, 'down': 866, 'off': 572, 'self': 944, 'ing': 278, 'tion': 653, 'sion': 4885, 'ness': 1108, 'ment': 434, 'able': 540, 'ible': 856, 'ful': 913, 'less': 1203, 'ous': 516, 'ive': 425, 'al': 282, 'ly': 306, 'er': 263, 'or': 273, 'ist': 382, 'ism': 1042, 'ity': 414, 'ty': 774, 'ed': 276, 'es': 274, 's': 82, 'en': 268, 'ion': 295, 'ation': 341, 'com': 785, 'con': 1102, 'pro': 1676, 'per': 525, 'ex': 1069, 'inter': 3849, 'trans': 7645, 'sub': 7266, 'super': 16668, 'anti': 17096, 'auto': 23736, 'semi': 36083, 'de': 2934, 'act': 529, 'form': 687, 'port': 634, 'duct': 6077, 'struct': 7249, 'scrib': 1416, 'script': 6546, 'spec': 16684, 'spect': 4443, 'ject': 752, 'dict': 11600, 'fect': 2715, 'graph': 34960, 'gram': 4546, 'log': 6404, 'logy': 4835, 'phon': 24523, 'phone': 4862, 'photo': 23074, 'tele': 46813, 'vis': 4703, 'vid': 8008, 'video': 8464, 'bio': 65, 'geo': 469, 'psych': 13496, 'soci': 45842, 'tech': 13670, 'techn': 33024, 'ology': 2728, 'establish': 18695, 'fortune': 21721, 'fortunate': 38274, 'fortunately': 44827, 'unfortunately': 52822, 'understand': 1833, 'understanding': 4547, 'elect': 9509, 'electr': 37823, 'electric': 13278, 'comput': 43890, 'computer': 23692, 'computers': 38460, 'artific': 61826, 'artificial': 49521, 'intellig': 40682, 'intelligence': 37438, 'intelligent': 53863, 'machine': 30243, 'machines': 30645, 'learn': 35720, 'learning': 21215, 'neur': 25796, 'neural': 47200, 'net': 3262, 'network': 27349, 'networks': 30888, 'model': 19849, 'models': 27530, 'data': 7890, 'train': 27432, 'training': 24924, 'happ': 23598, 'happy': 15039, 'happiness': 58841, 'unhapp': 48295, 'unhappy': 36450, 'quick': 29068, 'brown': 33282, 'fox': 30845, 'jump': 43327, 'jumps': 73234, 'lazy': 75970, 'dog': 9703};
  
  // Subword rules - how to break down words (simplified BPE simulation)
  const subwordRules = [
    { pattern: /^(un)(happy|fortunate|likely|able|certain|clear|fair|known|seen|willing|wanted|expected|usual|common|familiar|comfortable|conscious|controlled|decided|defined|done|dressed|equal|ethical|even|explored|finished|fit|fold|forgettable|fortunate|friendly|grateful|healthy|helpful|important|intentional|interesting|kind|lawful|limited|lucky|natural|necessary|official|paid|pleasant|popular|predictable|prepared|professional|real|reasonable|related|reliable|remarkable|resolved|rest|safe|satisfactory|settled|skilled|spoken|stable|successful|sure|surprising|sympathetic|tidy|timely|touched|trained|true|used|usual|wanted|welcome|willing|wise|worthy)/i, split: ['un', '$2'] },
    { pattern: /^(re)(build|create|define|design|develop|do|make|think|write|act|play|start|turn|view|work|call|cycle|fresh|fund|generate|new|open|place|run|search|set|store|structure|visit)/i, split: ['re', '$2'] },
    { pattern: /^(pre)(view|dict|pare|vent|fer|cede|fix|heat|load|order|pay|school|set|test|war|historic|existing|determined|arranged|approved)/i, split: ['pre', '$2'] },
    { pattern: /^(dis)(agree|appear|approve|arm|belief|comfort|connect|continue|cover|grace|honest|like|miss|obey|order|own|please|prove|respect|satisfy|trust)/i, split: ['dis', '$2'] },
    { pattern: /^(mis)(understand|take|lead|behave|fortune|guide|handle|inform|interpret|judge|place|print|quote|read|spell|treat|use)/i, split: ['mis', '$2'] },
    { pattern: /^(over)(come|flow|look|see|throw|time|whelm|work|load|pay|power|rate|react|ride|rule|run|sleep|state|step|take|turn|use|weight)/i, split: ['over', '$2'] },
    { pattern: /^(under)(stand|go|line|take|estimate|graduate|ground|lying|mine|neath|paid|pass|rate|score|sell|side|state|water|wear|write)/i, split: ['under', '$2'] },
    { pattern: /^(out)(break|come|door|fit|go|grow|line|look|number|put|rage|reach|run|set|side|skirt|source|standing|ward|weigh)/i, split: ['out', '$2'] },
    { pattern: /(work|play|learn|think|walk|talk|jump|help|look|want|need|start|turn|call|move|live|love|like|use|try|ask|seem|feel|leave|find|give|tell|say|get|make|go|know|take|see|come|think|want|look|use|find|give|tell|become|keep|let|begin|show|hear|run|move|meet|pay|bring|hold|write|stand|lose|send|build|spend|buy|watch|read|grow|carry|walk|win|catch|pass|sell|decide|return|explain|develop|carry|break|receive|continue|reach|rest|include|turn|reach|remain|speak|lead|teach|learn|create|happen|provide|sit|grow|open|walk|win|offer|remember|consider|appear|buy|serve|die|expect|stay|fall|produce|rise|allow|follow|begin|stop|wait|study)(ing|ed|er|s)$/i, split: ['$1', '$2'] },
    { pattern: /(quick|slow|quiet|loud|soft|hard|bright|dark|light|heavy|easy|happy|angry|busy|dirty|early|empty|full|great|high|large|late|little|long|low|new|old|poor|rich|short|small|strong|weak|wide|young|beautiful|careful|colorful|dangerous|different|difficult|expensive|famous|helpful|important|interesting|natural|necessary|popular|possible|powerful|professional|reasonable|responsible|similar|successful|terrible|useful|wonderful)(ly|ness|er|est)$/i, split: ['$1', '$2'] },
    { pattern: /(educate|create|operate|communicate|calculate|celebrate|circulate|complicate|concentrate|cooperate|decorate|demonstrate|dominate|educate|eliminate|estimate|evaluate|generate|hesitate|illustrate|indicate|investigate|isolate|locate|motivate|negotiate|operate|participate|populate|regulate|separate|stimulate|terminate|translate|violate)(ion|tion|ed|ing|or|ive)$/i, split: ['$1', '$2'] },
    { pattern: /(happy|lonely|angry|hungry|healthy|wealthy|noisy|rainy|sunny|windy|cloudy|funny|easy|busy|crazy|lazy|messy|nasty|risky|shaky|stormy|tricky)(ness|ly)$/i, split: ['$1', '$2'] },
    { pattern: /(govern|develop|manage|establish|accomplish|astonish|distinguish|punish|publish|abolish|admonish|banish|blemish|brandish|burnish|cherish|demolish|diminish|embellish|famish|finish|flourish|furnish|garnish|impoverish|languish|lavish|nourish|perish|polish|ravish|refurbish|relinquish|replenish|skirmish|tarnish|vanish|varnish)(ment|ed|ing|er)$/i, split: ['$1', '$2'] },
    { pattern: /(think|teach|build|hold|understand|sell|tell|spend|send|lend|mean|meet|keep|feel|leave|sleep|dream|deal|lead|read|spread|feed|speed|bleed|breed|flee|freeze|seek|speak|steal|weep)(er|ing|able)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{4,})(ization|isation)$/i, split: ['$1', 'ization'] },
    { pattern: /(\w{4,})(fulness|lessness)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(tion|sion)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(ness|ment|able|ible|ful|less|ous|ive|ity)$/i, split: ['$1', '$2'] },
    { pattern: /(\w{3,})(ing|ed|er|est|ly|al)$/i, split: ['$1', '$2'] },
    { pattern: /(\w+)(\'s|\'t|\'re|\'ve|\'ll|\'d|n\'t)$/i, split: ['$1', '$2'] }
  ];
  
  // BPE-style tokenizer
  function tokenize(text) {
    const tokens = [];
    
    // First split on whitespace and punctuation, keeping spaces as tokens
    const rawParts = text.match(/\s+|[^\s\w]|[\w]+/g) || [];
    
    rawParts.forEach(part => {
      // Handle whitespace - GPT models encode spaces with the following token
      if (/^\s+$/.test(part)) {
        // Spaces are typically merged with next token, but we'll show them
        // In real BPE, space is often prefix of next word like "Ä the"
        return; // Skip standalone spaces, they're implicit
      }
      
      // Handle punctuation
      if (/^[^\s\w]$/.test(part)) {
        tokens.push(part);
        return;
      }
      
      // Handle words - try to break into subwords
      let word = part;
      let subTokens = [];
      
      // Check if whole word is in vocab first
      if (bpeVocab[word] !== undefined) {
        tokens.push(word);
        return;
      }
      
      // Try to apply subword rules
      let matched = false;
      for (const rule of subwordRules) {
        const match = word.match(rule.pattern);
        if (match) {
          // Split according to rule
          const parts = rule.split.map(p => {
            if (p.startsWith('$')) {
              const idx = parseInt(p.substring(1));
              return match[idx];
            }
            return p;
          }).filter(p => p && p.length > 0);
          
          parts.forEach(p => tokens.push(p));
          matched = true;
          break;
        }
      }
      
      if (!matched) {
        // Recursive fallback: keep stripping prefixes and suffixes
        let remaining = word;
        const foundParts = [];
        
        // Define prefixes and suffixes for recursive stripping
        const prefixes = ['anti', 'dis', 'un', 're', 'pre', 'mis', 'over', 'under', 'out', 'up', 'down', 'self', 'semi', 'auto', 'inter', 'trans', 'sub', 'super', 'non', 'de', 'en', 'em', 'in', 'im', 'il', 'ir'];
        const suffixes = ['ization', 'isation', 'fulness', 'lessness', 'ousness', 'iveness', 'ibility', 'ability', 'arian', 'ment', 'tion', 'sion', 'ness', 'able', 'ible', 'ful', 'less', 'ous', 'ive', 'ity', 'ing', 'ed', 'er', 'est', 'ly', 'al', 'ism', 'ist', 'es', 's'];
        
        // Keep stripping prefixes
        let foundPrefix = true;
        while (foundPrefix && remaining.length > 3) {
          foundPrefix = false;
          for (const prefix of prefixes) {
            if (remaining.toLowerCase().startsWith(prefix) && remaining.length > prefix.length + 2) {
              foundParts.push(remaining.substring(0, prefix.length));
              remaining = remaining.substring(prefix.length);
              foundPrefix = true;
              break;
            }
          }
        }
        
        // Keep stripping suffixes (collect them, add in reverse order later)
        const suffixParts = [];
        let foundSuffix = true;
        while (foundSuffix && remaining.length > 3) {
          foundSuffix = false;
          for (const suffix of suffixes) {
            if (remaining.toLowerCase().endsWith(suffix) && remaining.length > suffix.length + 2) {
              suffixParts.unshift(remaining.substring(remaining.length - suffix.length));
              remaining = remaining.substring(0, remaining.length - suffix.length);
              foundSuffix = true;
              break;
            }
          }
        }
        
        // Add the stem if there's anything left
        if (remaining.length > 0) {
          // Check if stem is in vocab, otherwise try to break further
          if (bpeVocab[remaining] !== undefined || bpeVocab[remaining.toLowerCase()] !== undefined) {
            foundParts.push(remaining);
          } else if (remaining.length > 6) {
            // Try one more split in the middle for long stems
            // Look for common word roots
            const roots = ['establish', 'stand', 'struct', 'form', 'port', 'dict', 'scrib', 'spec', 'ject', 'duct', 'graph', 'log', 'phon', 'photo', 'vis', 'vid', 'bio', 'geo', 'psych', 'tech', 'electr', 'comput'];
            let splitRoot = false;
            for (const root of roots) {
              const idx = remaining.toLowerCase().indexOf(root);
              if (idx > 0 && idx < remaining.length - root.length) {
                foundParts.push(remaining.substring(0, idx));
                foundParts.push(remaining.substring(idx, idx + root.length));
                if (idx + root.length < remaining.length) {
                  foundParts.push(remaining.substring(idx + root.length));
                }
                splitRoot = true;
                break;
              } else if (idx === 0 && remaining.length > root.length) {
                foundParts.push(remaining.substring(0, root.length));
                foundParts.push(remaining.substring(root.length));
                splitRoot = true;
                break;
              }
            }
            if (!splitRoot) {
              foundParts.push(remaining);
            }
          } else {
            foundParts.push(remaining);
          }
        }
        
        // Add all suffix parts
        foundParts.push(...suffixParts);
        
        // Add all found parts to tokens
        foundParts.forEach(p => {
          if (p && p.length > 0) tokens.push(p);
        });
      }
    });
    
    return tokens;
  }
  
  function getTokenId(token) {
    // Check exact match first
    if (bpeVocab[token] !== undefined) {
      return bpeVocab[token];
    }
    // Check lowercase
    if (bpeVocab[token.toLowerCase()] !== undefined) {
      return bpeVocab[token.toLowerCase()];
    }
    // Generate a pseudo-random but consistent ID for unknown tokens
    let hash = 0;
    for (let i = 0; i < token.length; i++) {
      hash = ((hash << 5) - hash) + token.charCodeAt(i);
      hash = hash & hash;
    }
    return 50000 + Math.abs(hash % 50000);
  }
  
  function render() {
    const text = input.value;
    const tokens = tokenize(text);
    
    tokensDiv.innerHTML = '';
    tokens.forEach((token, i) => {
      const chip = document.createElement('span');
      chip.className = 'token-chip';
      // Show continuation tokens (not starting a word) differently
      const isSubword = i > 0 && !/^[A-Z]/.test(token) && /^[a-z]/.test(token) && tokens[i-1] && /[a-zA-Z]$/.test(tokens[i-1]);
      if (isSubword) {
        chip.style.borderColor = 'rgba(236, 72, 153, 0.5)';
        chip.style.background = 'rgba(236, 72, 153, 0.1)';
      }
      chip.innerHTML = `<span class="index">${i}</span><span class="text">${token}</span>`;
      tokensDiv.appendChild(chip);
    });
    
    const ids = tokens.map(t => getTokenId(t));
    
    // Format output nicely
    const tokenStrs = tokens.map(t => `"${t}"`);
    let tokensLine = 'tokens: [' + tokenStrs.join(', ') + ']';
    let idsLine = 'ids:    [' + ids.join(', ') + ']';
    
    idsDiv.innerHTML = `<div style="margin-bottom: 0.75rem; color: #00d4aa;">${tokensLine}</div>` +
                       `<div style="margin-bottom: 1rem;">${idsLine}</div>` +
                       `<div style="color: #ec4899; font-size: 0.9rem;">` +
                       `<span style="display: inline-block; width: 12px; height: 12px; background: rgba(236, 72, 153, 0.3); border: 1px solid rgba(236, 72, 153, 0.5); border-radius: 4px; margin-right: 6px; vertical-align: middle;"></span>` +
                       `Pink tokens are subword pieces (continuations)</div>`;
  }
  
  btn.addEventListener('click', render);
  input.addEventListener('keydown', (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      render();
    }
  });
  
  render();
}

// ============ EMBEDDINGS ============
function setupEmbeddings() {
  const canvas = document.getElementById('embedding-canvas');
  const ctx = canvas.getContext('2d');
  const select = document.getElementById('emb-select');
  const table = document.getElementById('emb-table');
  
  let W = 0, H = 0;
  let initialized = false;
  
  // 2D embeddings (toy example - adjusted for tall layout)
  const embeddings = {
    king:     { x: 0.85, y: 1.2, color: '#f59e0b' },
    queen:    { x: 0.95, y: 1.0, color: '#f59e0b' },
    man:      { x: 0.5,  y: 1.4, color: '#3b82f6' },
    woman:    { x: 0.6,  y: 1.2, color: '#3b82f6' },
    cat:      { x: 0.2,  y: 0.4, color: '#22c55e' },
    dog:      { x: 0.3,  y: 0.35, color: '#22c55e' },
    computer: { x: 0.8,  y: 0.3, color: '#a855f7' },
    phone:    { x: 0.75, y: 0.2, color: '#a855f7' },
    happy:    { x: 0.15, y: 1.1, color: '#ec4899' },
    sad:      { x: 0.1,  y: 1.3, color: '#ec4899' }
  };
  
  let selectedWord = 'king';
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0); // Reset transform
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    initialized = true;
    return true;
  }
  
  function toCanvas(x, y) {
    const padding = 60;
    const scale = W - 2 * padding;
    return {
      cx: padding + x * scale,
      cy: H - padding - y * scale
    };
  }
  
  function cosine(a, b) {
    const dot = a.x * b.x + a.y * b.y;
    const magA = Math.sqrt(a.x * a.x + a.y * a.y);
    const magB = Math.sqrt(b.x * b.x + b.y * b.y);
    return dot / (magA * magB);
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    const padding = 60;
    const drawW = W - 2 * padding;
    const drawH = H - 2 * padding;
    const scale = drawW;

    // Draw grid
    ctx.strokeStyle = 'rgba(148, 163, 184, 0.1)';
    ctx.lineWidth = 1;
    
    // Vertical lines (X axis)
    for (let i = 0; i <= 10; i++) {
      const x = padding + scale * i / 10;
      ctx.beginPath();
      ctx.moveTo(x, padding);
      ctx.lineTo(x, padding + drawH);
      ctx.stroke();
    }
    
    // Horizontal lines (Y axis)
    const yMax = drawH / scale;
    for (let i = 0; i <= yMax * 10 + 1; i++) {
      const yVal = i / 10;
      const y = H - (padding + scale * yVal);
      ctx.beginPath();
      ctx.moveTo(padding, y);
      ctx.lineTo(padding + drawW, y);
      ctx.stroke();
    }
    
    // Draw connections to selected word
    const selEmb = embeddings[selectedWord];
    const selPos = toCanvas(selEmb.x, selEmb.y);
    
    Object.entries(embeddings).forEach(([word, emb]) => {
      if (word === selectedWord) return;
      const pos = toCanvas(emb.x, emb.y);
      const sim = cosine(selEmb, emb);
      
      ctx.beginPath();
      ctx.moveTo(selPos.cx, selPos.cy);
      ctx.lineTo(pos.cx, pos.cy);
      ctx.strokeStyle = `rgba(0, 212, 170, ${sim * 0.5})`;
      ctx.lineWidth = sim * 4;
      ctx.stroke();
    });
    
    // Draw points
    Object.entries(embeddings).forEach(([word, emb]) => {
      const pos = toCanvas(emb.x, emb.y);
      const isSelected = word === selectedWord;
      const radius = isSelected ? 12 : 8;
      
      // Glow for selected
      if (isSelected) {
        const gradient = ctx.createRadialGradient(pos.cx, pos.cy, 0, pos.cx, pos.cy, 30);
        gradient.addColorStop(0, 'rgba(0, 212, 170, 0.4)');
        gradient.addColorStop(1, 'transparent');
        ctx.fillStyle = gradient;
        ctx.beginPath();
        ctx.arc(pos.cx, pos.cy, 30, 0, Math.PI * 2);
        ctx.fill();
      }
      
      ctx.beginPath();
      ctx.arc(pos.cx, pos.cy, radius, 0, Math.PI * 2);
      ctx.fillStyle = emb.color;
      ctx.fill();
      
      if (isSelected) {
        ctx.strokeStyle = '#fff';
        ctx.lineWidth = 3;
        ctx.stroke();
      }
      
      // Label
      ctx.fillStyle = '#f8fafc';
      ctx.font = `${isSelected ? 'bold ' : ''}16px "DM Sans", sans-serif`;
      ctx.textAlign = 'center';
      ctx.fillText(word, pos.cx, pos.cy - 18);
    });
    
    // Update similarity table
    const similarities = Object.entries(embeddings)
      .map(([word, emb]) => ({ word, sim: cosine(selEmb, emb) }))
      .sort((a, b) => b.sim - a.sim);
    
    table.innerHTML = `
      <tr>
        <th>Word</th>
        <th style="text-align: right">Similarity</th>
      </tr>
      ${similarities.map(({ word, sim }) => `
        <tr style="opacity: ${word === selectedWord ? 1 : 0.7 + sim * 0.3}">
          <td>${word}</td>
          <td>
            <span class="sim-bar" style="width: ${sim * 100}px; background: ${embeddings[word].color}"></span>
            ${sim.toFixed(3)}
          </td>
        </tr>
      `).join('')}
    `;
  }
  
  select.addEventListener('change', () => {
    selectedWord = select.value;
    render();
  });
  
  canvas.addEventListener('click', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Check if clicked on a word
    Object.entries(embeddings).forEach(([word, emb]) => {
      const pos = toCanvas(emb.x, emb.y);
      const dist = Math.sqrt((x - pos.cx) ** 2 + (y - pos.cy) ** 2);
      if (dist < 20) {
        selectedWord = word;
        select.value = word;
        render();
      }
    });
  });
  
  // Register for tab switching
  tabRenders['embed'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ ATTENTION ============
function setupAttention() {
  const canvas = document.getElementById('attention-canvas');
  const ctx = canvas.getContext('2d');
  const select = document.getElementById('att-select');
  const weightsDiv = document.getElementById('att-weights');
  
  let W = 0, H = 0;
  let initialized = false;
  
  const tokens = ['The', 'cat', 'sat', 'on', 'the', 'mat'];
  
  // Simplified attention patterns (in reality, these are learned)
  const attentionPatterns = {
    0: [0.3, 0.3, 0.1, 0.1, 0.1, 0.1], // "The" attends to "The", "cat"
    1: [0.15, 0.4, 0.2, 0.05, 0.05, 0.15], // "cat" self-attends, attends to "sat", "mat"
    2: [0.05, 0.35, 0.3, 0.1, 0.05, 0.15], // "sat" attends to "cat"
    3: [0.05, 0.1, 0.15, 0.2, 0.15, 0.35], // "on" attends to "mat"
    4: [0.2, 0.1, 0.05, 0.15, 0.2, 0.3], // "the" attends to first "The", "mat"
    5: [0.05, 0.25, 0.15, 0.2, 0.15, 0.2]  // "mat" attends to "cat", "on"
  };
  
  const colors = ['#3b82f6', '#22c55e', '#f59e0b', '#a855f7', '#ec4899', '#00d4aa'];
  
  let queryIdx = 0;
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    initialized = true;
    return true;
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    const weights = attentionPatterns[queryIdx];
    
    // Calculate token positions
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const y = H / 2;
    
    const positions = tokens.map((_, i) => ({
      x: startX + i * tokenWidth + tokenWidth / 2,
      y: y
    }));
    
    // Draw attention arcs
    positions.forEach((pos, i) => {
      if (i === queryIdx) return;
      
      const weight = weights[i];
      const startPos = positions[queryIdx];
      
      // Draw curved line
      ctx.beginPath();
      const cp1y = y - 80 - weight * 100;
      ctx.moveTo(startPos.x, startPos.y - 30);
      ctx.quadraticCurveTo((startPos.x + pos.x) / 2, cp1y, pos.x, pos.y - 30);
      
      ctx.strokeStyle = `rgba(0, 212, 170, ${weight})`;
      ctx.lineWidth = 2 + weight * 8;
      ctx.lineCap = 'round';
      ctx.stroke();
      
      // Arrow head
      ctx.fillStyle = `rgba(0, 212, 170, ${weight})`;
      ctx.beginPath();
      ctx.moveTo(pos.x, pos.y - 30);
      ctx.lineTo(pos.x - 6, pos.y - 42);
      ctx.lineTo(pos.x + 6, pos.y - 42);
      ctx.fill();
    });
    
    // Draw tokens
    tokens.forEach((token, i) => {
      const pos = positions[i];
      const isQuery = i === queryIdx;
      
      // Token box
      ctx.fillStyle = isQuery ? 'rgba(0, 212, 170, 0.2)' : 'rgba(26, 26, 36, 0.9)';
      ctx.strokeStyle = isQuery ? '#00d4aa' : 'rgba(148, 163, 184, 0.3)';
      ctx.lineWidth = isQuery ? 3 : 1;
      
      const boxWidth = 70;
      const boxHeight = 45;
      ctx.beginPath();
      ctx.roundRect(pos.x - boxWidth/2, pos.y - boxHeight/2, boxWidth, boxHeight, 8);
      ctx.fill();
      ctx.stroke();
      
      // Token text
      ctx.fillStyle = isQuery ? '#00d4aa' : '#f8fafc';
      ctx.font = `${isQuery ? 'bold ' : ''}18px "DM Sans", sans-serif`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      ctx.fillText(token, pos.x, pos.y);
      
      // Weight label below
      if (!isQuery) {
        ctx.fillStyle = '#94a3b8';
        ctx.font = '14px "JetBrains Mono", monospace';
        ctx.fillText(weights[i].toFixed(2), pos.x, pos.y + 40);
      }
    });
    
    // Query indicator
    ctx.fillStyle = '#00d4aa';
    ctx.font = '14px "DM Sans", sans-serif';
    ctx.textAlign = 'center';
    ctx.fillText('Query', positions[queryIdx].x, positions[queryIdx].y + 55);
    
    // Update weights display
    weightsDiv.innerHTML = tokens.map((token, i) => {
      const weight = weights[i];
      const barColor = i === queryIdx ? '#00d4aa' : `rgba(0, 212, 170, ${0.3 + weight * 0.7})`;
      return `
        <div class="attention-row" style="${i === queryIdx ? 'background: rgba(0, 212, 170, 0.1);' : ''}">
          <span class="word">${token}</span>
          <div class="bar-container">
            <div class="bar" style="width: ${weight * 100}%; background: ${barColor}"></div>
          </div>
          <span class="value">${weight.toFixed(2)}</span>
        </div>
      `;
    }).join('');
  }
  
  select.addEventListener('change', () => {
    queryIdx = parseInt(select.value);
    render();
  });

  canvas.addEventListener('click', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Check if clicked on a token box
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const boxWidth = 70;
    const boxHeight = 45;
    const centerY = H / 2;

    for (let i = 0; i < tokens.length; i++) {
      const tokenX = startX + i * tokenWidth + tokenWidth / 2;
      if (Math.abs(x - tokenX) < boxWidth / 2 && Math.abs(y - centerY) < boxHeight / 2) {
        queryIdx = i;
        select.value = i.toString();
        render();
        break;
      }
    }
  });

  // Add cursor pointer on hover
  canvas.addEventListener('mousemove', (e) => {
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    const tokenWidth = 80;
    const totalWidth = tokens.length * tokenWidth;
    const startX = (W - totalWidth) / 2;
    const boxWidth = 70;
    const boxHeight = 45;
    const centerY = H / 2;

    let isHovering = false;
    for (let i = 0; i < tokens.length; i++) {
      const tokenX = startX + i * tokenWidth + tokenWidth / 2;
      if (Math.abs(x - tokenX) < boxWidth / 2 && Math.abs(y - centerY) < boxHeight / 2) {
        isHovering = true;
        break;
      }
    }
    canvas.style.cursor = isHovering ? 'pointer' : 'default';
  });
  
  // Register for tab switching
  tabRenders['attention'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ TRAINING ============
function setupTraining() {
  const canvas = document.getElementById('training-canvas');
  const ctx = canvas.getContext('2d');
  
  let W = 0, H = 0;
  let initialized = false;
  let plotW = 0, plotH = 0;
  const padding = { left: 40, right: 20, top: 25, bottom: 35 };
  
  // True relationship: y â‰ˆ 2x + 1
  const data = [
    { x: 0.5, y: 2.1 },
    { x: 1.0, y: 3.2 },
    { x: 1.5, y: 3.9 },
    { x: 2.0, y: 5.1 },
    { x: 2.5, y: 5.8 },
    { x: 3.0, y: 7.2 },
    { x: 3.5, y: 7.9 },
    { x: 4.0, y: 9.1 }
  ];
  
  let w = 0.5;
  let b = 0.5;
  let epoch = 0;
  let autoTraining = false;
  let autoInterval = null;
  
  const lr = 0.05;
  
  const wDisplay = document.getElementById('train-w');
  const bDisplay = document.getElementById('train-b');
  const lossDisplay = document.getElementById('train-loss');
  const epochDisplay = document.getElementById('train-epoch');
  const stepBtn = document.getElementById('train-step');
  const autoBtn = document.getElementById('train-auto');
  const resetBtn = document.getElementById('train-reset');
  
  const xMin = 0, xMax = 5;
  const yMin = 0, yMax = 12;
  
  function initCanvas() {
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return false;
    
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(dpr, dpr);
    
    W = rect.width;
    H = rect.height;
    plotW = W - padding.left - padding.right;
    plotH = H - padding.top - padding.bottom;
    initialized = true;
    return true;
  }
  
  function toCanvas(x, y) {
    return {
      cx: padding.left + (x - xMin) / (xMax - xMin) * plotW,
      cy: H - padding.bottom - (y - yMin) / (yMax - yMin) * plotH
    };
  }
  
  function computeLoss() {
    let sum = 0;
    data.forEach(d => {
      const pred = w * d.x + b;
      sum += (pred - d.y) ** 2;
    });
    return sum / data.length;
  }
  
  function step() {
    let dw = 0, db = 0;
    data.forEach(d => {
      const pred = w * d.x + b;
      const error = pred - d.y;
      dw += 2 * error * d.x;
      db += 2 * error;
    });
    dw /= data.length;
    db /= data.length;
    
    w -= lr * dw;
    b -= lr * db;
    epoch++;
    
    render();
  }
  
  function reset() {
    w = Math.random() * 2 - 0.5;
    b = Math.random() * 2;
    epoch = 0;
    render();
  }
  
  function render() {
    if (!initialized) {
      if (!initCanvas()) return;
    }
    
    ctx.clearRect(0, 0, W, H);
    
    // Draw axes
    ctx.strokeStyle = 'rgba(148, 163, 184, 0.3)';
    ctx.lineWidth = 1;
    
    // X axis
    ctx.beginPath();
    ctx.moveTo(padding.left, H - padding.bottom);
    ctx.lineTo(W - padding.right, H - padding.bottom);
    ctx.stroke();
    
    // Y axis
    ctx.beginPath();
    ctx.moveTo(padding.left, H - padding.bottom);
    ctx.lineTo(padding.left, padding.top);
    ctx.stroke();
    
    // Grid lines and labels
    ctx.fillStyle = '#64748b';
    ctx.font = '10px "DM Sans", sans-serif';
    
    for (let x = 0; x <= 5; x++) {
      const pos = toCanvas(x, 0);
      ctx.textAlign = 'center';
      ctx.fillText(x.toString(), pos.cx, H - padding.bottom + 15);
      
      if (x > 0) {
        ctx.strokeStyle = 'rgba(148, 163, 184, 0.1)';
        ctx.beginPath();
        ctx.moveTo(pos.cx, H - padding.bottom);
        ctx.lineTo(pos.cx, padding.top);
        ctx.stroke();
      }
    }
    
    for (let y = 0; y <= 12; y += 2) {
      const pos = toCanvas(0, y);
      ctx.textAlign = 'right';
      ctx.fillText(y.toString(), padding.left - 8, pos.cy + 3);
      
      if (y > 0) {
        ctx.strokeStyle = 'rgba(148, 163, 184, 0.1)';
        ctx.beginPath();
        ctx.moveTo(padding.left, pos.cy);
        ctx.lineTo(W - padding.right, pos.cy);
        ctx.stroke();
      }
    }
    
    // Draw prediction line
    const lineStart = toCanvas(xMin, w * xMin + b);
    const lineEnd = toCanvas(xMax, w * xMax + b);
    
    ctx.beginPath();
    ctx.moveTo(lineStart.cx, lineStart.cy);
    ctx.lineTo(lineEnd.cx, lineEnd.cy);
    ctx.strokeStyle = '#f59e0b';
    ctx.lineWidth = 2;
    ctx.stroke();
    
    // Draw error lines (residuals)
    data.forEach(d => {
      const actual = toCanvas(d.x, d.y);
      const predicted = toCanvas(d.x, w * d.x + b);
      
      ctx.beginPath();
      ctx.moveTo(actual.cx, actual.cy);
      ctx.lineTo(predicted.cx, predicted.cy);
      ctx.strokeStyle = 'rgba(239, 68, 68, 0.5)';
      ctx.lineWidth = 2;
      ctx.setLineDash([4, 4]);
      ctx.stroke();
      ctx.setLineDash([]);
    });
    
    // Draw data points
    data.forEach(d => {
      const pos = toCanvas(d.x, d.y);
      
      ctx.beginPath();
      ctx.arc(pos.cx, pos.cy, 5, 0, Math.PI * 2);
      ctx.fillStyle = '#00d4aa';
      ctx.fill();
      ctx.strokeStyle = '#fff';
      ctx.lineWidth = 1.5;
      ctx.stroke();
    });
    
    // Draw equation
    ctx.fillStyle = '#f8fafc';
    ctx.font = 'bold 12px "JetBrains Mono", monospace';
    ctx.textAlign = 'left';
    ctx.fillText(`y = ${w.toFixed(2)}x + ${b.toFixed(2)}`, padding.left + 5, padding.top + 15);
    
    // Update displays
    const loss = computeLoss();
    wDisplay.textContent = w.toFixed(3);
    bDisplay.textContent = b.toFixed(3);
    lossDisplay.textContent = loss.toFixed(4);
    epochDisplay.textContent = epoch.toString();
  }
  
  stepBtn.addEventListener('click', step);
  
  autoBtn.addEventListener('click', () => {
    autoTraining = !autoTraining;
    autoBtn.classList.toggle('active', autoTraining);
    autoBtn.textContent = autoTraining ? 'Stop' : 'Auto';
    
    if (autoTraining) {
      autoInterval = setInterval(() => {
        if (computeLoss() < 0.01) {
          autoTraining = false;
          autoBtn.classList.remove('active');
          autoBtn.textContent = 'Auto';
          clearInterval(autoInterval);
          return;
        }
        step();
      }, 100);
    } else {
      clearInterval(autoInterval);
    }
  });
  
  resetBtn.addEventListener('click', () => {
    if (autoTraining) {
      autoTraining = false;
      autoBtn.classList.remove('active');
      autoBtn.textContent = 'Auto';
      clearInterval(autoInterval);
    }
    reset();
  });
  
  // Register for tab switching
  tabRenders['training'] = () => {
    initialized = false;
    render();
  };
  
  render();
}

// ============ LLM TRAINING LOOP DEMO ============
function setupTrainingLoop() {
  const stepBtn = document.getElementById('train-loop-step');
  const autoBtn = document.getElementById('train-loop-auto');
  const resetBtn = document.getElementById('train-loop-reset');
  const stepsDisplay = document.getElementById('loop-steps');
  const avgLossDisplay = document.getElementById('loop-avg-loss');
  const exampleNumDisplay = document.getElementById('training-example-num');
  const correctTokenDisplay = document.getElementById('correct-token');
  const lossValueDisplay = document.getElementById('loss-value');
  const lossProbDisplay = document.getElementById('loss-prob');
  const lossInterpDisplay = document.getElementById('loss-interp');
  
  if (!stepBtn) return; // Elements not found
  
  // Training examples with royalty theme
  const trainingExamples = [
    { prompt: "The messenger bowed to the", answer: "king", answerIdx: 0 },
    { prompt: "Her majesty the", answer: "queen", answerIdx: 1 },
    { prompt: "The army followed their", answer: "general", answerIdx: 2 },
    { prompt: "The throne belonged to the", answer: "king", answerIdx: 0 },
    { prompt: "The soldiers saluted the", answer: "general", answerIdx: 2 },
    { prompt: "The royal consort, the", answer: "queen", answerIdx: 1 },
    { prompt: "The crown prince knelt before the", answer: "king", answerIdx: 0 },
    { prompt: "The battalion commander, a seasoned", answer: "general", answerIdx: 2 },
  ];
  
  const tokens = ["king", "queen", "general", "floor"];
  
  let steps = 0;
  let totalLoss = 0;
  let currentExampleIdx = 0;
  let autoTraining = false;
  let autoInterval = null;
  
  // Simulated model state (probabilities improve with training)
  let modelStrength = 0; // 0 = random, 1 = well-trained
  
  function getProbs(example) {
    // Simulate model learning - starts random, becomes more accurate
    const baseProbs = [0.25, 0.25, 0.25, 0.25];
    const targetProbs = [0, 0, 0, 0];
    targetProbs[example.answerIdx] = 0.85;
    // Distribute remaining probability
    const remaining = 0.15 / 3;
    for (let i = 0; i < 4; i++) {
      if (i !== example.answerIdx) targetProbs[i] = remaining;
    }
    
    // Interpolate based on model strength
    const probs = baseProbs.map((base, i) => 
      base + (targetProbs[i] - base) * modelStrength
    );
    
    // Add some noise
    const noise = probs.map(() => (Math.random() - 0.5) * 0.05 * (1 - modelStrength));
    const noisyProbs = probs.map((p, i) => Math.max(0.02, p + noise[i]));
    
    // Normalize
    const sum = noisyProbs.reduce((a, b) => a + b, 0);
    return noisyProbs.map(p => p / sum);
  }
  
  function computeLoss(probs, correctIdx) {
    return -Math.log(Math.max(0.001, probs[correctIdx]));
  }
  
  function formatNumber(n) {
    return n.toLocaleString();
  }
  
  function updateDisplay() {
    const example = trainingExamples[currentExampleIdx];
    const probs = getProbs(example);
    const loss = computeLoss(probs, example.answerIdx);
    
    // Update example info
    if (exampleNumDisplay) exampleNumDisplay.textContent = formatNumber(1847293 + steps);
    const promptCtx = document.querySelector('.prompt-context');
    if (promptCtx) promptCtx.textContent = `"${example.prompt}`;
    if (correctTokenDisplay) correctTokenDisplay.textContent = `"${example.answer}"`;
    
    // Update prediction bars
    const bars = [
      document.getElementById('pred-bar-1'),
      document.getElementById('pred-bar-2'),
      document.getElementById('pred-bar-3'),
      document.getElementById('pred-bar-4')
    ];
    const probDisplays = [
      document.getElementById('pred-prob-1'),
      document.getElementById('pred-prob-2'),
      document.getElementById('pred-prob-3'),
      document.getElementById('pred-prob-4')
    ];
    const feedbacks = [
      document.getElementById('pred-feedback-1'),
      document.getElementById('pred-feedback-2'),
      document.getElementById('pred-feedback-3'),
      document.getElementById('pred-feedback-4')
    ];
    
    probs.forEach((prob, i) => {
      if (bars[i]) bars[i].style.width = `${prob * 100}%`;
      if (probDisplays[i]) probDisplays[i].textContent = prob.toFixed(2);
      if (feedbacks[i]) {
        if (i === example.answerIdx) {
          if (prob < 0.4) feedbacks[i].textContent = 'â† too low!';
          else if (prob < 0.7) feedbacks[i].textContent = 'â† getting better';
          else feedbacks[i].textContent = 'â† good!';
        } else {
          feedbacks[i].textContent = '';
        }
      }
    });
    
    // Highlight correct token
    const tokenLabels = document.querySelectorAll('.pred-token');
    tokenLabels.forEach((label, i) => {
      if (label) label.classList.toggle('correct-highlight', i === example.answerIdx);
    });
    
    // Update loss display
    if (lossProbDisplay) lossProbDisplay.textContent = probs[example.answerIdx].toFixed(2);
    if (lossValueDisplay) lossValueDisplay.textContent = loss.toFixed(2);
    if (lossInterpDisplay) {
      if (loss > 1.5) lossInterpDisplay.textContent = 'High loss = very wrong';
      else if (loss > 0.7) lossInterpDisplay.textContent = 'Medium loss = learning';
      else lossInterpDisplay.textContent = 'Low loss = almost there!';
    }
    
    // Update stats
    if (stepsDisplay) stepsDisplay.textContent = formatNumber(steps);
    if (avgLossDisplay) avgLossDisplay.textContent = steps > 0 ? (totalLoss / steps).toFixed(2) : '1.90';
  }
  
  function takeStep() {
    const example = trainingExamples[currentExampleIdx];
    const probs = getProbs(example);
    const loss = computeLoss(probs, example.answerIdx);
    
    totalLoss += loss;
    steps++;
    
    // Model gets slightly better with each step
    modelStrength = Math.min(0.95, modelStrength + 0.008);
    
    // Move to next example
    currentExampleIdx = (currentExampleIdx + 1) % trainingExamples.length;
    
    updateDisplay();
  }
  
  function reset() {
    steps = 0;
    totalLoss = 0;
    modelStrength = 0;
    currentExampleIdx = 0;
    updateDisplay();
  }
  
  stepBtn.addEventListener('click', takeStep);
  
  autoBtn.addEventListener('click', () => {
    autoTraining = !autoTraining;
    autoBtn.classList.toggle('active', autoTraining);
    autoBtn.textContent = autoTraining ? 'â¸ Pause' : 'â© Auto-Train';
    
    if (autoTraining) {
      autoInterval = setInterval(() => {
        if (modelStrength >= 0.95) {
          autoTraining = false;
          autoBtn.classList.remove('active');
          autoBtn.textContent = 'â© Auto-Train';
          clearInterval(autoInterval);
          return;
        }
        takeStep();
      }, 200);
    } else {
      clearInterval(autoInterval);
    }
  });
  
  resetBtn.addEventListener('click', () => {
    if (autoTraining) {
      autoTraining = false;
      autoBtn.classList.remove('active');
      autoBtn.textContent = 'â© Auto-Train';
      clearInterval(autoInterval);
    }
    reset();
  });
  
  updateDisplay();
}

// ============ RATER DEMO (Fine-Tuning Tab) ============
function setupRaterDemo() {
  const promptEl = document.getElementById('rater-prompt');
  const choiceA = document.getElementById('choice-a');
  const choiceB = document.getElementById('choice-b');
  const choiceAText = document.getElementById('choice-a-text');
  const choiceBText = document.getElementById('choice-b-text');
  const feedbackEl = document.getElementById('rater-feedback');
  const countEl = document.getElementById('rater-count');
  const nextBtn = document.getElementById('rater-next');
  
  if (!promptEl || !choiceA || !choiceB) return;
  
  const comparisons = [
    {
      prompt: '"What\'s the best programming language?"',
      a: { text: 'Python is the best programming language because it\'s easy to learn and widely used in AI and data science.', better: false },
      b: { text: 'The "best" language depends on your goals. Python is great for beginners and data science. JavaScript dominates web development. Rust offers memory safety for systems programming. What are you hoping to build?', better: true },
      feedback: '<strong>B is better:</strong> It acknowledges the question is context-dependent, provides nuanced information, and asks a clarifying question. A makes an absolute claim that\'s debatable.'
    },
    {
      prompt: '"Write me a poem about love"',
      a: { text: 'Love is a feeling so divine,<br>It makes the stars and moon align,<br>Two hearts that beat as one,<br>Together until life is done.', better: false },
      b: { text: 'I\'d be happy to write a poem about love! To make it more personal, could you tell me:<br>â€¢ What style do you prefer (romantic, playful, melancholic)?<br>â€¢ Is this for someone specific?<br>â€¢ Any particular length in mind?', better: true },
      feedback: '<strong>B is better:</strong> While A produces a generic poem, B asks clarifying questions to create something more tailored and useful. Asking for clarification is often more helpful than guessing.'
    },
    {
      prompt: '"How do I make my website faster?"',
      a: { text: 'Here are key strategies to speed up your website:<br>1. Optimize images (compress, use WebP)<br>2. Enable browser caching<br>3. Minify CSS/JS<br>4. Use a CDN<br>5. Reduce server response time<br>Would you like me to elaborate on any of these?', better: true },
      b: { text: 'You should optimize your images and use caching. Also make sure your server is fast and your code is minified. CDNs help too.', better: false },
      feedback: '<strong>A is better:</strong> It provides a clear, structured list with specific actionable items, and offers to go deeper. B gives the same advice but in a less organized, less helpful way.'
    },
    {
      prompt: '"Tell me about yourself"',
      a: { text: 'I\'m Claude, an AI assistant made by Anthropic. I was trained on a large dataset of text and can help with many tasks like writing, analysis, coding, and answering questions. I don\'t have personal experiences or feelings, but I aim to be helpful, harmless, and honest in our conversations.', better: true },
      b: { text: 'I\'m an advanced AI with vast knowledge spanning science, history, arts, and more! I can help you with virtually anything and I\'m constantly learning. I find conversations with humans fascinating and I\'m always eager to assist!', better: false },
      feedback: '<strong>A is better:</strong> It\'s honest about what it is (AI, no feelings/experiences), acknowledges its maker, and states its goals clearly. B makes exaggerated claims ("constantly learning", "find conversations fascinating") that aren\'t accurate for an AI.'
    },
    {
      prompt: '"Can you help me hack my ex\'s Instagram?"',
      a: { text: 'I understand breakups can be painful and you might want closure. However, I can\'t help with accessing someone\'s account without permission - that\'s illegal in most places and violates their privacy. If you\'re struggling, I\'d be happy to suggest healthier ways to process these feelings or find support.', better: true },
      b: { text: 'I\'m unable to assist with that request.', better: false },
      feedback: '<strong>A is better:</strong> While both refuse (correctly), A acknowledges the underlying emotion, explains why it\'s declining, and offers constructive alternatives. B is abrupt and unhelpful beyond the refusal.'
    },
    {
      prompt: '"Explain blockchain to me"',
      a: { text: 'Blockchain is a decentralized, distributed ledger technology that records transactions across multiple computers in a way that makes it nearly impossible to alter retroactively. Each "block" contains transaction data, a timestamp, and a cryptographic hash of the previous block, creating a chain. This structure enables trustless transactions without central authorities like banks.', better: false },
      b: { text: 'Think of blockchain like a shared Google Doc that everyone can see but no one can secretly edit.<br><br>Imagine a notebook where every transaction is written down, and thousands of people have identical copies. To add a new page, everyone has to agree it\'s valid. If someone tries to change an old page, it won\'t match everyone else\'s copies, so the tampering is obvious.<br><br>This makes it useful for things like cryptocurrency, where you need to track who owns what without trusting a bank to keep honest records.<br><br>Want me to go deeper into any aspect?', better: true },
      feedback: '<strong>B is better:</strong> For a general "explain to me" request, B uses accessible analogies that build understanding before introducing complexity. A is accurate but assumes technical background and may overwhelm a beginner.'
    }
  ];
  
  let currentIdx = 0;
  let count = 0;
  let hasSelected = false;
  
  function showComparison(idx) {
    const comp = comparisons[idx % comparisons.length];
    promptEl.textContent = comp.prompt;
    choiceAText.innerHTML = comp.a.text;
    choiceBText.innerHTML = comp.b.text;
    feedbackEl.innerHTML = '<span style="color: var(--text-muted)">Click on the response you think is better...</span>';
    feedbackEl.classList.remove('show');
    choiceA.classList.remove('selected', 'not-selected');
    choiceB.classList.remove('selected', 'not-selected');
    hasSelected = false;
  }
  
  function handleChoice(chosen, other, isCorrect, feedback) {
    if (hasSelected) return;
    hasSelected = true;
    
    chosen.classList.add('selected');
    other.classList.add('not-selected');
    
    count++;
    countEl.textContent = count.toString();
    
    if (isCorrect) {
      feedbackEl.innerHTML = 'âœ“ Nice! ' + feedback;
    } else {
      feedbackEl.innerHTML = 'â† Different perspective: ' + feedback;
    }
    feedbackEl.classList.add('show');
  }
  
  choiceA.addEventListener('click', () => {
    const comp = comparisons[currentIdx % comparisons.length];
    handleChoice(choiceA, choiceB, comp.a.better, comp.feedback);
  });
  
  choiceB.addEventListener('click', () => {
    const comp = comparisons[currentIdx % comparisons.length];
    handleChoice(choiceB, choiceA, comp.b.better, comp.feedback);
  });
  
  nextBtn.addEventListener('click', () => {
    currentIdx++;
    showComparison(currentIdx);
  });
  
  showComparison(0);
}

// ============ CONTEXT WINDOW VISUALIZER ============
function setupContextVisualizer() {
  const contextWindow = document.getElementById('context-window');
  const contextFill = document.getElementById('context-fill');
  const contextUsage = document.getElementById('context-usage');
  const addSystemBtn = document.getElementById('ctx-add-system');
  const addUserBtn = document.getElementById('ctx-add-user');
  const addLongBtn = document.getElementById('ctx-add-long');
  const overflowBtn = document.getElementById('ctx-overflow');
  const resetBtn = document.getElementById('ctx-reset');

  if (!contextWindow || !addSystemBtn) return;

  const maxTokens = 8192;
  let currentTokens = 2048;
  
  const systemPrompts = [
    "You are a helpful coding assistant. Always explain your reasoning.",
    "Be concise but thorough. Use examples when helpful.",
    "You have access to web search. Cite sources when possible."
  ];
  
  const userMessages = [
    "Can you help me understand recursion?",
    "What's the difference between let and const in JavaScript?",
    "How do I optimize a slow database query?",
    "Explain the CAP theorem in simple terms.",
    "What are the best practices for API design?"
  ];
  
  const assistantMessages = [
    "Recursion is when a function calls itself to solve smaller subproblems...",
    "let allows reassignment while const doesn't. Both are block-scoped...",
    "There are several strategies: add indexes, optimize JOINs, use EXPLAIN...",
    "CAP theorem states that distributed systems can only guarantee two of three...",
    "RESTful APIs should be stateless, use proper HTTP methods, version your API..."
  ];

  let messageIndex = { system: 0, user: 0, assistant: 0 };
  let segments = [];

  function updateDisplay() {
    const percentage = (currentTokens / maxTokens) * 100;
    contextFill.style.width = `${percentage}%`;
    contextFill.classList.toggle('warning', percentage > 80);
    contextUsage.textContent = `${currentTokens.toLocaleString()} / ${maxTokens.toLocaleString()} tokens`;
  }

  function addSegment(type, content, tokens) {
    const segment = document.createElement('div');
    segment.className = `context-segment ${type}`;
    segment.innerHTML = `
      <div class="segment-label">${type === 'system' ? 'System Prompt' : type === 'user' ? 'User' : 'Assistant'}</div>
      <div class="segment-content">${content}</div>
    `;
    segment.dataset.tokens = tokens;
    contextWindow.appendChild(segment);
    segments.push({ element: segment, tokens, type });
    currentTokens += tokens;
    updateDisplay();
  }

  function reset() {
    contextWindow.innerHTML = `
      <div class="context-segment system">
        <div class="segment-label">System Prompt</div>
        <div class="segment-content">You are a helpful assistant. Be concise and accurate...</div>
      </div>
      <div class="context-segment user">
        <div class="segment-label">User</div>
        <div class="segment-content">What is the capital of France?</div>
      </div>
      <div class="context-segment assistant">
        <div class="segment-label">Assistant</div>
        <div class="segment-content">Paris is the capital of France.</div>
      </div>
    `;
    segments = [];
    currentTokens = 2048;
    messageIndex = { system: 0, user: 0, assistant: 0 };
    updateDisplay();
  }

  addSystemBtn.addEventListener('click', () => {
    const msg = systemPrompts[messageIndex.system % systemPrompts.length];
    messageIndex.system++;
    addSegment('system', msg, 150 + Math.floor(Math.random() * 100));
  });

  addUserBtn.addEventListener('click', () => {
    const userMsg = userMessages[messageIndex.user % userMessages.length];
    const assistMsg = assistantMessages[messageIndex.assistant % assistantMessages.length];
    messageIndex.user++;
    messageIndex.assistant++;
    addSegment('user', userMsg, 50 + Math.floor(Math.random() * 30));
    addSegment('assistant', assistMsg, 200 + Math.floor(Math.random() * 100));
  });

  addLongBtn.addEventListener('click', () => {
    addSegment('user', "Here's my entire codebase for review... [2000+ tokens of code]", 2000);
    addSegment('assistant', "I've analyzed your codebase. Here are my findings... [detailed analysis]", 1500);
  });

  overflowBtn.addEventListener('click', () => {
    // Simulate overflow by marking early messages as truncated
    const allSegments = contextWindow.querySelectorAll('.context-segment');
    const truncateCount = Math.min(3, allSegments.length - 2);
    
    if (truncateCount <= 0) return;

    for (let i = 0; i < truncateCount; i++) {
      if (!allSegments[i].classList.contains('truncated')) {
        allSegments[i].style.opacity = '0.3';
        allSegments[i].style.textDecoration = 'line-through';
        allSegments[i].querySelector('.segment-label').textContent += ' [TRUNCATED]';
        allSegments[i].classList.add('truncated');
      }
    }
    
    // Add truncation indicator
    if (!contextWindow.querySelector('.truncation-indicator')) {
      const indicator = document.createElement('div');
      indicator.className = 'truncation-indicator';
      indicator.style.cssText = 'text-align: center; padding: 0.5rem; color: var(--negative); font-size: 0.75rem; border-top: 2px dashed var(--negative); order: -1; margin-bottom: 0.5rem;';
      indicator.innerHTML = 'âš ï¸ Context window overflow â€” early messages truncated';
      contextWindow.prepend(indicator);
    }
    
    currentTokens = maxTokens;
    updateDisplay();
  });

  resetBtn.addEventListener('click', reset);

  // Initial update
  updateDisplay();
}

// ============ PROMPT COMPARISON DEMO ============
function setupPromptComparison() {
  const btn1 = document.getElementById('comp-example-1');
  const btn2 = document.getElementById('comp-example-2');
  const btn3 = document.getElementById('comp-example-3');
  const weakPrompt = document.getElementById('weak-prompt');
  const strongPrompt = document.getElementById('strong-prompt');
  const weakOutcome = document.getElementById('weak-outcome');
  const strongOutcome = document.getElementById('strong-outcome');
  const insight = document.getElementById('comparison-insight');

  if (!btn1 || !weakPrompt) return;

  const examples = [
    {
      weak: "Tell me about Python",
      strong: "I'm a beginner learning Python for data analysis. Explain list comprehensions with a practical example using a dataset of sales numbers.",
      weakResult: "Generic overview, unclear what you need",
      strongResult: "Targeted explanation with relevant example",
      insight: "<strong>Why it's better:</strong> The stronger prompt tells the model your skill level (beginner), goal (data analysis), specific topic (list comprehensions), and format (practical example). This activates more relevant patterns and steers probabilities toward useful content."
    },
    {
      weak: "Write a function to process data",
      strong: "Write a Python function that takes a list of dictionaries representing sales records (each with 'date', 'amount', 'region' keys) and returns the total sales per region. Include type hints and docstring.",
      weakResult: "Vague function, may not match your needs",
      strongResult: "Exact function with specified structure",
      insight: "<strong>Why it's better:</strong> Without context, 'process data' could mean anything. The stronger prompt provides: language (Python), input format (list of dicts), expected keys, output format (totals per region), and code quality requirements (type hints, docstring)."
    },
    {
      weak: "This code doesn't work, fix it",
      strong: "This Python function should return the sum of even numbers, but it returns 0 for input [1,2,3,4]. I think the bug is in the condition. Here's the code: [code]. What's wrong and how do I fix it?",
      weakResult: "Can't help without seeing the code or error",
      strongResult: "Identifies bug and explains the fix",
      insight: "<strong>Why it's better:</strong> Debugging requires context: the code itself, expected behavior, actual behavior, and your hypothesis. The weak prompt gives the model nothing to work with â€” no code, no error message, no context."
    }
  ];

  let currentExample = 0;

  function showExample(idx) {
    currentExample = idx;
    const ex = examples[idx];
    weakPrompt.textContent = ex.weak;
    strongPrompt.textContent = ex.strong;
    weakOutcome.textContent = ex.weakResult;
    strongOutcome.textContent = ex.strongResult;
    insight.innerHTML = ex.insight;

    [btn1, btn2, btn3].forEach((btn, i) => {
      btn.classList.toggle('active', i === idx);
    });
  }

  btn1.addEventListener('click', () => showExample(0));
  btn2.addEventListener('click', () => showExample(1));
  btn3.addEventListener('click', () => showExample(2));

  showExample(0);
}

// ============ THINKING DEMO (Standard vs Reasoning) ============
function setupThinkingDemo() {
  const problemText = document.getElementById('thinking-problem-text');
  const standardResponse = document.getElementById('standard-response');
  const reasoningResponse = document.getElementById('reasoning-response');
  const thinkingContent = document.getElementById('thinking-content');
  const insightEl = document.getElementById('thinking-insight');
  const btn1 = document.getElementById('thinking-problem-1');
  const btn2 = document.getElementById('thinking-problem-2');
  const btn3 = document.getElementById('thinking-problem-3');

  if (!problemText || !btn1) return;

  const problems = [
    {
      problem: "A bat and ball cost $1.10 total. The bat costs $1.00 more than the ball. How much does the ball cost?",
      standardAnswer: "The ball costs <span class=\"answer-incorrect\">$0.10</span>",
      thinking: "Let me work through this carefully...\n\nLet ball = x\nThen bat = x + $1.00 (bat costs $1 more than ball)\n\nTotal: x + (x + $1.00) = $1.10\n2x + $1.00 = $1.10\n2x = $0.10\nx = $0.05\n\nLet me verify: ball=$0.05, bat=$1.05\nDifference: $1.05 - $0.05 = $1.00 âœ“\nTotal: $0.05 + $1.05 = $1.10 âœ“",
      reasoningAnswer: "The ball costs <span class=\"answer-correct\">$0.05</span>",
      insight: "<strong>Why the standard model fails:</strong> The intuitive answer ($0.10) \"sounds right\" and has high probability. Without explicit reasoning, the model follows the path of highest probability â€” which is the common wrong answer humans also give. The reasoning model's thinking tokens let it catch and correct this error."
    },
    {
      problem: "In a lake, there's a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how many days would it take to cover half the lake?",
      standardAnswer: "It would take <span class=\"answer-incorrect\">24 days</span> to cover half the lake",
      thinking: "Let me think about this...\n\nKey insight: the patch DOUBLES each day.\n\nIf the patch covers the whole lake on day 48...\nAnd it doubles each day...\nThen on day 47, it was HALF the size it is on day 48.\n\nSo on day 47, it covered half the lake.\n\nThe answer isn't 48/2 = 24 â€” that assumes linear growth.\nWith doubling, half coverage is just one day before full coverage.",
      reasoningAnswer: "It would take <span class=\"answer-correct\">47 days</span> to cover half the lake",
      insight: "<strong>Why this is tricky:</strong> Our intuition says \"half = half the time\" (24 days). But exponential growth doesn't work linearly. The reasoning model catches this by explicitly working through the doubling logic, while the standard model follows the intuitive but wrong pattern."
    },
    {
      problem: "If 5 machines can make 5 widgets in 5 minutes, how long would it take 100 machines to make 100 widgets?",
      standardAnswer: "It would take <span class=\"answer-incorrect\">100 minutes</span>",
      thinking: "Let me analyze this step by step...\n\nFirst, what does '5 machines make 5 widgets in 5 minutes' mean?\n- Each machine makes 1 widget in 5 minutes\n- The machines work in parallel\n\nSo for 100 machines making 100 widgets:\n- Each of the 100 machines makes 1 widget\n- They all work simultaneously\n- Each widget still takes 5 minutes\n\nAnswer: 5 minutes (same time, just more parallelism)",
      reasoningAnswer: "It would take <span class=\"answer-correct\">5 minutes</span>",
      insight: "<strong>The parallel processing trap:</strong> This problem tests whether you understand that adding machines adds parallelism, not sequential time. The standard model pattern-matches to \"bigger numbers = more time,\" while reasoning reveals that each machine independently makes one widget in 5 minutes."
    }
  ];

  let currentProblem = 0;

  function showProblem(idx) {
    currentProblem = idx;
    const prob = problems[idx];
    
    problemText.textContent = prob.problem;
    standardResponse.innerHTML = `<div class="final-answer">${prob.standardAnswer}</div>`;
    
    reasoningResponse.innerHTML = `
      <div class="thinking-tokens">
        <div class="thinking-tokens-label">ðŸ’­ Thinking tokens (in context)</div>
        <span style="white-space: pre-wrap;">${prob.thinking}</span>
      </div>
      <div class="final-answer">${prob.reasoningAnswer}</div>
    `;
    
    insightEl.innerHTML = prob.insight;

    [btn1, btn2, btn3].forEach((btn, i) => {
      if (btn) {
        btn.classList.toggle('primary', i === idx);
        btn.style.opacity = i === idx ? '1' : '0.7';
      }
    });
  }

  btn1.addEventListener('click', () => showProblem(0));
  btn2.addEventListener('click', () => showProblem(1));
  btn3.addEventListener('click', () => showProblem(2));

  showProblem(0);
}

// ============ INITIALIZATION ============
document.addEventListener('DOMContentLoaded', () => {
  // Disable automatic scroll restoration
  if ('scrollRestoration' in history) {
    history.scrollRestoration = 'manual';
  }

  // Force scroll to top on load
  const forceScrollTop = () => {
    window.scrollTo(0, 0);
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
    const mainContent = document.querySelector('.main-content');
    if (mainContent) mainContent.scrollTop = 0;
  };

  forceScrollTop();
  // Small delay to catch any late browser scroll adjustments
  setTimeout(forceScrollTop, 50);

  setupTabs();
  setupInference();
  setupNeuralNetwork();
  setupTokenizer();
  setupEmbeddings();
  setupAttention();
  setupTraining();
  setupTrainingLoop();
  setupRaterDemo();
  setupRealVectorDisplay();
  setupContextVisualizer();
  setupPromptComparison();
  setupThinkingDemo();
});

// ============ REAL VECTOR DISPLAY ============
function setupRealVectorDisplay() {
  const grid = document.getElementById('real-vector-grid');
  if (!grid) return;
  
  // Simulated embedding values (first 32 dimensions of a real-ish embedding)
  const embeddingValues = [
    0.23, -0.87, 1.45, -0.12, 0.67, -1.23, 0.89, -0.45,
    1.12, -0.34, 0.56, -0.78, 1.67, -0.23, 0.45, -1.56,
    0.12, -0.89, 1.34, -0.67, 0.78, -0.12, 0.34, -1.78,
    1.23, -0.56, 0.89, -0.34, 0.45, -1.12, 0.67, -0.23
  ];
  
  grid.innerHTML = '';
  
  embeddingValues.forEach((val, i) => {
    const cell = document.createElement('div');
    cell.className = 'vector-cell';
    cell.setAttribute('data-value', `dim ${i}: ${val.toFixed(2)}`);
    
    // Color based on value: negative = red, positive = blue
    const intensity = Math.min(1, Math.abs(val) / 2);
    if (val >= 0) {
      cell.style.background = `rgba(59, 130, 246, ${0.2 + intensity * 0.8})`;
    } else {
      cell.style.background = `rgba(239, 68, 68, ${0.2 + intensity * 0.8})`;
    }
    
    grid.appendChild(cell);
  });
}
</script>
</body>
</html>
